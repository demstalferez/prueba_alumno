2022-11-22 10:32:00,454:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 10:32:00,454:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 10:32:00,454:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 10:32:00,454:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 10:34:33,803:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 10:34:33,804:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 10:34:33,804:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 10:34:33,804:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 10:34:34,480:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-11-22 10:37:55,220:INFO:PyCaret ClassificationExperiment
2022-11-22 10:37:55,220:INFO:Logging name: clf-default-name
2022-11-22 10:37:55,220:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-11-22 10:37:55,220:INFO:version 3.0.0.rc4
2022-11-22 10:37:55,220:INFO:Initializing setup()
2022-11-22 10:37:55,220:INFO:self.USI: 61c3
2022-11-22 10:37:55,220:INFO:self.variable_keys: {'y_test', '_is_multiclass', 'exp_name_log', 'data', 'variable_keys', 'y', 'master_model_container', 'USI', '_all_models_internal', '_ml_usecase', 'memory', '_gpu_n_jobs_param', 'html_param', 'X', 'target_param', '_all_metrics', 'y_train', 'logging_param', 'X_train', 'fold_generator', 'gpu_param', 'X_test', 'idx', 'pipeline', 'seed', 'fix_imbalance', '_available_plots', '_all_models', 'exp_id', 'display_container', 'fold_groups_param', 'log_plots_param', 'n_jobs_param', 'fold_shuffle_param'}
2022-11-22 10:37:55,220:INFO:Checking environment
2022-11-22 10:37:55,220:INFO:python_version: 3.10.6
2022-11-22 10:37:55,220:INFO:python_build: ('main', 'Nov  2 2022 18:53:38')
2022-11-22 10:37:55,220:INFO:machine: x86_64
2022-11-22 10:37:55,220:INFO:platform: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-22 10:37:55,220:INFO:Memory: svmem(total=7962374144, available=2966405120, percent=62.7, used=4028092416, free=924729344, active=1423405056, inactive=4693204992, buffers=205877248, cached=2803675136, shared=651173888, slab=433516544)
2022-11-22 10:37:55,221:INFO:Physical Core: 4
2022-11-22 10:37:55,221:INFO:Logical Core: 8
2022-11-22 10:37:55,221:INFO:Checking libraries
2022-11-22 10:37:55,221:INFO:System:
2022-11-22 10:37:55,221:INFO:    python: 3.10.6 (main, Nov  2 2022, 18:53:38) [GCC 11.3.0]
2022-11-22 10:37:55,221:INFO:executable: /bin/python3
2022-11-22 10:37:55,221:INFO:   machine: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-22 10:37:55,221:INFO:PyCaret required dependencies:
2022-11-22 10:37:55,221:INFO:                 pip: 22.0.2
2022-11-22 10:37:55,221:INFO:          setuptools: 59.6.0
2022-11-22 10:37:55,221:INFO:             pycaret: 3.0.0rc4
2022-11-22 10:37:55,221:INFO:             IPython: 8.6.0
2022-11-22 10:37:55,221:INFO:          ipywidgets: 8.0.2
2022-11-22 10:37:55,221:INFO:                tqdm: 4.64.1
2022-11-22 10:37:55,221:INFO:               numpy: 1.21.4
2022-11-22 10:37:55,221:INFO:              pandas: 1.3.5
2022-11-22 10:37:55,221:INFO:              jinja2: 3.0.3
2022-11-22 10:37:55,221:INFO:               scipy: 1.8.1
2022-11-22 10:37:55,221:INFO:              joblib: 1.2.0
2022-11-22 10:37:55,221:INFO:             sklearn: 1.1.3
2022-11-22 10:37:55,221:INFO:                pyod: 1.0.6
2022-11-22 10:37:55,221:INFO:            imblearn: 0.9.1
2022-11-22 10:37:55,222:INFO:   category_encoders: 2.5.1.post0
2022-11-22 10:37:55,222:INFO:            lightgbm: 3.3.3
2022-11-22 10:37:55,222:INFO:               numba: 0.55.2
2022-11-22 10:37:55,222:INFO:            requests: 2.25.1
2022-11-22 10:37:55,222:INFO:          matplotlib: 3.6.2
2022-11-22 10:37:55,222:INFO:          scikitplot: 0.3.7
2022-11-22 10:37:55,222:INFO:         yellowbrick: 1.5
2022-11-22 10:37:55,222:INFO:              plotly: 5.11.0
2022-11-22 10:37:55,222:INFO:             kaleido: 0.2.1
2022-11-22 10:37:55,222:INFO:         statsmodels: 0.13.5
2022-11-22 10:37:55,222:INFO:              sktime: 0.13.4
2022-11-22 10:37:55,222:INFO:               tbats: 1.1.1
2022-11-22 10:37:55,222:INFO:            pmdarima: 1.8.5
2022-11-22 10:37:55,222:INFO:              psutil: 5.9.0
2022-11-22 10:37:55,222:INFO:PyCaret optional dependencies:
2022-11-22 10:37:55,224:INFO:                shap: Not installed
2022-11-22 10:37:55,225:INFO:           interpret: Not installed
2022-11-22 10:37:55,225:INFO:                umap: Not installed
2022-11-22 10:37:55,225:INFO:    pandas_profiling: Not installed
2022-11-22 10:37:55,225:INFO:  explainerdashboard: Not installed
2022-11-22 10:37:55,225:INFO:             autoviz: Not installed
2022-11-22 10:37:55,225:INFO:           fairlearn: Not installed
2022-11-22 10:37:55,225:INFO:             xgboost: Not installed
2022-11-22 10:37:55,225:INFO:            catboost: Not installed
2022-11-22 10:37:55,225:INFO:              kmodes: Not installed
2022-11-22 10:37:55,225:INFO:             mlxtend: Not installed
2022-11-22 10:37:55,225:INFO:       statsforecast: Not installed
2022-11-22 10:37:55,225:INFO:        tune_sklearn: Not installed
2022-11-22 10:37:55,225:INFO:                 ray: Not installed
2022-11-22 10:37:55,225:INFO:            hyperopt: Not installed
2022-11-22 10:37:55,225:INFO:              optuna: Not installed
2022-11-22 10:37:55,225:INFO:               skopt: Not installed
2022-11-22 10:37:55,225:INFO:              mlflow: Not installed
2022-11-22 10:37:55,225:INFO:              gradio: Not installed
2022-11-22 10:37:55,225:INFO:             fastapi: Not installed
2022-11-22 10:37:55,225:INFO:             uvicorn: Not installed
2022-11-22 10:37:55,225:INFO:              m2cgen: Not installed
2022-11-22 10:37:55,225:INFO:           evidently: Not installed
2022-11-22 10:37:55,225:INFO:                nltk: 3.6.7
2022-11-22 10:37:55,225:INFO:            pyLDAvis: Not installed
2022-11-22 10:37:55,225:INFO:              gensim: Not installed
2022-11-22 10:37:55,225:INFO:               spacy: Not installed
2022-11-22 10:37:55,225:INFO:           wordcloud: Not installed
2022-11-22 10:37:55,225:INFO:            textblob: Not installed
2022-11-22 10:37:55,225:INFO:               fugue: Not installed
2022-11-22 10:37:55,225:INFO:           streamlit: 1.15.0
2022-11-22 10:37:55,225:INFO:             prophet: Not installed
2022-11-22 10:37:55,225:INFO:None
2022-11-22 10:37:55,225:INFO:Set up data.
2022-11-22 10:37:55,230:INFO:Set up train/test split.
2022-11-22 10:39:12,079:INFO:PyCaret ClassificationExperiment
2022-11-22 10:39:12,079:INFO:Logging name: clf-default-name
2022-11-22 10:39:12,079:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-11-22 10:39:12,079:INFO:version 3.0.0.rc4
2022-11-22 10:39:12,079:INFO:Initializing setup()
2022-11-22 10:39:12,079:INFO:self.USI: 3c4f
2022-11-22 10:39:12,079:INFO:self.variable_keys: {'y_test', '_is_multiclass', 'exp_name_log', 'data', 'variable_keys', 'y', 'master_model_container', 'USI', '_all_models_internal', '_ml_usecase', 'memory', '_gpu_n_jobs_param', 'html_param', 'X', 'target_param', '_all_metrics', 'y_train', 'logging_param', 'X_train', 'fold_generator', 'gpu_param', 'X_test', 'idx', 'pipeline', 'seed', 'fix_imbalance', '_available_plots', '_all_models', 'exp_id', 'display_container', 'fold_groups_param', 'log_plots_param', 'n_jobs_param', 'fold_shuffle_param'}
2022-11-22 10:39:12,079:INFO:Checking environment
2022-11-22 10:39:12,079:INFO:python_version: 3.10.6
2022-11-22 10:39:12,079:INFO:python_build: ('main', 'Nov  2 2022 18:53:38')
2022-11-22 10:39:12,079:INFO:machine: x86_64
2022-11-22 10:39:12,080:INFO:platform: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-22 10:39:12,080:INFO:Memory: svmem(total=7962374144, available=2906181632, percent=63.5, used=4068425728, free=859406336, active=1424625664, inactive=4755079168, buffers=206581760, cached=2827960320, shared=671064064, slab=433917952)
2022-11-22 10:39:12,080:INFO:Physical Core: 4
2022-11-22 10:39:12,080:INFO:Logical Core: 8
2022-11-22 10:39:12,080:INFO:Checking libraries
2022-11-22 10:39:12,080:INFO:System:
2022-11-22 10:39:12,080:INFO:    python: 3.10.6 (main, Nov  2 2022, 18:53:38) [GCC 11.3.0]
2022-11-22 10:39:12,080:INFO:executable: /bin/python3
2022-11-22 10:39:12,080:INFO:   machine: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-22 10:39:12,080:INFO:PyCaret required dependencies:
2022-11-22 10:39:12,080:INFO:                 pip: 22.0.2
2022-11-22 10:39:12,081:INFO:          setuptools: 59.6.0
2022-11-22 10:39:12,081:INFO:             pycaret: 3.0.0rc4
2022-11-22 10:39:12,081:INFO:             IPython: 8.6.0
2022-11-22 10:39:12,081:INFO:          ipywidgets: 8.0.2
2022-11-22 10:39:12,081:INFO:                tqdm: 4.64.1
2022-11-22 10:39:12,081:INFO:               numpy: 1.21.4
2022-11-22 10:39:12,081:INFO:              pandas: 1.3.5
2022-11-22 10:39:12,081:INFO:              jinja2: 3.0.3
2022-11-22 10:39:12,081:INFO:               scipy: 1.8.1
2022-11-22 10:39:12,081:INFO:              joblib: 1.2.0
2022-11-22 10:39:12,081:INFO:             sklearn: 1.1.3
2022-11-22 10:39:12,081:INFO:                pyod: 1.0.6
2022-11-22 10:39:12,081:INFO:            imblearn: 0.9.1
2022-11-22 10:39:12,081:INFO:   category_encoders: 2.5.1.post0
2022-11-22 10:39:12,081:INFO:            lightgbm: 3.3.3
2022-11-22 10:39:12,081:INFO:               numba: 0.55.2
2022-11-22 10:39:12,081:INFO:            requests: 2.25.1
2022-11-22 10:39:12,081:INFO:          matplotlib: 3.6.2
2022-11-22 10:39:12,081:INFO:          scikitplot: 0.3.7
2022-11-22 10:39:12,081:INFO:         yellowbrick: 1.5
2022-11-22 10:39:12,081:INFO:              plotly: 5.11.0
2022-11-22 10:39:12,081:INFO:             kaleido: 0.2.1
2022-11-22 10:39:12,081:INFO:         statsmodels: 0.13.5
2022-11-22 10:39:12,081:INFO:              sktime: 0.13.4
2022-11-22 10:39:12,081:INFO:               tbats: 1.1.1
2022-11-22 10:39:12,081:INFO:            pmdarima: 1.8.5
2022-11-22 10:39:12,081:INFO:              psutil: 5.9.0
2022-11-22 10:39:12,081:INFO:PyCaret optional dependencies:
2022-11-22 10:39:12,081:INFO:                shap: Not installed
2022-11-22 10:39:12,081:INFO:           interpret: Not installed
2022-11-22 10:39:12,081:INFO:                umap: Not installed
2022-11-22 10:39:12,081:INFO:    pandas_profiling: Not installed
2022-11-22 10:39:12,081:INFO:  explainerdashboard: Not installed
2022-11-22 10:39:12,081:INFO:             autoviz: Not installed
2022-11-22 10:39:12,081:INFO:           fairlearn: Not installed
2022-11-22 10:39:12,081:INFO:             xgboost: Not installed
2022-11-22 10:39:12,081:INFO:            catboost: Not installed
2022-11-22 10:39:12,081:INFO:              kmodes: Not installed
2022-11-22 10:39:12,081:INFO:             mlxtend: Not installed
2022-11-22 10:39:12,081:INFO:       statsforecast: Not installed
2022-11-22 10:39:12,081:INFO:        tune_sklearn: Not installed
2022-11-22 10:39:12,081:INFO:                 ray: Not installed
2022-11-22 10:39:12,081:INFO:            hyperopt: Not installed
2022-11-22 10:39:12,081:INFO:              optuna: Not installed
2022-11-22 10:39:12,081:INFO:               skopt: Not installed
2022-11-22 10:39:12,081:INFO:              mlflow: Not installed
2022-11-22 10:39:12,081:INFO:              gradio: Not installed
2022-11-22 10:39:12,081:INFO:             fastapi: Not installed
2022-11-22 10:39:12,081:INFO:             uvicorn: Not installed
2022-11-22 10:39:12,081:INFO:              m2cgen: Not installed
2022-11-22 10:39:12,081:INFO:           evidently: Not installed
2022-11-22 10:39:12,081:INFO:                nltk: 3.6.7
2022-11-22 10:39:12,081:INFO:            pyLDAvis: Not installed
2022-11-22 10:39:12,081:INFO:              gensim: Not installed
2022-11-22 10:39:12,081:INFO:               spacy: Not installed
2022-11-22 10:39:12,081:INFO:           wordcloud: Not installed
2022-11-22 10:39:12,081:INFO:            textblob: Not installed
2022-11-22 10:39:12,081:INFO:               fugue: Not installed
2022-11-22 10:39:12,081:INFO:           streamlit: 1.15.0
2022-11-22 10:39:12,081:INFO:             prophet: Not installed
2022-11-22 10:39:12,081:INFO:None
2022-11-22 10:39:12,081:INFO:Set up data.
2022-11-22 10:39:12,101:INFO:Set up train/test split.
2022-11-22 10:40:17,111:INFO:PyCaret ClassificationExperiment
2022-11-22 10:40:17,111:INFO:Logging name: clf-default-name
2022-11-22 10:40:17,111:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-11-22 10:40:17,111:INFO:version 3.0.0.rc4
2022-11-22 10:40:17,111:INFO:Initializing setup()
2022-11-22 10:40:17,111:INFO:self.USI: 49cb
2022-11-22 10:40:17,111:INFO:self.variable_keys: {'y_test', '_is_multiclass', 'exp_name_log', 'data', 'variable_keys', 'y', 'master_model_container', 'USI', '_all_models_internal', '_ml_usecase', 'memory', '_gpu_n_jobs_param', 'html_param', 'X', 'target_param', '_all_metrics', 'y_train', 'logging_param', 'X_train', 'fold_generator', 'gpu_param', 'X_test', 'idx', 'pipeline', 'seed', 'fix_imbalance', '_available_plots', '_all_models', 'exp_id', 'display_container', 'fold_groups_param', 'log_plots_param', 'n_jobs_param', 'fold_shuffle_param'}
2022-11-22 10:40:17,111:INFO:Checking environment
2022-11-22 10:40:17,111:INFO:python_version: 3.10.6
2022-11-22 10:40:17,111:INFO:python_build: ('main', 'Nov  2 2022 18:53:38')
2022-11-22 10:40:17,111:INFO:machine: x86_64
2022-11-22 10:40:17,111:INFO:platform: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-22 10:40:17,111:INFO:Memory: svmem(total=7962374144, available=3145498624, percent=60.5, used=3852378112, free=1097773056, active=1427030016, inactive=4522516480, buffers=206925824, cached=2805297152, shared=647794688, slab=433762304)
2022-11-22 10:40:17,112:INFO:Physical Core: 4
2022-11-22 10:40:17,112:INFO:Logical Core: 8
2022-11-22 10:40:17,112:INFO:Checking libraries
2022-11-22 10:40:17,112:INFO:System:
2022-11-22 10:40:17,112:INFO:    python: 3.10.6 (main, Nov  2 2022, 18:53:38) [GCC 11.3.0]
2022-11-22 10:40:17,112:INFO:executable: /bin/python3
2022-11-22 10:40:17,112:INFO:   machine: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-22 10:40:17,112:INFO:PyCaret required dependencies:
2022-11-22 10:40:17,112:INFO:                 pip: 22.0.2
2022-11-22 10:40:17,112:INFO:          setuptools: 59.6.0
2022-11-22 10:40:17,112:INFO:             pycaret: 3.0.0rc4
2022-11-22 10:40:17,112:INFO:             IPython: 8.6.0
2022-11-22 10:40:17,112:INFO:          ipywidgets: 8.0.2
2022-11-22 10:40:17,112:INFO:                tqdm: 4.64.1
2022-11-22 10:40:17,112:INFO:               numpy: 1.21.4
2022-11-22 10:40:17,112:INFO:              pandas: 1.3.5
2022-11-22 10:40:17,112:INFO:              jinja2: 3.0.3
2022-11-22 10:40:17,112:INFO:               scipy: 1.8.1
2022-11-22 10:40:17,112:INFO:              joblib: 1.2.0
2022-11-22 10:40:17,112:INFO:             sklearn: 1.1.3
2022-11-22 10:40:17,112:INFO:                pyod: 1.0.6
2022-11-22 10:40:17,112:INFO:            imblearn: 0.9.1
2022-11-22 10:40:17,112:INFO:   category_encoders: 2.5.1.post0
2022-11-22 10:40:17,113:INFO:            lightgbm: 3.3.3
2022-11-22 10:40:17,113:INFO:               numba: 0.55.2
2022-11-22 10:40:17,113:INFO:            requests: 2.25.1
2022-11-22 10:40:17,113:INFO:          matplotlib: 3.6.2
2022-11-22 10:40:17,113:INFO:          scikitplot: 0.3.7
2022-11-22 10:40:17,113:INFO:         yellowbrick: 1.5
2022-11-22 10:40:17,113:INFO:              plotly: 5.11.0
2022-11-22 10:40:17,113:INFO:             kaleido: 0.2.1
2022-11-22 10:40:17,113:INFO:         statsmodels: 0.13.5
2022-11-22 10:40:17,113:INFO:              sktime: 0.13.4
2022-11-22 10:40:17,113:INFO:               tbats: 1.1.1
2022-11-22 10:40:17,113:INFO:            pmdarima: 1.8.5
2022-11-22 10:40:17,113:INFO:              psutil: 5.9.0
2022-11-22 10:40:17,113:INFO:PyCaret optional dependencies:
2022-11-22 10:40:17,113:INFO:                shap: Not installed
2022-11-22 10:40:17,113:INFO:           interpret: Not installed
2022-11-22 10:40:17,113:INFO:                umap: Not installed
2022-11-22 10:40:17,113:INFO:    pandas_profiling: Not installed
2022-11-22 10:40:17,113:INFO:  explainerdashboard: Not installed
2022-11-22 10:40:17,113:INFO:             autoviz: Not installed
2022-11-22 10:40:17,113:INFO:           fairlearn: Not installed
2022-11-22 10:40:17,113:INFO:             xgboost: Not installed
2022-11-22 10:40:17,113:INFO:            catboost: Not installed
2022-11-22 10:40:17,113:INFO:              kmodes: Not installed
2022-11-22 10:40:17,113:INFO:             mlxtend: Not installed
2022-11-22 10:40:17,113:INFO:       statsforecast: Not installed
2022-11-22 10:40:17,113:INFO:        tune_sklearn: Not installed
2022-11-22 10:40:17,113:INFO:                 ray: Not installed
2022-11-22 10:40:17,113:INFO:            hyperopt: Not installed
2022-11-22 10:40:17,113:INFO:              optuna: Not installed
2022-11-22 10:40:17,113:INFO:               skopt: Not installed
2022-11-22 10:40:17,113:INFO:              mlflow: Not installed
2022-11-22 10:40:17,114:INFO:              gradio: Not installed
2022-11-22 10:40:17,114:INFO:             fastapi: Not installed
2022-11-22 10:40:17,114:INFO:             uvicorn: Not installed
2022-11-22 10:40:17,114:INFO:              m2cgen: Not installed
2022-11-22 10:40:17,114:INFO:           evidently: Not installed
2022-11-22 10:40:17,114:INFO:                nltk: 3.6.7
2022-11-22 10:40:17,114:INFO:            pyLDAvis: Not installed
2022-11-22 10:40:17,114:INFO:              gensim: Not installed
2022-11-22 10:40:17,114:INFO:               spacy: Not installed
2022-11-22 10:40:17,114:INFO:           wordcloud: Not installed
2022-11-22 10:40:17,114:INFO:            textblob: Not installed
2022-11-22 10:40:17,114:INFO:               fugue: Not installed
2022-11-22 10:40:17,114:INFO:           streamlit: 1.15.0
2022-11-22 10:40:17,114:INFO:             prophet: Not installed
2022-11-22 10:40:17,114:INFO:None
2022-11-22 10:40:17,114:INFO:Set up data.
2022-11-22 10:40:17,132:INFO:Set up train/test split.
2022-11-22 10:40:48,715:INFO:PyCaret ClassificationExperiment
2022-11-22 10:40:48,715:INFO:Logging name: clf-default-name
2022-11-22 10:40:48,715:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-11-22 10:40:48,715:INFO:version 3.0.0.rc4
2022-11-22 10:40:48,715:INFO:Initializing setup()
2022-11-22 10:40:48,715:INFO:self.USI: 80f9
2022-11-22 10:40:48,715:INFO:self.variable_keys: {'y_test', '_is_multiclass', 'exp_name_log', 'data', 'variable_keys', 'y', 'master_model_container', 'USI', '_all_models_internal', '_ml_usecase', 'memory', '_gpu_n_jobs_param', 'html_param', 'X', 'target_param', '_all_metrics', 'y_train', 'logging_param', 'X_train', 'fold_generator', 'gpu_param', 'X_test', 'idx', 'pipeline', 'seed', 'fix_imbalance', '_available_plots', '_all_models', 'exp_id', 'display_container', 'fold_groups_param', 'log_plots_param', 'n_jobs_param', 'fold_shuffle_param'}
2022-11-22 10:40:48,715:INFO:Checking environment
2022-11-22 10:40:48,715:INFO:python_version: 3.10.6
2022-11-22 10:40:48,715:INFO:python_build: ('main', 'Nov  2 2022 18:53:38')
2022-11-22 10:40:48,715:INFO:machine: x86_64
2022-11-22 10:40:48,715:INFO:platform: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-22 10:40:48,716:INFO:Memory: svmem(total=7962374144, available=3110772736, percent=60.9, used=3896954880, free=1058013184, active=1427992576, inactive=4565295104, buffers=207327232, cached=2800078848, shared=637943808, slab=434462720)
2022-11-22 10:40:48,716:INFO:Physical Core: 4
2022-11-22 10:40:48,716:INFO:Logical Core: 8
2022-11-22 10:40:48,716:INFO:Checking libraries
2022-11-22 10:40:48,716:INFO:System:
2022-11-22 10:40:48,716:INFO:    python: 3.10.6 (main, Nov  2 2022, 18:53:38) [GCC 11.3.0]
2022-11-22 10:40:48,716:INFO:executable: /bin/python3
2022-11-22 10:40:48,716:INFO:   machine: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-22 10:40:48,716:INFO:PyCaret required dependencies:
2022-11-22 10:40:48,716:INFO:                 pip: 22.0.2
2022-11-22 10:40:48,716:INFO:          setuptools: 59.6.0
2022-11-22 10:40:48,716:INFO:             pycaret: 3.0.0rc4
2022-11-22 10:40:48,716:INFO:             IPython: 8.6.0
2022-11-22 10:40:48,716:INFO:          ipywidgets: 8.0.2
2022-11-22 10:40:48,716:INFO:                tqdm: 4.64.1
2022-11-22 10:40:48,716:INFO:               numpy: 1.21.4
2022-11-22 10:40:48,716:INFO:              pandas: 1.3.5
2022-11-22 10:40:48,716:INFO:              jinja2: 3.0.3
2022-11-22 10:40:48,717:INFO:               scipy: 1.8.1
2022-11-22 10:40:48,717:INFO:              joblib: 1.2.0
2022-11-22 10:40:48,717:INFO:             sklearn: 1.1.3
2022-11-22 10:40:48,717:INFO:                pyod: 1.0.6
2022-11-22 10:40:48,717:INFO:            imblearn: 0.9.1
2022-11-22 10:40:48,717:INFO:   category_encoders: 2.5.1.post0
2022-11-22 10:40:48,717:INFO:            lightgbm: 3.3.3
2022-11-22 10:40:48,717:INFO:               numba: 0.55.2
2022-11-22 10:40:48,717:INFO:            requests: 2.25.1
2022-11-22 10:40:48,717:INFO:          matplotlib: 3.6.2
2022-11-22 10:40:48,717:INFO:          scikitplot: 0.3.7
2022-11-22 10:40:48,717:INFO:         yellowbrick: 1.5
2022-11-22 10:40:48,717:INFO:              plotly: 5.11.0
2022-11-22 10:40:48,717:INFO:             kaleido: 0.2.1
2022-11-22 10:40:48,717:INFO:         statsmodels: 0.13.5
2022-11-22 10:40:48,717:INFO:              sktime: 0.13.4
2022-11-22 10:40:48,717:INFO:               tbats: 1.1.1
2022-11-22 10:40:48,717:INFO:            pmdarima: 1.8.5
2022-11-22 10:40:48,717:INFO:              psutil: 5.9.0
2022-11-22 10:40:48,717:INFO:PyCaret optional dependencies:
2022-11-22 10:40:48,717:INFO:                shap: Not installed
2022-11-22 10:40:48,717:INFO:           interpret: Not installed
2022-11-22 10:40:48,717:INFO:                umap: Not installed
2022-11-22 10:40:48,717:INFO:    pandas_profiling: Not installed
2022-11-22 10:40:48,717:INFO:  explainerdashboard: Not installed
2022-11-22 10:40:48,717:INFO:             autoviz: Not installed
2022-11-22 10:40:48,717:INFO:           fairlearn: Not installed
2022-11-22 10:40:48,717:INFO:             xgboost: Not installed
2022-11-22 10:40:48,717:INFO:            catboost: Not installed
2022-11-22 10:40:48,717:INFO:              kmodes: Not installed
2022-11-22 10:40:48,717:INFO:             mlxtend: Not installed
2022-11-22 10:40:48,717:INFO:       statsforecast: Not installed
2022-11-22 10:40:48,718:INFO:        tune_sklearn: Not installed
2022-11-22 10:40:48,718:INFO:                 ray: Not installed
2022-11-22 10:40:48,718:INFO:            hyperopt: Not installed
2022-11-22 10:40:48,718:INFO:              optuna: Not installed
2022-11-22 10:40:48,718:INFO:               skopt: Not installed
2022-11-22 10:40:48,718:INFO:              mlflow: Not installed
2022-11-22 10:40:48,718:INFO:              gradio: Not installed
2022-11-22 10:40:48,718:INFO:             fastapi: Not installed
2022-11-22 10:40:48,718:INFO:             uvicorn: Not installed
2022-11-22 10:40:48,718:INFO:              m2cgen: Not installed
2022-11-22 10:40:48,718:INFO:           evidently: Not installed
2022-11-22 10:40:48,718:INFO:                nltk: 3.6.7
2022-11-22 10:40:48,718:INFO:            pyLDAvis: Not installed
2022-11-22 10:40:48,718:INFO:              gensim: Not installed
2022-11-22 10:40:48,718:INFO:               spacy: Not installed
2022-11-22 10:40:48,718:INFO:           wordcloud: Not installed
2022-11-22 10:40:48,718:INFO:            textblob: Not installed
2022-11-22 10:40:48,718:INFO:               fugue: Not installed
2022-11-22 10:40:48,718:INFO:           streamlit: 1.15.0
2022-11-22 10:40:48,718:INFO:             prophet: Not installed
2022-11-22 10:40:48,718:INFO:None
2022-11-22 10:40:48,718:INFO:Set up data.
2022-11-22 10:40:48,744:INFO:Set up train/test split.
2022-11-22 10:41:21,413:INFO:PyCaret RegressionExperiment
2022-11-22 10:41:21,414:INFO:Logging name: reg-default-name
2022-11-22 10:41:21,414:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-22 10:41:21,414:INFO:version 3.0.0.rc4
2022-11-22 10:41:21,414:INFO:Initializing setup()
2022-11-22 10:41:21,414:INFO:self.USI: b12d
2022-11-22 10:41:21,414:INFO:self.variable_keys: {'y_test', 'exp_name_log', 'data', 'variable_keys', 'y', 'master_model_container', 'USI', '_all_models_internal', '_ml_usecase', 'memory', '_gpu_n_jobs_param', 'html_param', 'X', 'target_param', '_all_metrics', 'y_train', 'logging_param', 'X_train', 'fold_generator', 'transform_target_param', 'gpu_param', 'X_test', 'idx', 'pipeline', 'seed', '_available_plots', '_all_models', 'exp_id', 'display_container', 'fold_groups_param', 'log_plots_param', 'transform_target_method_param', 'n_jobs_param', 'fold_shuffle_param'}
2022-11-22 10:41:21,414:INFO:Checking environment
2022-11-22 10:41:21,414:INFO:python_version: 3.10.6
2022-11-22 10:41:21,414:INFO:python_build: ('main', 'Nov  2 2022 18:53:38')
2022-11-22 10:41:21,414:INFO:machine: x86_64
2022-11-22 10:41:21,414:INFO:platform: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-22 10:41:21,414:INFO:Memory: svmem(total=7962374144, available=3038285824, percent=61.8, used=3926937600, free=980975616, active=1429315584, inactive=4610793472, buffers=207810560, cached=2846650368, shared=680448000, slab=434069504)
2022-11-22 10:41:21,415:INFO:Physical Core: 4
2022-11-22 10:41:21,415:INFO:Logical Core: 8
2022-11-22 10:41:21,415:INFO:Checking libraries
2022-11-22 10:41:21,415:INFO:System:
2022-11-22 10:41:21,415:INFO:    python: 3.10.6 (main, Nov  2 2022, 18:53:38) [GCC 11.3.0]
2022-11-22 10:41:21,415:INFO:executable: /bin/python3
2022-11-22 10:41:21,415:INFO:   machine: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-22 10:41:21,415:INFO:PyCaret required dependencies:
2022-11-22 10:41:21,415:INFO:                 pip: 22.0.2
2022-11-22 10:41:21,415:INFO:          setuptools: 59.6.0
2022-11-22 10:41:21,415:INFO:             pycaret: 3.0.0rc4
2022-11-22 10:41:21,415:INFO:             IPython: 8.6.0
2022-11-22 10:41:21,415:INFO:          ipywidgets: 8.0.2
2022-11-22 10:41:21,415:INFO:                tqdm: 4.64.1
2022-11-22 10:41:21,415:INFO:               numpy: 1.21.4
2022-11-22 10:41:21,415:INFO:              pandas: 1.3.5
2022-11-22 10:41:21,415:INFO:              jinja2: 3.0.3
2022-11-22 10:41:21,415:INFO:               scipy: 1.8.1
2022-11-22 10:41:21,415:INFO:              joblib: 1.2.0
2022-11-22 10:41:21,415:INFO:             sklearn: 1.1.3
2022-11-22 10:41:21,415:INFO:                pyod: 1.0.6
2022-11-22 10:41:21,415:INFO:            imblearn: 0.9.1
2022-11-22 10:41:21,415:INFO:   category_encoders: 2.5.1.post0
2022-11-22 10:41:21,415:INFO:            lightgbm: 3.3.3
2022-11-22 10:41:21,415:INFO:               numba: 0.55.2
2022-11-22 10:41:21,415:INFO:            requests: 2.25.1
2022-11-22 10:41:21,415:INFO:          matplotlib: 3.6.2
2022-11-22 10:41:21,415:INFO:          scikitplot: 0.3.7
2022-11-22 10:41:21,416:INFO:         yellowbrick: 1.5
2022-11-22 10:41:21,416:INFO:              plotly: 5.11.0
2022-11-22 10:41:21,416:INFO:             kaleido: 0.2.1
2022-11-22 10:41:21,416:INFO:         statsmodels: 0.13.5
2022-11-22 10:41:21,416:INFO:              sktime: 0.13.4
2022-11-22 10:41:21,416:INFO:               tbats: 1.1.1
2022-11-22 10:41:21,416:INFO:            pmdarima: 1.8.5
2022-11-22 10:41:21,416:INFO:              psutil: 5.9.0
2022-11-22 10:41:21,416:INFO:PyCaret optional dependencies:
2022-11-22 10:41:21,416:INFO:                shap: Not installed
2022-11-22 10:41:21,416:INFO:           interpret: Not installed
2022-11-22 10:41:21,416:INFO:                umap: Not installed
2022-11-22 10:41:21,416:INFO:    pandas_profiling: Not installed
2022-11-22 10:41:21,416:INFO:  explainerdashboard: Not installed
2022-11-22 10:41:21,416:INFO:             autoviz: Not installed
2022-11-22 10:41:21,416:INFO:           fairlearn: Not installed
2022-11-22 10:41:21,416:INFO:             xgboost: Not installed
2022-11-22 10:41:21,416:INFO:            catboost: Not installed
2022-11-22 10:41:21,416:INFO:              kmodes: Not installed
2022-11-22 10:41:21,416:INFO:             mlxtend: Not installed
2022-11-22 10:41:21,416:INFO:       statsforecast: Not installed
2022-11-22 10:41:21,416:INFO:        tune_sklearn: Not installed
2022-11-22 10:41:21,416:INFO:                 ray: Not installed
2022-11-22 10:41:21,416:INFO:            hyperopt: Not installed
2022-11-22 10:41:21,416:INFO:              optuna: Not installed
2022-11-22 10:41:21,416:INFO:               skopt: Not installed
2022-11-22 10:41:21,416:INFO:              mlflow: Not installed
2022-11-22 10:41:21,416:INFO:              gradio: Not installed
2022-11-22 10:41:21,416:INFO:             fastapi: Not installed
2022-11-22 10:41:21,416:INFO:             uvicorn: Not installed
2022-11-22 10:41:21,416:INFO:              m2cgen: Not installed
2022-11-22 10:41:21,416:INFO:           evidently: Not installed
2022-11-22 10:41:21,416:INFO:                nltk: 3.6.7
2022-11-22 10:41:21,416:INFO:            pyLDAvis: Not installed
2022-11-22 10:41:21,416:INFO:              gensim: Not installed
2022-11-22 10:41:21,417:INFO:               spacy: Not installed
2022-11-22 10:41:21,417:INFO:           wordcloud: Not installed
2022-11-22 10:41:21,417:INFO:            textblob: Not installed
2022-11-22 10:41:21,417:INFO:               fugue: Not installed
2022-11-22 10:41:21,417:INFO:           streamlit: 1.15.0
2022-11-22 10:41:21,417:INFO:             prophet: Not installed
2022-11-22 10:41:21,417:INFO:None
2022-11-22 10:41:21,417:INFO:Set up data.
2022-11-22 10:41:21,435:INFO:Set up train/test split.
2022-11-22 10:41:21,443:INFO:Set up index.
2022-11-22 10:41:21,444:INFO:Set up folding strategy.
2022-11-22 10:41:21,444:INFO:Assigning column types.
2022-11-22 10:41:21,457:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-22 10:41:21,458:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,461:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,464:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,507:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,538:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,538:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:21,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:21,545:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,548:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,551:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,591:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,621:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,621:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:21,622:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:21,622:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-22 10:41:21,625:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,628:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,668:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,698:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:21,699:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:21,703:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,706:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,745:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:21,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:21,776:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-22 10:41:21,782:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,821:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,852:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,853:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:21,853:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:21,861:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,902:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,934:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 10:41:21,935:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:21,935:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:21,935:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-22 10:41:21,983:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 10:41:22,016:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 10:41:22,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:22,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:22,066:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 10:41:22,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 10:41:22,099:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:22,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:22,099:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-22 10:41:22,147:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 10:41:22,177:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:22,177:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:22,222:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 10:41:22,254:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:22,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:22,255:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-22 10:41:22,342:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:22,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:22,428:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:22,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:22,429:INFO:Preparing preprocessing pipeline...
2022-11-22 10:41:22,430:INFO:Set up simple imputation.
2022-11-22 10:41:22,438:INFO:Set up encoding of categorical features.
2022-11-22 10:41:22,438:INFO:Set up variance threshold.
2022-11-22 10:41:23,071:INFO:Finished creating preprocessing pipeline.
2022-11-22 10:41:23,077:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['year', 'kms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['make', 'model', 'version', 'f...
                                    transformer=LeaveOneOutEncoder(cols=['make',
                                                                         'model',
                                                                         'version',
                                                                         'fuel',
                                                                         'dealer',
                                                                         'province',
                                                                         'publish_date',
                                                                         'insert_date'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=8827,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False)
2022-11-22 10:41:23,077:INFO:Creating final display dataframe.
2022-11-22 10:41:25,099:INFO:Setup display_container:                  Description             Value
0                 Session id              8827
1                     Target             price
2                Target type        Regression
3                 Data shape        (5000, 15)
4           Train data shape        (3499, 15)
5            Test data shape        (1501, 15)
6           Numeric features                 2
7       Categorical features                 9
8   Rows with missing values              0.1%
9                 Preprocess              True
10           Imputation type            simple
11        Numeric imputation              mean
12    Categorical imputation          constant
13  Maximum one-hot encoding                 5
14           Encoding method              None
15    Low variance threshold                 0
16            Fold Generator             KFold
17               Fold Number                10
18                  CPU Jobs                -1
19                   Use GPU             False
20            Log Experiment             False
21           Experiment Name  reg-default-name
22                       USI              b12d
2022-11-22 10:41:25,188:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:25,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:25,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:25,266:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 10:41:25,276:INFO:setup() successfully completed in 3.86s...............
2022-11-22 10:41:46,266:INFO:Initializing compare_models()
2022-11-22 10:41:46,267:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-22 10:41:46,267:INFO:Checking exceptions
2022-11-22 10:41:46,269:INFO:Preparing display monitor
2022-11-22 10:41:46,298:INFO:Initializing Linear Regression
2022-11-22 10:41:46,299:INFO:Total runtime is 2.586841583251953e-06 minutes
2022-11-22 10:41:46,302:INFO:SubProcess create_model() called ==================================
2022-11-22 10:41:46,303:INFO:Initializing create_model()
2022-11-22 10:41:46,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:41:46,303:INFO:Checking exceptions
2022-11-22 10:41:46,304:INFO:Importing libraries
2022-11-22 10:41:46,304:INFO:Copying training dataset
2022-11-22 10:41:46,307:INFO:Defining folds
2022-11-22 10:41:46,307:INFO:Declaring metric variables
2022-11-22 10:41:46,311:INFO:Importing untrained model
2022-11-22 10:41:46,315:INFO:Linear Regression Imported successfully
2022-11-22 10:41:46,320:INFO:Starting cross validation
2022-11-22 10:41:46,325:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:41:51,948:INFO:Calculating mean and std
2022-11-22 10:41:51,950:INFO:Creating metrics dataframe
2022-11-22 10:41:51,954:INFO:Uploading results into container
2022-11-22 10:41:51,955:INFO:Uploading model into container now
2022-11-22 10:41:51,956:INFO:master_model_container: 1
2022-11-22 10:41:51,956:INFO:display_container: 2
2022-11-22 10:41:51,956:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1,
                 normalize='deprecated', positive=False)
2022-11-22 10:41:51,956:INFO:create_model() successfully completed......................................
2022-11-22 10:41:52,097:INFO:SubProcess create_model() end ==================================
2022-11-22 10:41:52,097:INFO:Creating metrics dataframe
2022-11-22 10:41:52,108:INFO:Initializing Lasso Regression
2022-11-22 10:41:52,108:INFO:Total runtime is 0.09682078758875529 minutes
2022-11-22 10:41:52,110:INFO:SubProcess create_model() called ==================================
2022-11-22 10:41:52,110:INFO:Initializing create_model()
2022-11-22 10:41:52,111:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:41:52,111:INFO:Checking exceptions
2022-11-22 10:41:52,112:INFO:Importing libraries
2022-11-22 10:41:52,112:INFO:Copying training dataset
2022-11-22 10:41:52,115:INFO:Defining folds
2022-11-22 10:41:52,115:INFO:Declaring metric variables
2022-11-22 10:41:52,119:INFO:Importing untrained model
2022-11-22 10:41:52,123:INFO:Lasso Regression Imported successfully
2022-11-22 10:41:52,131:INFO:Starting cross validation
2022-11-22 10:41:52,133:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:41:52,559:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.155e+09, tolerance: 7.139e+07
  model = cd_fast.enet_coordinate_descent(

2022-11-22 10:41:52,570:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.860e+10, tolerance: 6.803e+07
  model = cd_fast.enet_coordinate_descent(

2022-11-22 10:41:53,285:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+08, tolerance: 7.024e+07
  model = cd_fast.enet_coordinate_descent(

2022-11-22 10:41:53,496:INFO:Calculating mean and std
2022-11-22 10:41:53,497:INFO:Creating metrics dataframe
2022-11-22 10:41:53,500:INFO:Uploading results into container
2022-11-22 10:41:53,501:INFO:Uploading model into container now
2022-11-22 10:41:53,502:INFO:master_model_container: 2
2022-11-22 10:41:53,502:INFO:display_container: 2
2022-11-22 10:41:53,502:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize='deprecated', positive=False, precompute=False,
      random_state=8827, selection='cyclic', tol=0.0001, warm_start=False)
2022-11-22 10:41:53,502:INFO:create_model() successfully completed......................................
2022-11-22 10:41:53,625:INFO:SubProcess create_model() end ==================================
2022-11-22 10:41:53,625:INFO:Creating metrics dataframe
2022-11-22 10:41:53,640:INFO:Initializing Ridge Regression
2022-11-22 10:41:53,640:INFO:Total runtime is 0.12235519488652546 minutes
2022-11-22 10:41:53,643:INFO:SubProcess create_model() called ==================================
2022-11-22 10:41:53,643:INFO:Initializing create_model()
2022-11-22 10:41:53,643:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:41:53,643:INFO:Checking exceptions
2022-11-22 10:41:53,645:INFO:Importing libraries
2022-11-22 10:41:53,645:INFO:Copying training dataset
2022-11-22 10:41:53,648:INFO:Defining folds
2022-11-22 10:41:53,648:INFO:Declaring metric variables
2022-11-22 10:41:53,652:INFO:Importing untrained model
2022-11-22 10:41:53,657:INFO:Ridge Regression Imported successfully
2022-11-22 10:41:53,663:INFO:Starting cross validation
2022-11-22 10:41:53,665:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:41:54,534:INFO:Calculating mean and std
2022-11-22 10:41:54,536:INFO:Creating metrics dataframe
2022-11-22 10:41:54,539:INFO:Uploading results into container
2022-11-22 10:41:54,539:INFO:Uploading model into container now
2022-11-22 10:41:54,539:INFO:master_model_container: 3
2022-11-22 10:41:54,540:INFO:display_container: 2
2022-11-22 10:41:54,540:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize='deprecated', positive=False, random_state=8827, solver='auto',
      tol=0.001)
2022-11-22 10:41:54,540:INFO:create_model() successfully completed......................................
2022-11-22 10:41:54,661:INFO:SubProcess create_model() end ==================================
2022-11-22 10:41:54,661:INFO:Creating metrics dataframe
2022-11-22 10:41:54,673:INFO:Initializing Elastic Net
2022-11-22 10:41:54,673:INFO:Total runtime is 0.13957357803980508 minutes
2022-11-22 10:41:54,676:INFO:SubProcess create_model() called ==================================
2022-11-22 10:41:54,676:INFO:Initializing create_model()
2022-11-22 10:41:54,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:41:54,677:INFO:Checking exceptions
2022-11-22 10:41:54,679:INFO:Importing libraries
2022-11-22 10:41:54,679:INFO:Copying training dataset
2022-11-22 10:41:54,684:INFO:Defining folds
2022-11-22 10:41:54,684:INFO:Declaring metric variables
2022-11-22 10:41:54,689:INFO:Importing untrained model
2022-11-22 10:41:54,692:INFO:Elastic Net Imported successfully
2022-11-22 10:41:54,700:INFO:Starting cross validation
2022-11-22 10:41:54,701:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:41:55,646:INFO:Calculating mean and std
2022-11-22 10:41:55,647:INFO:Creating metrics dataframe
2022-11-22 10:41:55,650:INFO:Uploading results into container
2022-11-22 10:41:55,651:INFO:Uploading model into container now
2022-11-22 10:41:55,651:INFO:master_model_container: 4
2022-11-22 10:41:55,651:INFO:display_container: 2
2022-11-22 10:41:55,651:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize='deprecated', positive=False,
           precompute=False, random_state=8827, selection='cyclic', tol=0.0001,
           warm_start=False)
2022-11-22 10:41:55,651:INFO:create_model() successfully completed......................................
2022-11-22 10:41:55,773:INFO:SubProcess create_model() end ==================================
2022-11-22 10:41:55,773:INFO:Creating metrics dataframe
2022-11-22 10:41:55,788:INFO:Initializing Least Angle Regression
2022-11-22 10:41:55,790:INFO:Total runtime is 0.15819371541341143 minutes
2022-11-22 10:41:55,794:INFO:SubProcess create_model() called ==================================
2022-11-22 10:41:55,795:INFO:Initializing create_model()
2022-11-22 10:41:55,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:41:55,795:INFO:Checking exceptions
2022-11-22 10:41:55,798:INFO:Importing libraries
2022-11-22 10:41:55,798:INFO:Copying training dataset
2022-11-22 10:41:55,803:INFO:Defining folds
2022-11-22 10:41:55,803:INFO:Declaring metric variables
2022-11-22 10:41:55,806:INFO:Importing untrained model
2022-11-22 10:41:55,811:INFO:Least Angle Regression Imported successfully
2022-11-22 10:41:55,821:INFO:Starting cross validation
2022-11-22 10:41:55,823:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:41:56,172:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:56,191:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:56,212:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:56,235:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:56,256:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:56,272:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:56,272:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:56,406:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:56,622:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:56,629:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:56,730:INFO:Calculating mean and std
2022-11-22 10:41:56,732:INFO:Creating metrics dataframe
2022-11-22 10:41:56,735:INFO:Uploading results into container
2022-11-22 10:41:56,735:INFO:Uploading model into container now
2022-11-22 10:41:56,736:INFO:master_model_container: 5
2022-11-22 10:41:56,736:INFO:display_container: 2
2022-11-22 10:41:56,736:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, normalize='deprecated',
     precompute='auto', random_state=8827, verbose=False)
2022-11-22 10:41:56,736:INFO:create_model() successfully completed......................................
2022-11-22 10:41:56,861:INFO:SubProcess create_model() end ==================================
2022-11-22 10:41:56,861:INFO:Creating metrics dataframe
2022-11-22 10:41:56,873:INFO:Initializing Lasso Least Angle Regression
2022-11-22 10:41:56,873:INFO:Total runtime is 0.17624268531799314 minutes
2022-11-22 10:41:56,877:INFO:SubProcess create_model() called ==================================
2022-11-22 10:41:56,877:INFO:Initializing create_model()
2022-11-22 10:41:56,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:41:56,877:INFO:Checking exceptions
2022-11-22 10:41:56,881:INFO:Importing libraries
2022-11-22 10:41:56,881:INFO:Copying training dataset
2022-11-22 10:41:56,888:INFO:Defining folds
2022-11-22 10:41:56,889:INFO:Declaring metric variables
2022-11-22 10:41:56,894:INFO:Importing untrained model
2022-11-22 10:41:56,900:INFO:Lasso Least Angle Regression Imported successfully
2022-11-22 10:41:56,908:INFO:Starting cross validation
2022-11-22 10:41:56,910:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:41:57,277:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 10:41:57,310:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 10:41:57,354:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 10:41:57,373:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 10:41:57,380:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 10:41:57,404:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 10:41:57,459:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 10:41:57,500:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 10:41:57,804:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 10:41:57,805:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 10:41:57,936:INFO:Calculating mean and std
2022-11-22 10:41:57,937:INFO:Creating metrics dataframe
2022-11-22 10:41:57,940:INFO:Uploading results into container
2022-11-22 10:41:57,940:INFO:Uploading model into container now
2022-11-22 10:41:57,941:INFO:master_model_container: 6
2022-11-22 10:41:57,941:INFO:display_container: 2
2022-11-22 10:41:57,941:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize='deprecated',
          positive=False, precompute='auto', random_state=8827, verbose=False)
2022-11-22 10:41:57,941:INFO:create_model() successfully completed......................................
2022-11-22 10:41:58,086:INFO:SubProcess create_model() end ==================================
2022-11-22 10:41:58,086:INFO:Creating metrics dataframe
2022-11-22 10:41:58,097:INFO:Initializing Orthogonal Matching Pursuit
2022-11-22 10:41:58,097:INFO:Total runtime is 0.19664171536763508 minutes
2022-11-22 10:41:58,100:INFO:SubProcess create_model() called ==================================
2022-11-22 10:41:58,100:INFO:Initializing create_model()
2022-11-22 10:41:58,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:41:58,100:INFO:Checking exceptions
2022-11-22 10:41:58,102:INFO:Importing libraries
2022-11-22 10:41:58,102:INFO:Copying training dataset
2022-11-22 10:41:58,105:INFO:Defining folds
2022-11-22 10:41:58,106:INFO:Declaring metric variables
2022-11-22 10:41:58,109:INFO:Importing untrained model
2022-11-22 10:41:58,112:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-22 10:41:58,119:INFO:Starting cross validation
2022-11-22 10:41:58,120:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:41:58,484:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:58,513:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:58,528:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:58,539:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:58,557:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:58,568:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:58,579:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:58,596:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:58,922:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:58,923:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 10:41:59,025:INFO:Calculating mean and std
2022-11-22 10:41:59,026:INFO:Creating metrics dataframe
2022-11-22 10:41:59,030:INFO:Uploading results into container
2022-11-22 10:41:59,030:INFO:Uploading model into container now
2022-11-22 10:41:59,030:INFO:master_model_container: 7
2022-11-22 10:41:59,030:INFO:display_container: 2
2022-11-22 10:41:59,031:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize='deprecated', precompute='auto', tol=None)
2022-11-22 10:41:59,031:INFO:create_model() successfully completed......................................
2022-11-22 10:41:59,154:INFO:SubProcess create_model() end ==================================
2022-11-22 10:41:59,154:INFO:Creating metrics dataframe
2022-11-22 10:41:59,169:INFO:Initializing Bayesian Ridge
2022-11-22 10:41:59,169:INFO:Total runtime is 0.21450591484705606 minutes
2022-11-22 10:41:59,172:INFO:SubProcess create_model() called ==================================
2022-11-22 10:41:59,173:INFO:Initializing create_model()
2022-11-22 10:41:59,173:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:41:59,173:INFO:Checking exceptions
2022-11-22 10:41:59,175:INFO:Importing libraries
2022-11-22 10:41:59,175:INFO:Copying training dataset
2022-11-22 10:41:59,180:INFO:Defining folds
2022-11-22 10:41:59,181:INFO:Declaring metric variables
2022-11-22 10:41:59,186:INFO:Importing untrained model
2022-11-22 10:41:59,190:INFO:Bayesian Ridge Imported successfully
2022-11-22 10:41:59,201:INFO:Starting cross validation
2022-11-22 10:41:59,217:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:42:00,154:INFO:Calculating mean and std
2022-11-22 10:42:00,155:INFO:Creating metrics dataframe
2022-11-22 10:42:00,158:INFO:Uploading results into container
2022-11-22 10:42:00,158:INFO:Uploading model into container now
2022-11-22 10:42:00,158:INFO:master_model_container: 8
2022-11-22 10:42:00,158:INFO:display_container: 2
2022-11-22 10:42:00,159:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize='deprecated', tol=0.001, verbose=False)
2022-11-22 10:42:00,159:INFO:create_model() successfully completed......................................
2022-11-22 10:42:00,285:INFO:SubProcess create_model() end ==================================
2022-11-22 10:42:00,285:INFO:Creating metrics dataframe
2022-11-22 10:42:00,301:INFO:Initializing Passive Aggressive Regressor
2022-11-22 10:42:00,302:INFO:Total runtime is 0.2333873391151428 minutes
2022-11-22 10:42:00,307:INFO:SubProcess create_model() called ==================================
2022-11-22 10:42:00,307:INFO:Initializing create_model()
2022-11-22 10:42:00,307:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:42:00,307:INFO:Checking exceptions
2022-11-22 10:42:00,310:INFO:Importing libraries
2022-11-22 10:42:00,310:INFO:Copying training dataset
2022-11-22 10:42:00,313:INFO:Defining folds
2022-11-22 10:42:00,314:INFO:Declaring metric variables
2022-11-22 10:42:00,317:INFO:Importing untrained model
2022-11-22 10:42:00,320:INFO:Passive Aggressive Regressor Imported successfully
2022-11-22 10:42:00,328:INFO:Starting cross validation
2022-11-22 10:42:00,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:42:01,234:INFO:Calculating mean and std
2022-11-22 10:42:01,235:INFO:Creating metrics dataframe
2022-11-22 10:42:01,237:INFO:Uploading results into container
2022-11-22 10:42:01,238:INFO:Uploading model into container now
2022-11-22 10:42:01,238:INFO:master_model_container: 9
2022-11-22 10:42:01,238:INFO:display_container: 2
2022-11-22 10:42:01,238:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=8827, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2022-11-22 10:42:01,238:INFO:create_model() successfully completed......................................
2022-11-22 10:42:01,359:INFO:SubProcess create_model() end ==================================
2022-11-22 10:42:01,360:INFO:Creating metrics dataframe
2022-11-22 10:42:01,371:INFO:Initializing Huber Regressor
2022-11-22 10:42:01,371:INFO:Total runtime is 0.25120532512664795 minutes
2022-11-22 10:42:01,374:INFO:SubProcess create_model() called ==================================
2022-11-22 10:42:01,375:INFO:Initializing create_model()
2022-11-22 10:42:01,375:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:42:01,375:INFO:Checking exceptions
2022-11-22 10:42:01,377:INFO:Importing libraries
2022-11-22 10:42:01,377:INFO:Copying training dataset
2022-11-22 10:42:01,382:INFO:Defining folds
2022-11-22 10:42:01,382:INFO:Declaring metric variables
2022-11-22 10:42:01,386:INFO:Importing untrained model
2022-11-22 10:42:01,390:INFO:Huber Regressor Imported successfully
2022-11-22 10:42:01,399:INFO:Starting cross validation
2022-11-22 10:42:01,401:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:42:01,834:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 10:42:01,860:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 10:42:01,860:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 10:42:01,880:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 10:42:01,890:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 10:42:01,933:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 10:42:01,971:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 10:42:01,974:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 10:42:02,305:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 10:42:02,319:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 10:42:02,412:INFO:Calculating mean and std
2022-11-22 10:42:02,415:INFO:Creating metrics dataframe
2022-11-22 10:42:02,418:INFO:Uploading results into container
2022-11-22 10:42:02,418:INFO:Uploading model into container now
2022-11-22 10:42:02,418:INFO:master_model_container: 10
2022-11-22 10:42:02,418:INFO:display_container: 2
2022-11-22 10:42:02,419:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2022-11-22 10:42:02,419:INFO:create_model() successfully completed......................................
2022-11-22 10:42:02,569:INFO:SubProcess create_model() end ==================================
2022-11-22 10:42:02,569:INFO:Creating metrics dataframe
2022-11-22 10:42:02,578:INFO:Initializing K Neighbors Regressor
2022-11-22 10:42:02,579:INFO:Total runtime is 0.2713359475135803 minutes
2022-11-22 10:42:02,581:INFO:SubProcess create_model() called ==================================
2022-11-22 10:42:02,582:INFO:Initializing create_model()
2022-11-22 10:42:02,582:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:42:02,582:INFO:Checking exceptions
2022-11-22 10:42:02,584:INFO:Importing libraries
2022-11-22 10:42:02,584:INFO:Copying training dataset
2022-11-22 10:42:02,586:INFO:Defining folds
2022-11-22 10:42:02,587:INFO:Declaring metric variables
2022-11-22 10:42:02,589:INFO:Importing untrained model
2022-11-22 10:42:02,594:INFO:K Neighbors Regressor Imported successfully
2022-11-22 10:42:02,600:INFO:Starting cross validation
2022-11-22 10:42:02,602:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:42:03,561:INFO:Calculating mean and std
2022-11-22 10:42:03,563:INFO:Creating metrics dataframe
2022-11-22 10:42:03,565:INFO:Uploading results into container
2022-11-22 10:42:03,566:INFO:Uploading model into container now
2022-11-22 10:42:03,566:INFO:master_model_container: 11
2022-11-22 10:42:03,566:INFO:display_container: 2
2022-11-22 10:42:03,566:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2022-11-22 10:42:03,566:INFO:create_model() successfully completed......................................
2022-11-22 10:42:03,717:INFO:SubProcess create_model() end ==================================
2022-11-22 10:42:03,717:INFO:Creating metrics dataframe
2022-11-22 10:42:03,729:INFO:Initializing Decision Tree Regressor
2022-11-22 10:42:03,729:INFO:Total runtime is 0.2905131419499715 minutes
2022-11-22 10:42:03,732:INFO:SubProcess create_model() called ==================================
2022-11-22 10:42:03,732:INFO:Initializing create_model()
2022-11-22 10:42:03,732:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:42:03,732:INFO:Checking exceptions
2022-11-22 10:42:03,734:INFO:Importing libraries
2022-11-22 10:42:03,734:INFO:Copying training dataset
2022-11-22 10:42:03,737:INFO:Defining folds
2022-11-22 10:42:03,737:INFO:Declaring metric variables
2022-11-22 10:42:03,740:INFO:Importing untrained model
2022-11-22 10:42:03,745:INFO:Decision Tree Regressor Imported successfully
2022-11-22 10:42:03,752:INFO:Starting cross validation
2022-11-22 10:42:03,754:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:42:04,734:INFO:Calculating mean and std
2022-11-22 10:42:04,735:INFO:Creating metrics dataframe
2022-11-22 10:42:04,739:INFO:Uploading results into container
2022-11-22 10:42:04,739:INFO:Uploading model into container now
2022-11-22 10:42:04,739:INFO:master_model_container: 12
2022-11-22 10:42:04,739:INFO:display_container: 2
2022-11-22 10:42:04,740:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      random_state=8827, splitter='best')
2022-11-22 10:42:04,740:INFO:create_model() successfully completed......................................
2022-11-22 10:42:04,881:INFO:SubProcess create_model() end ==================================
2022-11-22 10:42:04,881:INFO:Creating metrics dataframe
2022-11-22 10:42:04,891:INFO:Initializing Random Forest Regressor
2022-11-22 10:42:04,892:INFO:Total runtime is 0.3098853349685669 minutes
2022-11-22 10:42:04,895:INFO:SubProcess create_model() called ==================================
2022-11-22 10:42:04,895:INFO:Initializing create_model()
2022-11-22 10:42:04,896:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:42:04,896:INFO:Checking exceptions
2022-11-22 10:42:04,897:INFO:Importing libraries
2022-11-22 10:42:04,897:INFO:Copying training dataset
2022-11-22 10:42:04,900:INFO:Defining folds
2022-11-22 10:42:04,900:INFO:Declaring metric variables
2022-11-22 10:42:04,903:INFO:Importing untrained model
2022-11-22 10:42:04,907:INFO:Random Forest Regressor Imported successfully
2022-11-22 10:42:04,915:INFO:Starting cross validation
2022-11-22 10:42:04,916:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:42:08,717:INFO:Calculating mean and std
2022-11-22 10:42:08,719:INFO:Creating metrics dataframe
2022-11-22 10:42:08,724:INFO:Uploading results into container
2022-11-22 10:42:08,725:INFO:Uploading model into container now
2022-11-22 10:42:08,725:INFO:master_model_container: 13
2022-11-22 10:42:08,725:INFO:display_container: 2
2022-11-22 10:42:08,726:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                      oob_score=False, random_state=8827, verbose=0,
                      warm_start=False)
2022-11-22 10:42:08,726:INFO:create_model() successfully completed......................................
2022-11-22 10:42:08,858:INFO:SubProcess create_model() end ==================================
2022-11-22 10:42:08,858:INFO:Creating metrics dataframe
2022-11-22 10:42:08,869:INFO:Initializing Extra Trees Regressor
2022-11-22 10:42:08,869:INFO:Total runtime is 0.37617231607437135 minutes
2022-11-22 10:42:08,872:INFO:SubProcess create_model() called ==================================
2022-11-22 10:42:08,872:INFO:Initializing create_model()
2022-11-22 10:42:08,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:42:08,872:INFO:Checking exceptions
2022-11-22 10:42:08,874:INFO:Importing libraries
2022-11-22 10:42:08,874:INFO:Copying training dataset
2022-11-22 10:42:08,877:INFO:Defining folds
2022-11-22 10:42:08,877:INFO:Declaring metric variables
2022-11-22 10:42:08,880:INFO:Importing untrained model
2022-11-22 10:42:08,883:INFO:Extra Trees Regressor Imported successfully
2022-11-22 10:42:08,891:INFO:Starting cross validation
2022-11-22 10:42:08,892:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:42:11,269:INFO:Calculating mean and std
2022-11-22 10:42:11,271:INFO:Creating metrics dataframe
2022-11-22 10:42:11,274:INFO:Uploading results into container
2022-11-22 10:42:11,274:INFO:Uploading model into container now
2022-11-22 10:42:11,275:INFO:master_model_container: 14
2022-11-22 10:42:11,275:INFO:display_container: 2
2022-11-22 10:42:11,275:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False)
2022-11-22 10:42:11,275:INFO:create_model() successfully completed......................................
2022-11-22 10:42:11,399:INFO:SubProcess create_model() end ==================================
2022-11-22 10:42:11,399:INFO:Creating metrics dataframe
2022-11-22 10:42:11,410:INFO:Initializing AdaBoost Regressor
2022-11-22 10:42:11,411:INFO:Total runtime is 0.41853456099828085 minutes
2022-11-22 10:42:11,413:INFO:SubProcess create_model() called ==================================
2022-11-22 10:42:11,413:INFO:Initializing create_model()
2022-11-22 10:42:11,413:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:42:11,413:INFO:Checking exceptions
2022-11-22 10:42:11,416:INFO:Importing libraries
2022-11-22 10:42:11,416:INFO:Copying training dataset
2022-11-22 10:42:11,420:INFO:Defining folds
2022-11-22 10:42:11,420:INFO:Declaring metric variables
2022-11-22 10:42:11,423:INFO:Importing untrained model
2022-11-22 10:42:11,426:INFO:AdaBoost Regressor Imported successfully
2022-11-22 10:42:11,432:INFO:Starting cross validation
2022-11-22 10:42:11,434:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:42:12,983:INFO:Calculating mean and std
2022-11-22 10:42:12,985:INFO:Creating metrics dataframe
2022-11-22 10:42:12,988:INFO:Uploading results into container
2022-11-22 10:42:12,988:INFO:Uploading model into container now
2022-11-22 10:42:12,988:INFO:master_model_container: 15
2022-11-22 10:42:12,988:INFO:display_container: 2
2022-11-22 10:42:12,989:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=8827)
2022-11-22 10:42:12,989:INFO:create_model() successfully completed......................................
2022-11-22 10:42:13,110:INFO:SubProcess create_model() end ==================================
2022-11-22 10:42:13,110:INFO:Creating metrics dataframe
2022-11-22 10:42:13,122:INFO:Initializing Gradient Boosting Regressor
2022-11-22 10:42:13,122:INFO:Total runtime is 0.4470668037732442 minutes
2022-11-22 10:42:13,125:INFO:SubProcess create_model() called ==================================
2022-11-22 10:42:13,125:INFO:Initializing create_model()
2022-11-22 10:42:13,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:42:13,125:INFO:Checking exceptions
2022-11-22 10:42:13,127:INFO:Importing libraries
2022-11-22 10:42:13,127:INFO:Copying training dataset
2022-11-22 10:42:13,130:INFO:Defining folds
2022-11-22 10:42:13,130:INFO:Declaring metric variables
2022-11-22 10:42:13,134:INFO:Importing untrained model
2022-11-22 10:42:13,138:INFO:Gradient Boosting Regressor Imported successfully
2022-11-22 10:42:13,143:INFO:Starting cross validation
2022-11-22 10:42:13,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:42:15,570:INFO:Calculating mean and std
2022-11-22 10:42:15,572:INFO:Creating metrics dataframe
2022-11-22 10:42:15,574:INFO:Uploading results into container
2022-11-22 10:42:15,575:INFO:Uploading model into container now
2022-11-22 10:42:15,575:INFO:master_model_container: 16
2022-11-22 10:42:15,575:INFO:display_container: 2
2022-11-22 10:42:15,575:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=8827, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-22 10:42:15,576:INFO:create_model() successfully completed......................................
2022-11-22 10:42:15,701:INFO:SubProcess create_model() end ==================================
2022-11-22 10:42:15,701:INFO:Creating metrics dataframe
2022-11-22 10:42:15,712:INFO:Initializing Light Gradient Boosting Machine
2022-11-22 10:42:15,712:INFO:Total runtime is 0.49022461175918575 minutes
2022-11-22 10:42:15,716:INFO:SubProcess create_model() called ==================================
2022-11-22 10:42:15,716:INFO:Initializing create_model()
2022-11-22 10:42:15,716:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:42:15,716:INFO:Checking exceptions
2022-11-22 10:42:15,718:INFO:Importing libraries
2022-11-22 10:42:15,719:INFO:Copying training dataset
2022-11-22 10:42:15,721:INFO:Defining folds
2022-11-22 10:42:15,722:INFO:Declaring metric variables
2022-11-22 10:42:15,724:INFO:Importing untrained model
2022-11-22 10:42:15,728:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-22 10:42:15,734:INFO:Starting cross validation
2022-11-22 10:42:15,736:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:42:16,966:INFO:Calculating mean and std
2022-11-22 10:42:16,967:INFO:Creating metrics dataframe
2022-11-22 10:42:16,970:INFO:Uploading results into container
2022-11-22 10:42:16,970:INFO:Uploading model into container now
2022-11-22 10:42:16,971:INFO:master_model_container: 17
2022-11-22 10:42:16,971:INFO:display_container: 2
2022-11-22 10:42:16,971:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=8827, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-11-22 10:42:16,971:INFO:create_model() successfully completed......................................
2022-11-22 10:42:17,093:INFO:SubProcess create_model() end ==================================
2022-11-22 10:42:17,094:INFO:Creating metrics dataframe
2022-11-22 10:42:17,106:INFO:Initializing Dummy Regressor
2022-11-22 10:42:17,106:INFO:Total runtime is 0.5134607275327047 minutes
2022-11-22 10:42:17,108:INFO:SubProcess create_model() called ==================================
2022-11-22 10:42:17,109:INFO:Initializing create_model()
2022-11-22 10:42:17,109:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54bcb430>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:42:17,109:INFO:Checking exceptions
2022-11-22 10:42:17,112:INFO:Importing libraries
2022-11-22 10:42:17,112:INFO:Copying training dataset
2022-11-22 10:42:17,115:INFO:Defining folds
2022-11-22 10:42:17,116:INFO:Declaring metric variables
2022-11-22 10:42:17,118:INFO:Importing untrained model
2022-11-22 10:42:17,121:INFO:Dummy Regressor Imported successfully
2022-11-22 10:42:17,127:INFO:Starting cross validation
2022-11-22 10:42:17,128:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:42:18,110:INFO:Calculating mean and std
2022-11-22 10:42:18,113:INFO:Creating metrics dataframe
2022-11-22 10:42:18,116:INFO:Uploading results into container
2022-11-22 10:42:18,116:INFO:Uploading model into container now
2022-11-22 10:42:18,117:INFO:master_model_container: 18
2022-11-22 10:42:18,117:INFO:display_container: 2
2022-11-22 10:42:18,117:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2022-11-22 10:42:18,117:INFO:create_model() successfully completed......................................
2022-11-22 10:42:18,261:INFO:SubProcess create_model() end ==================================
2022-11-22 10:42:18,261:INFO:Creating metrics dataframe
2022-11-22 10:42:18,283:INFO:Initializing create_model()
2022-11-22 10:42:18,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:42:18,283:INFO:Checking exceptions
2022-11-22 10:42:18,287:INFO:Importing libraries
2022-11-22 10:42:18,287:INFO:Copying training dataset
2022-11-22 10:42:18,289:INFO:Defining folds
2022-11-22 10:42:18,289:INFO:Declaring metric variables
2022-11-22 10:42:18,289:INFO:Importing untrained model
2022-11-22 10:42:18,289:INFO:Declaring custom model
2022-11-22 10:42:18,290:INFO:Extra Trees Regressor Imported successfully
2022-11-22 10:42:18,291:INFO:Cross validation set to False
2022-11-22 10:42:18,291:INFO:Fitting Model
2022-11-22 10:42:19,015:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False)
2022-11-22 10:42:19,016:INFO:create_model() successfully completed......................................
2022-11-22 10:42:19,176:INFO:master_model_container: 18
2022-11-22 10:42:19,177:INFO:display_container: 2
2022-11-22 10:42:19,177:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False)
2022-11-22 10:42:19,177:INFO:compare_models() successfully completed......................................
2022-11-22 10:42:58,854:INFO:Initializing create_model()
2022-11-22 10:42:58,854:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:42:58,854:INFO:Checking exceptions
2022-11-22 10:42:58,879:INFO:Importing libraries
2022-11-22 10:42:58,879:INFO:Copying training dataset
2022-11-22 10:42:58,882:INFO:Defining folds
2022-11-22 10:42:58,882:INFO:Declaring metric variables
2022-11-22 10:42:58,886:INFO:Importing untrained model
2022-11-22 10:42:58,889:INFO:Extra Trees Regressor Imported successfully
2022-11-22 10:42:58,896:INFO:Starting cross validation
2022-11-22 10:42:58,899:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:43:01,027:INFO:Calculating mean and std
2022-11-22 10:43:01,029:INFO:Creating metrics dataframe
2022-11-22 10:43:01,034:INFO:Finalizing model
2022-11-22 10:43:01,354:INFO:Uploading results into container
2022-11-22 10:43:01,355:INFO:Uploading model into container now
2022-11-22 10:43:01,365:INFO:master_model_container: 19
2022-11-22 10:43:01,366:INFO:display_container: 3
2022-11-22 10:43:01,366:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False)
2022-11-22 10:43:01,366:INFO:create_model() successfully completed......................................
2022-11-22 10:43:01,496:INFO:Initializing tune_model()
2022-11-22 10:43:01,496:INFO:tune_model(estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>)
2022-11-22 10:43:01,496:INFO:Checking exceptions
2022-11-22 10:43:01,515:INFO:Copying training dataset
2022-11-22 10:43:01,519:INFO:Checking base model
2022-11-22 10:43:01,519:INFO:Base model : Extra Trees Regressor
2022-11-22 10:43:01,522:INFO:Declaring metric variables
2022-11-22 10:43:01,525:INFO:Defining Hyperparameters
2022-11-22 10:43:01,657:INFO:Tuning with n_jobs=-1
2022-11-22 10:43:01,657:INFO:Initializing RandomizedSearchCV
2022-11-22 10:43:02,011:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:02,032:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:02,036:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:02,048:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:02,051:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:02,052:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:02,063:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:02,135:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:08,737:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:08,965:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:08,968:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:09,025:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:09,080:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:09,180:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:09,281:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:09,591:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:10,292:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:10,655:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:10,757:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:10,800:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:11,066:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:11,295:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:11,810:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:11,912:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:11,917:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:12,040:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:12,393:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:12,418:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:12,700:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:12,705:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:13,388:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:13,476:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:13,553:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:13,572:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:13,921:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:14,610:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:15,423:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:16,034:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:21,582:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:21,682:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:21,905:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:22,039:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:22,438:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:22,833:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:23,692:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:24,259:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:24,747:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:25,086:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:25,527:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:25,839:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:26,015:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:26,960:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:27,082:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:27,110:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:27,218:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:27,316:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:27,347:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:27,408:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:27,488:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:28,048:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:43:28,422:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:28,424:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:28,454:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:28,806:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:28,873:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:28,896:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:28,913:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:29,434:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:29,548:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:29,599:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:29,649:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:29,859:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:29,945:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:30,073:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:30,253:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:30,461:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:31,795:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:32,765:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:43,766:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:44,131:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:44,640:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:44,854:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:45,187:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:45,837:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:49,510:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:43:51,680:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:44:02,325:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:44:04,005:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:44:17,550:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:44:18,967:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-11-22 10:44:21,599:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:22,930:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:24,427:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:26,589:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:26,953:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:28,009:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:29,442:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:31,090:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:31,360:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:31,804:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:35,926:INFO:best_params: {'actual_estimator__n_estimators': 180, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': True}
2022-11-22 10:44:35,927:INFO:Hyperparameter search completed
2022-11-22 10:44:35,928:INFO:SubProcess create_model() called ==================================
2022-11-22 10:44:35,928:INFO:Initializing create_model()
2022-11-22 10:44:35,929:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad55531a80>, model_only=True, return_train_score=False, kwargs={'n_estimators': 180, 'min_samples_split': 9, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.002, 'max_features': 1.0, 'max_depth': 11, 'criterion': 'mse', 'bootstrap': True})
2022-11-22 10:44:35,929:INFO:Checking exceptions
2022-11-22 10:44:35,931:INFO:Importing libraries
2022-11-22 10:44:35,931:INFO:Copying training dataset
2022-11-22 10:44:35,933:INFO:Defining folds
2022-11-22 10:44:35,934:INFO:Declaring metric variables
2022-11-22 10:44:35,936:INFO:Importing untrained model
2022-11-22 10:44:35,936:INFO:Declaring custom model
2022-11-22 10:44:35,940:INFO:Extra Trees Regressor Imported successfully
2022-11-22 10:44:35,947:INFO:Starting cross validation
2022-11-22 10:44:35,948:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:44:36,344:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:36,415:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:36,444:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:36,464:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:36,467:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:36,483:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:36,510:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:36,622:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:37,961:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:37,976:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:38,467:INFO:Calculating mean and std
2022-11-22 10:44:38,469:INFO:Creating metrics dataframe
2022-11-22 10:44:38,478:INFO:Finalizing model
2022-11-22 10:44:38,686:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-11-22 10:44:38,933:INFO:Uploading results into container
2022-11-22 10:44:38,933:INFO:Uploading model into container now
2022-11-22 10:44:38,934:INFO:master_model_container: 20
2022-11-22 10:44:38,934:INFO:display_container: 4
2022-11-22 10:44:38,935:INFO:ExtraTreesRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                    max_depth=11, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.002,
                    min_samples_leaf=2, min_samples_split=9,
                    min_weight_fraction_leaf=0.0, n_estimators=180, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False)
2022-11-22 10:44:38,935:INFO:create_model() successfully completed......................................
2022-11-22 10:44:39,067:INFO:SubProcess create_model() end ==================================
2022-11-22 10:44:39,067:INFO:choose_better activated
2022-11-22 10:44:39,072:INFO:SubProcess create_model() called ==================================
2022-11-22 10:44:39,073:INFO:Initializing create_model()
2022-11-22 10:44:39,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 10:44:39,073:INFO:Checking exceptions
2022-11-22 10:44:39,076:INFO:Importing libraries
2022-11-22 10:44:39,077:INFO:Copying training dataset
2022-11-22 10:44:39,079:INFO:Defining folds
2022-11-22 10:44:39,079:INFO:Declaring metric variables
2022-11-22 10:44:39,079:INFO:Importing untrained model
2022-11-22 10:44:39,079:INFO:Declaring custom model
2022-11-22 10:44:39,080:INFO:Extra Trees Regressor Imported successfully
2022-11-22 10:44:39,080:INFO:Starting cross validation
2022-11-22 10:44:39,081:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 10:44:41,993:INFO:Calculating mean and std
2022-11-22 10:44:41,994:INFO:Creating metrics dataframe
2022-11-22 10:44:41,996:INFO:Finalizing model
2022-11-22 10:44:42,343:INFO:Uploading results into container
2022-11-22 10:44:42,344:INFO:Uploading model into container now
2022-11-22 10:44:42,344:INFO:master_model_container: 21
2022-11-22 10:44:42,344:INFO:display_container: 5
2022-11-22 10:44:42,345:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False)
2022-11-22 10:44:42,345:INFO:create_model() successfully completed......................................
2022-11-22 10:44:42,452:INFO:SubProcess create_model() end ==================================
2022-11-22 10:44:42,453:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False) result for R2 is 0.6928
2022-11-22 10:44:42,454:INFO:ExtraTreesRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                    max_depth=11, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.002,
                    min_samples_leaf=2, min_samples_split=9,
                    min_weight_fraction_leaf=0.0, n_estimators=180, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False) result for R2 is 0.709
2022-11-22 10:44:42,454:INFO:ExtraTreesRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                    max_depth=11, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.002,
                    min_samples_leaf=2, min_samples_split=9,
                    min_weight_fraction_leaf=0.0, n_estimators=180, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False) is best model
2022-11-22 10:44:42,454:INFO:choose_better completed
2022-11-22 10:44:42,463:INFO:master_model_container: 21
2022-11-22 10:44:42,463:INFO:display_container: 4
2022-11-22 10:44:42,463:INFO:ExtraTreesRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                    max_depth=11, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.002,
                    min_samples_leaf=2, min_samples_split=9,
                    min_weight_fraction_leaf=0.0, n_estimators=180, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False)
2022-11-22 10:44:42,463:INFO:tune_model() successfully completed......................................
2022-11-22 10:45:17,293:INFO:Initializing plot_model()
2022-11-22 10:45:17,294:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                    max_depth=11, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.002,
                    min_samples_leaf=2, min_samples_split=9,
                    min_weight_fraction_leaf=0.0, n_estimators=180, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, system=True)
2022-11-22 10:45:17,294:INFO:Checking exceptions
2022-11-22 10:45:17,315:INFO:Preloading libraries
2022-11-22 10:45:17,329:INFO:Copying training dataset
2022-11-22 10:45:17,329:INFO:Plot type: residuals
2022-11-22 10:45:17,968:INFO:Fitting Model
2022-11-22 10:45:17,968:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2022-11-22 10:45:18,049:INFO:Scoring test/hold-out set
2022-11-22 10:45:18,479:INFO:Visual Rendered Successfully
2022-11-22 10:45:18,610:INFO:plot_model() successfully completed......................................
2022-11-22 10:46:07,707:INFO:Initializing plot_model()
2022-11-22 10:46:07,707:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, system=True)
2022-11-22 10:46:07,707:INFO:Checking exceptions
2022-11-22 10:46:07,724:INFO:Preloading libraries
2022-11-22 10:46:07,767:INFO:Copying training dataset
2022-11-22 10:46:07,767:INFO:Plot type: residuals
2022-11-22 10:46:08,276:INFO:Fitting Model
2022-11-22 10:46:08,276:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2022-11-22 10:46:08,340:INFO:Scoring test/hold-out set
2022-11-22 10:46:08,628:INFO:Visual Rendered Successfully
2022-11-22 10:46:08,765:INFO:plot_model() successfully completed......................................
2022-11-22 10:49:00,520:INFO:Initializing save_model()
2022-11-22 10:49:00,521:INFO:save_model(model=ExtraTreesRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                    max_depth=11, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.002,
                    min_samples_leaf=2, min_samples_split=9,
                    min_weight_fraction_leaf=0.0, n_estimators=180, n_jobs=-1,
                    oob_score=False, random_state=8827, verbose=0,
                    warm_start=False), model_name=Et_model, prep_pipe_=Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['year', 'kms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['make', 'model', 'version', 'f...
                                    transformer=LeaveOneOutEncoder(cols=['make',
                                                                         'model',
                                                                         'version',
                                                                         'fuel',
                                                                         'dealer',
                                                                         'province',
                                                                         'publish_date',
                                                                         'insert_date'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=8827,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2022-11-22 10:49:00,521:INFO:Adding model into prep_pipe
2022-11-22 10:49:00,592:INFO:Et_model.pkl saved in current working directory
2022-11-22 10:49:00,601:INFO:Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['year', 'kms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['make', 'model', 'version', 'f...
                ('trained_model',
                 ExtraTreesRegressor(bootstrap=True, ccp_alpha=0.0,
                                     criterion='mse', max_depth=11,
                                     max_features=1.0, max_leaf_nodes=None,
                                     max_samples=None,
                                     min_impurity_decrease=0.002,
                                     min_samples_leaf=2, min_samples_split=9,
                                     min_weight_fraction_leaf=0.0,
                                     n_estimators=180, n_jobs=-1,
                                     oob_score=False, random_state=8827,
                                     verbose=0, warm_start=False))],
         verbose=False)
2022-11-22 10:49:00,601:INFO:save_model() successfully completed......................................
2022-11-22 10:56:45,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 10:56:45,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 10:56:45,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 10:56:45,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 10:56:45,657:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-11-22 10:56:46,041:INFO:Initializing load_model()
2022-11-22 10:56:46,041:INFO:load_model(model_name=Et_coches, platform=None, authentication=None, verbose=True)
2022-11-22 10:57:14,238:INFO:Initializing load_model()
2022-11-22 10:57:14,238:INFO:load_model(model_name=Et_model, platform=None, authentication=None, verbose=True)
2022-11-22 10:59:19,993:INFO:Initializing load_model()
2022-11-22 10:59:19,993:INFO:load_model(model_name=Et_model, platform=None, authentication=None, verbose=True)
2022-11-22 10:59:52,535:INFO:Initializing load_model()
2022-11-22 10:59:52,535:INFO:load_model(model_name=Et_model, platform=None, authentication=None, verbose=True)
2022-11-22 11:00:14,285:INFO:Initializing load_model()
2022-11-22 11:00:14,285:INFO:load_model(model_name=Et_model, platform=None, authentication=None, verbose=True)
2022-11-22 11:02:25,115:INFO:Initializing load_model()
2022-11-22 11:02:25,115:INFO:load_model(model_name=Et_model, platform=None, authentication=None, verbose=True)
2022-11-22 11:03:00,323:INFO:Initializing load_model()
2022-11-22 11:03:00,323:INFO:load_model(model_name=Et_model, platform=None, authentication=None, verbose=True)
2022-11-22 11:03:00,365:INFO:Initializing predict_model()
2022-11-22 11:03:00,366:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc67e588100>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc69ee232e0>)
2022-11-22 11:03:00,366:INFO:Checking exceptions
2022-11-22 11:03:00,366:INFO:Preloading libraries
2022-11-22 11:05:51,046:INFO:Initializing load_model()
2022-11-22 11:05:51,046:INFO:load_model(model_name=Et_model, platform=None, authentication=None, verbose=True)
2022-11-22 11:05:51,085:INFO:Initializing predict_model()
2022-11-22 11:05:51,085:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc69ec43a60>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc67e9672e0>)
2022-11-22 11:05:51,086:INFO:Checking exceptions
2022-11-22 11:05:51,086:INFO:Preloading libraries
2022-11-22 11:07:54,218:INFO:Initializing load_model()
2022-11-22 11:07:54,218:INFO:load_model(model_name=Et_model, platform=None, authentication=None, verbose=True)
2022-11-22 11:07:54,259:INFO:Initializing predict_model()
2022-11-22 11:07:54,260:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc67f48d4b0>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc69ee237f0>)
2022-11-22 11:07:54,260:INFO:Checking exceptions
2022-11-22 11:07:54,260:INFO:Preloading libraries
2022-11-22 11:09:08,129:INFO:Initializing create_model()
2022-11-22 11:09:08,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=gbr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:09:08,130:INFO:Checking exceptions
2022-11-22 11:09:08,157:INFO:Importing libraries
2022-11-22 11:09:08,158:INFO:Copying training dataset
2022-11-22 11:09:08,163:INFO:Defining folds
2022-11-22 11:09:08,163:INFO:Declaring metric variables
2022-11-22 11:09:08,166:INFO:Importing untrained model
2022-11-22 11:09:08,170:INFO:Gradient Boosting Regressor Imported successfully
2022-11-22 11:09:08,178:INFO:Starting cross validation
2022-11-22 11:09:08,180:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:09:12,681:INFO:Calculating mean and std
2022-11-22 11:09:12,683:INFO:Creating metrics dataframe
2022-11-22 11:09:12,690:INFO:Finalizing model
2022-11-22 11:09:13,391:INFO:Uploading results into container
2022-11-22 11:09:13,392:INFO:Uploading model into container now
2022-11-22 11:09:13,402:INFO:master_model_container: 22
2022-11-22 11:09:13,402:INFO:display_container: 5
2022-11-22 11:09:13,402:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=8827, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-22 11:09:13,402:INFO:create_model() successfully completed......................................
2022-11-22 11:09:13,548:INFO:Initializing tune_model()
2022-11-22 11:09:13,548:INFO:tune_model(estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=8827, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>)
2022-11-22 11:09:13,548:INFO:Checking exceptions
2022-11-22 11:09:13,567:INFO:Copying training dataset
2022-11-22 11:09:13,571:INFO:Checking base model
2022-11-22 11:09:13,571:INFO:Base model : Gradient Boosting Regressor
2022-11-22 11:09:13,574:INFO:Declaring metric variables
2022-11-22 11:09:13,578:INFO:Defining Hyperparameters
2022-11-22 11:09:13,714:INFO:Tuning with n_jobs=-1
2022-11-22 11:09:13,714:INFO:Initializing RandomizedSearchCV
2022-11-22 11:09:31,086:INFO:best_params: {'actual_estimator__subsample': 0.95, 'actual_estimator__n_estimators': 280, 'actual_estimator__min_samples_split': 4, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.01, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 1, 'actual_estimator__learning_rate': 0.15}
2022-11-22 11:09:31,087:INFO:Hyperparameter search completed
2022-11-22 11:09:31,087:INFO:SubProcess create_model() called ==================================
2022-11-22 11:09:31,088:INFO:Initializing create_model()
2022-11-22 11:09:31,088:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=8827, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad55531c00>, model_only=True, return_train_score=False, kwargs={'subsample': 0.95, 'n_estimators': 280, 'min_samples_split': 4, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.01, 'max_features': 'sqrt', 'max_depth': 1, 'learning_rate': 0.15})
2022-11-22 11:09:31,088:INFO:Checking exceptions
2022-11-22 11:09:31,089:INFO:Importing libraries
2022-11-22 11:09:31,089:INFO:Copying training dataset
2022-11-22 11:09:31,091:INFO:Defining folds
2022-11-22 11:09:31,092:INFO:Declaring metric variables
2022-11-22 11:09:31,095:INFO:Importing untrained model
2022-11-22 11:09:31,095:INFO:Declaring custom model
2022-11-22 11:09:31,098:INFO:Gradient Boosting Regressor Imported successfully
2022-11-22 11:09:31,103:INFO:Starting cross validation
2022-11-22 11:09:31,104:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:09:32,633:INFO:Calculating mean and std
2022-11-22 11:09:32,634:INFO:Creating metrics dataframe
2022-11-22 11:09:32,639:INFO:Finalizing model
2022-11-22 11:09:33,025:INFO:Uploading results into container
2022-11-22 11:09:33,026:INFO:Uploading model into container now
2022-11-22 11:09:33,026:INFO:master_model_container: 23
2022-11-22 11:09:33,026:INFO:display_container: 6
2022-11-22 11:09:33,027:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.15, loss='squared_error',
                          max_depth=1, max_features='sqrt', max_leaf_nodes=None,
                          min_impurity_decrease=0.01, min_samples_leaf=4,
                          min_samples_split=4, min_weight_fraction_leaf=0.0,
                          n_estimators=280, n_iter_no_change=None,
                          random_state=8827, subsample=0.95, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-22 11:09:33,027:INFO:create_model() successfully completed......................................
2022-11-22 11:09:33,156:INFO:SubProcess create_model() end ==================================
2022-11-22 11:09:33,156:INFO:choose_better activated
2022-11-22 11:09:33,159:INFO:SubProcess create_model() called ==================================
2022-11-22 11:09:33,160:INFO:Initializing create_model()
2022-11-22 11:09:33,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=8827, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:09:33,160:INFO:Checking exceptions
2022-11-22 11:09:33,164:INFO:Importing libraries
2022-11-22 11:09:33,164:INFO:Copying training dataset
2022-11-22 11:09:33,166:INFO:Defining folds
2022-11-22 11:09:33,166:INFO:Declaring metric variables
2022-11-22 11:09:33,166:INFO:Importing untrained model
2022-11-22 11:09:33,167:INFO:Declaring custom model
2022-11-22 11:09:33,167:INFO:Gradient Boosting Regressor Imported successfully
2022-11-22 11:09:33,167:INFO:Starting cross validation
2022-11-22 11:09:33,168:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:09:35,519:INFO:Calculating mean and std
2022-11-22 11:09:35,520:INFO:Creating metrics dataframe
2022-11-22 11:09:35,522:INFO:Finalizing model
2022-11-22 11:09:36,260:INFO:Uploading results into container
2022-11-22 11:09:36,261:INFO:Uploading model into container now
2022-11-22 11:09:36,261:INFO:master_model_container: 24
2022-11-22 11:09:36,261:INFO:display_container: 7
2022-11-22 11:09:36,261:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=8827, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-22 11:09:36,261:INFO:create_model() successfully completed......................................
2022-11-22 11:09:36,385:INFO:SubProcess create_model() end ==================================
2022-11-22 11:09:36,386:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=8827, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) result for R2 is 0.5996
2022-11-22 11:09:36,386:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.15, loss='squared_error',
                          max_depth=1, max_features='sqrt', max_leaf_nodes=None,
                          min_impurity_decrease=0.01, min_samples_leaf=4,
                          min_samples_split=4, min_weight_fraction_leaf=0.0,
                          n_estimators=280, n_iter_no_change=None,
                          random_state=8827, subsample=0.95, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) result for R2 is 0.622
2022-11-22 11:09:36,387:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.15, loss='squared_error',
                          max_depth=1, max_features='sqrt', max_leaf_nodes=None,
                          min_impurity_decrease=0.01, min_samples_leaf=4,
                          min_samples_split=4, min_weight_fraction_leaf=0.0,
                          n_estimators=280, n_iter_no_change=None,
                          random_state=8827, subsample=0.95, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) is best model
2022-11-22 11:09:36,387:INFO:choose_better completed
2022-11-22 11:09:36,396:INFO:master_model_container: 24
2022-11-22 11:09:36,397:INFO:display_container: 6
2022-11-22 11:09:36,397:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.15, loss='squared_error',
                          max_depth=1, max_features='sqrt', max_leaf_nodes=None,
                          min_impurity_decrease=0.01, min_samples_leaf=4,
                          min_samples_split=4, min_weight_fraction_leaf=0.0,
                          n_estimators=280, n_iter_no_change=None,
                          random_state=8827, subsample=0.95, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-22 11:09:36,397:INFO:tune_model() successfully completed......................................
2022-11-22 11:09:52,882:INFO:Initializing plot_model()
2022-11-22 11:09:52,883:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.15, loss='squared_error',
                          max_depth=1, max_features='sqrt', max_leaf_nodes=None,
                          min_impurity_decrease=0.01, min_samples_leaf=4,
                          min_samples_split=4, min_weight_fraction_leaf=0.0,
                          n_estimators=280, n_iter_no_change=None,
                          random_state=8827, subsample=0.95, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, system=True)
2022-11-22 11:09:52,883:INFO:Checking exceptions
2022-11-22 11:09:52,889:INFO:Preloading libraries
2022-11-22 11:09:52,902:INFO:Copying training dataset
2022-11-22 11:09:52,903:INFO:Plot type: residuals
2022-11-22 11:09:53,437:INFO:Fitting Model
2022-11-22 11:09:53,437:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2022-11-22 11:09:53,469:INFO:Scoring test/hold-out set
2022-11-22 11:09:53,746:INFO:Visual Rendered Successfully
2022-11-22 11:09:53,879:INFO:plot_model() successfully completed......................................
2022-11-22 11:10:01,645:INFO:Initializing plot_model()
2022-11-22 11:10:01,645:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=8827, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad5498d180>, system=True)
2022-11-22 11:10:01,645:INFO:Checking exceptions
2022-11-22 11:10:01,650:INFO:Preloading libraries
2022-11-22 11:10:01,656:INFO:Copying training dataset
2022-11-22 11:10:01,656:INFO:Plot type: residuals
2022-11-22 11:10:02,182:INFO:Fitting Model
2022-11-22 11:10:02,183:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2022-11-22 11:10:02,216:INFO:Scoring test/hold-out set
2022-11-22 11:10:02,477:INFO:Visual Rendered Successfully
2022-11-22 11:10:02,607:INFO:plot_model() successfully completed......................................
2022-11-22 11:10:27,048:INFO:Initializing save_model()
2022-11-22 11:10:27,048:INFO:save_model(model=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.15, loss='squared_error',
                          max_depth=1, max_features='sqrt', max_leaf_nodes=None,
                          min_impurity_decrease=0.01, min_samples_leaf=4,
                          min_samples_split=4, min_weight_fraction_leaf=0.0,
                          n_estimators=280, n_iter_no_change=None,
                          random_state=8827, subsample=0.95, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), model_name=Coches_gbr, prep_pipe_=Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['year', 'kms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['make', 'model', 'version', 'f...
                                    transformer=LeaveOneOutEncoder(cols=['make',
                                                                         'model',
                                                                         'version',
                                                                         'fuel',
                                                                         'dealer',
                                                                         'province',
                                                                         'publish_date',
                                                                         'insert_date'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=8827,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2022-11-22 11:10:27,048:INFO:Adding model into prep_pipe
2022-11-22 11:10:27,065:INFO:Coches_gbr.pkl saved in current working directory
2022-11-22 11:10:27,073:INFO:Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['year', 'kms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['make', 'model', 'version', 'f...
                                           criterion='friedman_mse', init=None,
                                           learning_rate=0.15,
                                           loss='squared_error', max_depth=1,
                                           max_features='sqrt',
                                           max_leaf_nodes=None,
                                           min_impurity_decrease=0.01,
                                           min_samples_leaf=4,
                                           min_samples_split=4,
                                           min_weight_fraction_leaf=0.0,
                                           n_estimators=280,
                                           n_iter_no_change=None,
                                           random_state=8827, subsample=0.95,
                                           tol=0.0001, validation_fraction=0.1,
                                           verbose=0, warm_start=False))],
         verbose=False)
2022-11-22 11:10:27,073:INFO:save_model() successfully completed......................................
2022-11-22 11:11:03,074:INFO:Initializing load_model()
2022-11-22 11:11:03,075:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:11:03,091:INFO:Initializing predict_model()
2022-11-22 11:11:03,092:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc67e58a950>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc68c6fd090>)
2022-11-22 11:11:03,092:INFO:Checking exceptions
2022-11-22 11:11:03,093:INFO:Preloading libraries
2022-11-22 11:13:32,628:INFO:Initializing load_model()
2022-11-22 11:13:32,629:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:13:32,646:INFO:Initializing predict_model()
2022-11-22 11:13:32,646:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc69ecda7d0>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc67e966dd0>)
2022-11-22 11:13:32,646:INFO:Checking exceptions
2022-11-22 11:13:32,647:INFO:Preloading libraries
2022-11-22 11:15:03,439:INFO:Initializing load_model()
2022-11-22 11:15:03,439:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:15:03,474:INFO:Initializing predict_model()
2022-11-22 11:15:03,474:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc67e9ee6e0>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc67e966ef0>)
2022-11-22 11:15:03,474:INFO:Checking exceptions
2022-11-22 11:15:03,475:INFO:Preloading libraries
2022-11-22 11:15:13,510:INFO:Initializing load_model()
2022-11-22 11:15:13,511:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:15:13,557:INFO:Initializing predict_model()
2022-11-22 11:15:13,558:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc69ecd6a40>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc67e966dd0>)
2022-11-22 11:15:13,558:INFO:Checking exceptions
2022-11-22 11:15:13,558:INFO:Preloading libraries
2022-11-22 11:15:14,666:INFO:Initializing load_model()
2022-11-22 11:15:14,667:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:15:14,705:INFO:Initializing predict_model()
2022-11-22 11:15:14,705:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc67f453fa0>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc67e966cb0>)
2022-11-22 11:15:14,705:INFO:Checking exceptions
2022-11-22 11:15:14,706:INFO:Preloading libraries
2022-11-22 11:15:16,480:INFO:Initializing load_model()
2022-11-22 11:15:16,480:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:15:16,516:INFO:Initializing predict_model()
2022-11-22 11:15:16,516:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc69ecd6a70>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc69ee21900>)
2022-11-22 11:15:16,516:INFO:Checking exceptions
2022-11-22 11:15:16,517:INFO:Preloading libraries
2022-11-22 11:15:18,746:INFO:Initializing load_model()
2022-11-22 11:15:18,747:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:15:18,776:INFO:Initializing predict_model()
2022-11-22 11:15:18,776:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc67e9ef6d0>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc67e9672e0>)
2022-11-22 11:15:18,777:INFO:Checking exceptions
2022-11-22 11:15:18,777:INFO:Preloading libraries
2022-11-22 11:15:20,753:INFO:Initializing load_model()
2022-11-22 11:15:20,754:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:15:20,799:INFO:Initializing predict_model()
2022-11-22 11:15:20,799:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc68060d6f0>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc69ee237f0>)
2022-11-22 11:15:20,799:INFO:Checking exceptions
2022-11-22 11:15:20,800:INFO:Preloading libraries
2022-11-22 11:15:21,240:INFO:Initializing load_model()
2022-11-22 11:15:21,241:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:15:21,278:INFO:Initializing predict_model()
2022-11-22 11:15:21,279:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc67e58b3a0>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc69ee21870>)
2022-11-22 11:15:21,279:INFO:Checking exceptions
2022-11-22 11:15:21,280:INFO:Preloading libraries
2022-11-22 11:16:31,110:INFO:Initializing load_model()
2022-11-22 11:16:31,110:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:16:31,149:INFO:Initializing predict_model()
2022-11-22 11:16:31,149:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc680282ec0>, estimator=Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'kms'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['make', 'model', 'version', 'fuel',
                                             'shift', 'dealer', 'province',
                                             'publish_date', 'insert_date'],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='consta...
                                                                   handle_missing='return_nan',
                                                                   random_state=8827))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('trained_model',
                 GradientBoostingRegressor(learning_rate=0.15, max_depth=1,
                                           max_features='sqrt',
                                           min_impurity_decrease=0.01,
                                           min_samples_leaf=4,
                                           min_samples_split=4,
                                           n_estimators=280, random_state=8827,
                                           subsample=0.95))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc69ee235b0>)
2022-11-22 11:16:31,149:INFO:Checking exceptions
2022-11-22 11:16:31,149:INFO:Preloading libraries
2022-11-22 11:16:31,149:INFO:Set up data.
2022-11-22 11:16:31,167:INFO:Set up index.
2022-11-22 11:19:45,091:INFO:Initializing load_model()
2022-11-22 11:19:45,092:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:19:45,122:INFO:Initializing predict_model()
2022-11-22 11:19:45,122:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc67e9f36d0>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc67e0a0280>)
2022-11-22 11:19:45,122:INFO:Checking exceptions
2022-11-22 11:19:45,123:INFO:Preloading libraries
2022-11-22 11:21:34,049:INFO:PyCaret RegressionExperiment
2022-11-22 11:21:34,049:INFO:Logging name: reg-default-name
2022-11-22 11:21:34,049:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-22 11:21:34,049:INFO:version 3.0.0.rc4
2022-11-22 11:21:34,049:INFO:Initializing setup()
2022-11-22 11:21:34,049:INFO:self.USI: fbc7
2022-11-22 11:21:34,049:INFO:self.variable_keys: {'y_test', 'exp_name_log', 'data', 'variable_keys', 'y', 'master_model_container', 'USI', '_all_models_internal', '_ml_usecase', 'memory', '_gpu_n_jobs_param', 'html_param', 'X', 'target_param', '_all_metrics', 'y_train', 'logging_param', 'X_train', 'fold_generator', 'transform_target_param', 'gpu_param', 'X_test', 'idx', 'pipeline', 'seed', '_available_plots', '_all_models', 'exp_id', 'display_container', 'fold_groups_param', 'log_plots_param', 'transform_target_method_param', 'n_jobs_param', 'fold_shuffle_param'}
2022-11-22 11:21:34,049:INFO:Checking environment
2022-11-22 11:21:34,049:INFO:python_version: 3.10.6
2022-11-22 11:21:34,049:INFO:python_build: ('main', 'Nov  2 2022 18:53:38')
2022-11-22 11:21:34,049:INFO:machine: x86_64
2022-11-22 11:21:34,049:INFO:platform: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-22 11:21:34,049:INFO:Memory: svmem(total=7962374144, available=1987047424, percent=75.0, used=4592533504, free=1015894016, active=1821761536, inactive=4291706880, buffers=43278336, cached=2310668288, shared=1066090496, slab=386932736)
2022-11-22 11:21:34,049:INFO:Physical Core: 4
2022-11-22 11:21:34,049:INFO:Logical Core: 8
2022-11-22 11:21:34,050:INFO:Checking libraries
2022-11-22 11:21:34,050:INFO:System:
2022-11-22 11:21:34,050:INFO:    python: 3.10.6 (main, Nov  2 2022, 18:53:38) [GCC 11.3.0]
2022-11-22 11:21:34,050:INFO:executable: /bin/python3
2022-11-22 11:21:34,050:INFO:   machine: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-22 11:21:34,050:INFO:PyCaret required dependencies:
2022-11-22 11:21:34,050:INFO:                 pip: 22.0.2
2022-11-22 11:21:34,050:INFO:          setuptools: 59.6.0
2022-11-22 11:21:34,050:INFO:             pycaret: 3.0.0rc4
2022-11-22 11:21:34,050:INFO:             IPython: 8.6.0
2022-11-22 11:21:34,050:INFO:          ipywidgets: 8.0.2
2022-11-22 11:21:34,050:INFO:                tqdm: 4.64.1
2022-11-22 11:21:34,050:INFO:               numpy: 1.21.4
2022-11-22 11:21:34,050:INFO:              pandas: 1.3.5
2022-11-22 11:21:34,050:INFO:              jinja2: 3.0.3
2022-11-22 11:21:34,050:INFO:               scipy: 1.8.1
2022-11-22 11:21:34,050:INFO:              joblib: 1.2.0
2022-11-22 11:21:34,050:INFO:             sklearn: 1.1.3
2022-11-22 11:21:34,050:INFO:                pyod: 1.0.6
2022-11-22 11:21:34,050:INFO:            imblearn: 0.9.1
2022-11-22 11:21:34,050:INFO:   category_encoders: 2.5.1.post0
2022-11-22 11:21:34,050:INFO:            lightgbm: 3.3.3
2022-11-22 11:21:34,050:INFO:               numba: 0.55.2
2022-11-22 11:21:34,050:INFO:            requests: 2.25.1
2022-11-22 11:21:34,050:INFO:          matplotlib: 3.6.2
2022-11-22 11:21:34,050:INFO:          scikitplot: 0.3.7
2022-11-22 11:21:34,050:INFO:         yellowbrick: 1.5
2022-11-22 11:21:34,050:INFO:              plotly: 5.11.0
2022-11-22 11:21:34,050:INFO:             kaleido: 0.2.1
2022-11-22 11:21:34,050:INFO:         statsmodels: 0.13.5
2022-11-22 11:21:34,050:INFO:              sktime: 0.13.4
2022-11-22 11:21:34,050:INFO:               tbats: 1.1.1
2022-11-22 11:21:34,050:INFO:            pmdarima: 1.8.5
2022-11-22 11:21:34,050:INFO:              psutil: 5.9.0
2022-11-22 11:21:34,050:INFO:PyCaret optional dependencies:
2022-11-22 11:21:34,050:INFO:                shap: Not installed
2022-11-22 11:21:34,050:INFO:           interpret: Not installed
2022-11-22 11:21:34,050:INFO:                umap: Not installed
2022-11-22 11:21:34,050:INFO:    pandas_profiling: Not installed
2022-11-22 11:21:34,050:INFO:  explainerdashboard: Not installed
2022-11-22 11:21:34,051:INFO:             autoviz: Not installed
2022-11-22 11:21:34,051:INFO:           fairlearn: Not installed
2022-11-22 11:21:34,051:INFO:             xgboost: Not installed
2022-11-22 11:21:34,051:INFO:            catboost: Not installed
2022-11-22 11:21:34,051:INFO:              kmodes: Not installed
2022-11-22 11:21:34,051:INFO:             mlxtend: Not installed
2022-11-22 11:21:34,051:INFO:       statsforecast: Not installed
2022-11-22 11:21:34,051:INFO:        tune_sklearn: Not installed
2022-11-22 11:21:34,051:INFO:                 ray: Not installed
2022-11-22 11:21:34,051:INFO:            hyperopt: Not installed
2022-11-22 11:21:34,051:INFO:              optuna: Not installed
2022-11-22 11:21:34,051:INFO:               skopt: Not installed
2022-11-22 11:21:34,051:INFO:              mlflow: Not installed
2022-11-22 11:21:34,051:INFO:              gradio: Not installed
2022-11-22 11:21:34,051:INFO:             fastapi: Not installed
2022-11-22 11:21:34,051:INFO:             uvicorn: Not installed
2022-11-22 11:21:34,051:INFO:              m2cgen: Not installed
2022-11-22 11:21:34,051:INFO:           evidently: Not installed
2022-11-22 11:21:34,051:INFO:                nltk: 3.6.7
2022-11-22 11:21:34,051:INFO:            pyLDAvis: Not installed
2022-11-22 11:21:34,051:INFO:              gensim: Not installed
2022-11-22 11:21:34,051:INFO:               spacy: Not installed
2022-11-22 11:21:34,051:INFO:           wordcloud: Not installed
2022-11-22 11:21:34,051:INFO:            textblob: Not installed
2022-11-22 11:21:34,051:INFO:               fugue: Not installed
2022-11-22 11:21:34,051:INFO:           streamlit: 1.15.0
2022-11-22 11:21:34,051:INFO:             prophet: Not installed
2022-11-22 11:21:34,051:INFO:None
2022-11-22 11:21:34,051:INFO:Set up data.
2022-11-22 11:21:34,060:INFO:Set up train/test split.
2022-11-22 11:21:34,064:INFO:Set up index.
2022-11-22 11:21:34,065:INFO:Set up folding strategy.
2022-11-22 11:21:34,065:INFO:Assigning column types.
2022-11-22 11:21:34,072:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-22 11:21:34,072:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,075:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,079:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,117:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,146:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,147:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,151:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,154:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,195:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,227:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-22 11:21:34,231:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,234:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,278:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,313:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,313:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,314:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,317:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,320:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,363:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,397:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,398:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,398:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-22 11:21:34,405:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,448:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,483:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,491:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,537:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,575:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,576:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-22 11:21:34,627:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,662:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,662:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,662:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,711:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,741:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,742:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,742:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-22 11:21:34,789:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,865:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:21:34,896:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,897:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-22 11:21:34,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:34,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:35,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:35,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:35,084:INFO:Preparing preprocessing pipeline...
2022-11-22 11:21:35,085:INFO:Set up simple imputation.
2022-11-22 11:21:35,085:INFO:Set up variance threshold.
2022-11-22 11:21:35,127:INFO:Finished creating preprocessing pipeline.
2022-11-22 11:21:35,130:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False)
2022-11-22 11:21:35,130:INFO:Creating final display dataframe.
2022-11-22 11:21:35,254:INFO:Setup display_container:                Description             Value
0               Session id              6498
1                   Target             price
2              Target type        Regression
3               Data shape        (5000, 13)
4         Train data shape        (3499, 13)
5          Test data shape        (1501, 13)
6         Numeric features                12
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              fbc7
2022-11-22 11:21:35,353:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:35,354:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:35,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:35,437:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:21:35,443:INFO:setup() successfully completed in 1.4s...............
2022-11-22 11:21:38,393:INFO:Initializing compare_models()
2022-11-22 11:21:38,393:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-22 11:21:38,394:INFO:Checking exceptions
2022-11-22 11:21:38,395:INFO:Preparing display monitor
2022-11-22 11:21:38,424:INFO:Initializing Linear Regression
2022-11-22 11:21:38,424:INFO:Total runtime is 2.6067097981770834e-06 minutes
2022-11-22 11:21:38,427:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:38,427:INFO:Initializing create_model()
2022-11-22 11:21:38,427:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:38,427:INFO:Checking exceptions
2022-11-22 11:21:38,429:INFO:Importing libraries
2022-11-22 11:21:38,430:INFO:Copying training dataset
2022-11-22 11:21:38,433:INFO:Defining folds
2022-11-22 11:21:38,433:INFO:Declaring metric variables
2022-11-22 11:21:38,438:INFO:Importing untrained model
2022-11-22 11:21:38,441:INFO:Linear Regression Imported successfully
2022-11-22 11:21:38,447:INFO:Starting cross validation
2022-11-22 11:21:38,449:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:41,166:INFO:Calculating mean and std
2022-11-22 11:21:41,168:INFO:Creating metrics dataframe
2022-11-22 11:21:41,171:INFO:Uploading results into container
2022-11-22 11:21:41,172:INFO:Uploading model into container now
2022-11-22 11:21:41,172:INFO:master_model_container: 1
2022-11-22 11:21:41,172:INFO:display_container: 2
2022-11-22 11:21:41,173:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1,
                 normalize='deprecated', positive=False)
2022-11-22 11:21:41,173:INFO:create_model() successfully completed......................................
2022-11-22 11:21:41,333:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:41,333:INFO:Creating metrics dataframe
2022-11-22 11:21:41,342:INFO:Initializing Lasso Regression
2022-11-22 11:21:41,343:INFO:Total runtime is 0.04864813089370727 minutes
2022-11-22 11:21:41,345:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:41,346:INFO:Initializing create_model()
2022-11-22 11:21:41,346:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:41,346:INFO:Checking exceptions
2022-11-22 11:21:41,348:INFO:Importing libraries
2022-11-22 11:21:41,348:INFO:Copying training dataset
2022-11-22 11:21:41,351:INFO:Defining folds
2022-11-22 11:21:41,352:INFO:Declaring metric variables
2022-11-22 11:21:41,355:INFO:Importing untrained model
2022-11-22 11:21:41,359:INFO:Lasso Regression Imported successfully
2022-11-22 11:21:41,366:INFO:Starting cross validation
2022-11-22 11:21:41,366:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:41,463:INFO:Calculating mean and std
2022-11-22 11:21:41,465:INFO:Creating metrics dataframe
2022-11-22 11:21:41,468:INFO:Uploading results into container
2022-11-22 11:21:41,468:INFO:Uploading model into container now
2022-11-22 11:21:41,469:INFO:master_model_container: 2
2022-11-22 11:21:41,469:INFO:display_container: 2
2022-11-22 11:21:41,469:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize='deprecated', positive=False, precompute=False,
      random_state=6498, selection='cyclic', tol=0.0001, warm_start=False)
2022-11-22 11:21:41,469:INFO:create_model() successfully completed......................................
2022-11-22 11:21:41,596:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:41,596:INFO:Creating metrics dataframe
2022-11-22 11:21:41,606:INFO:Initializing Ridge Regression
2022-11-22 11:21:41,606:INFO:Total runtime is 0.05303775072097778 minutes
2022-11-22 11:21:41,608:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:41,609:INFO:Initializing create_model()
2022-11-22 11:21:41,609:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:41,609:INFO:Checking exceptions
2022-11-22 11:21:41,611:INFO:Importing libraries
2022-11-22 11:21:41,611:INFO:Copying training dataset
2022-11-22 11:21:41,617:INFO:Defining folds
2022-11-22 11:21:41,617:INFO:Declaring metric variables
2022-11-22 11:21:41,622:INFO:Importing untrained model
2022-11-22 11:21:41,626:INFO:Ridge Regression Imported successfully
2022-11-22 11:21:41,636:INFO:Starting cross validation
2022-11-22 11:21:41,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:41,728:INFO:Calculating mean and std
2022-11-22 11:21:41,730:INFO:Creating metrics dataframe
2022-11-22 11:21:41,733:INFO:Uploading results into container
2022-11-22 11:21:41,733:INFO:Uploading model into container now
2022-11-22 11:21:41,733:INFO:master_model_container: 3
2022-11-22 11:21:41,734:INFO:display_container: 2
2022-11-22 11:21:41,734:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize='deprecated', positive=False, random_state=6498, solver='auto',
      tol=0.001)
2022-11-22 11:21:41,734:INFO:create_model() successfully completed......................................
2022-11-22 11:21:41,859:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:41,859:INFO:Creating metrics dataframe
2022-11-22 11:21:41,870:INFO:Initializing Elastic Net
2022-11-22 11:21:41,870:INFO:Total runtime is 0.057442522048950194 minutes
2022-11-22 11:21:41,873:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:41,873:INFO:Initializing create_model()
2022-11-22 11:21:41,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:41,873:INFO:Checking exceptions
2022-11-22 11:21:41,874:INFO:Importing libraries
2022-11-22 11:21:41,874:INFO:Copying training dataset
2022-11-22 11:21:41,877:INFO:Defining folds
2022-11-22 11:21:41,878:INFO:Declaring metric variables
2022-11-22 11:21:41,882:INFO:Importing untrained model
2022-11-22 11:21:41,885:INFO:Elastic Net Imported successfully
2022-11-22 11:21:41,890:INFO:Starting cross validation
2022-11-22 11:21:41,891:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:41,997:INFO:Calculating mean and std
2022-11-22 11:21:41,998:INFO:Creating metrics dataframe
2022-11-22 11:21:42,001:INFO:Uploading results into container
2022-11-22 11:21:42,002:INFO:Uploading model into container now
2022-11-22 11:21:42,002:INFO:master_model_container: 4
2022-11-22 11:21:42,003:INFO:display_container: 2
2022-11-22 11:21:42,003:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize='deprecated', positive=False,
           precompute=False, random_state=6498, selection='cyclic', tol=0.0001,
           warm_start=False)
2022-11-22 11:21:42,003:INFO:create_model() successfully completed......................................
2022-11-22 11:21:42,124:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:42,124:INFO:Creating metrics dataframe
2022-11-22 11:21:42,135:INFO:Initializing Least Angle Regression
2022-11-22 11:21:42,135:INFO:Total runtime is 0.06185066302617391 minutes
2022-11-22 11:21:42,137:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:42,138:INFO:Initializing create_model()
2022-11-22 11:21:42,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:42,138:INFO:Checking exceptions
2022-11-22 11:21:42,139:INFO:Importing libraries
2022-11-22 11:21:42,139:INFO:Copying training dataset
2022-11-22 11:21:42,142:INFO:Defining folds
2022-11-22 11:21:42,142:INFO:Declaring metric variables
2022-11-22 11:21:42,145:INFO:Importing untrained model
2022-11-22 11:21:42,149:INFO:Least Angle Regression Imported successfully
2022-11-22 11:21:42,155:INFO:Starting cross validation
2022-11-22 11:21:42,156:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:42,180:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,184:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,188:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,197:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,202:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,206:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,220:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,226:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,229:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,232:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,243:INFO:Calculating mean and std
2022-11-22 11:21:42,244:INFO:Creating metrics dataframe
2022-11-22 11:21:42,247:INFO:Uploading results into container
2022-11-22 11:21:42,248:INFO:Uploading model into container now
2022-11-22 11:21:42,248:INFO:master_model_container: 5
2022-11-22 11:21:42,248:INFO:display_container: 2
2022-11-22 11:21:42,248:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, normalize='deprecated',
     precompute='auto', random_state=6498, verbose=False)
2022-11-22 11:21:42,248:INFO:create_model() successfully completed......................................
2022-11-22 11:21:42,370:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:42,370:INFO:Creating metrics dataframe
2022-11-22 11:21:42,380:INFO:Initializing Lasso Least Angle Regression
2022-11-22 11:21:42,380:INFO:Total runtime is 0.06593863964080811 minutes
2022-11-22 11:21:42,382:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:42,383:INFO:Initializing create_model()
2022-11-22 11:21:42,383:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:42,383:INFO:Checking exceptions
2022-11-22 11:21:42,384:INFO:Importing libraries
2022-11-22 11:21:42,384:INFO:Copying training dataset
2022-11-22 11:21:42,387:INFO:Defining folds
2022-11-22 11:21:42,388:INFO:Declaring metric variables
2022-11-22 11:21:42,391:INFO:Importing untrained model
2022-11-22 11:21:42,394:INFO:Lasso Least Angle Regression Imported successfully
2022-11-22 11:21:42,401:INFO:Starting cross validation
2022-11-22 11:21:42,402:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:42,427:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:21:42,431:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:21:42,437:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:21:42,441:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:21:42,453:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:21:42,454:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:21:42,459:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:21:42,466:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:21:42,469:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:21:42,471:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:21:42,480:INFO:Calculating mean and std
2022-11-22 11:21:42,480:INFO:Creating metrics dataframe
2022-11-22 11:21:42,483:INFO:Uploading results into container
2022-11-22 11:21:42,483:INFO:Uploading model into container now
2022-11-22 11:21:42,483:INFO:master_model_container: 6
2022-11-22 11:21:42,483:INFO:display_container: 2
2022-11-22 11:21:42,484:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize='deprecated',
          positive=False, precompute='auto', random_state=6498, verbose=False)
2022-11-22 11:21:42,484:INFO:create_model() successfully completed......................................
2022-11-22 11:21:42,607:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:42,607:INFO:Creating metrics dataframe
2022-11-22 11:21:42,618:INFO:Initializing Orthogonal Matching Pursuit
2022-11-22 11:21:42,618:INFO:Total runtime is 0.06991128524144491 minutes
2022-11-22 11:21:42,621:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:42,621:INFO:Initializing create_model()
2022-11-22 11:21:42,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:42,621:INFO:Checking exceptions
2022-11-22 11:21:42,623:INFO:Importing libraries
2022-11-22 11:21:42,623:INFO:Copying training dataset
2022-11-22 11:21:42,625:INFO:Defining folds
2022-11-22 11:21:42,626:INFO:Declaring metric variables
2022-11-22 11:21:42,629:INFO:Importing untrained model
2022-11-22 11:21:42,632:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-22 11:21:42,640:INFO:Starting cross validation
2022-11-22 11:21:42,641:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:42,664:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,670:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,677:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,681:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,683:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,693:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,701:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,705:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,708:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,709:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:21:42,721:INFO:Calculating mean and std
2022-11-22 11:21:42,721:INFO:Creating metrics dataframe
2022-11-22 11:21:42,724:INFO:Uploading results into container
2022-11-22 11:21:42,724:INFO:Uploading model into container now
2022-11-22 11:21:42,724:INFO:master_model_container: 7
2022-11-22 11:21:42,725:INFO:display_container: 2
2022-11-22 11:21:42,725:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize='deprecated', precompute='auto', tol=None)
2022-11-22 11:21:42,725:INFO:create_model() successfully completed......................................
2022-11-22 11:21:42,848:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:42,848:INFO:Creating metrics dataframe
2022-11-22 11:21:42,858:INFO:Initializing Bayesian Ridge
2022-11-22 11:21:42,858:INFO:Total runtime is 0.07391119003295898 minutes
2022-11-22 11:21:42,861:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:42,862:INFO:Initializing create_model()
2022-11-22 11:21:42,862:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:42,862:INFO:Checking exceptions
2022-11-22 11:21:42,863:INFO:Importing libraries
2022-11-22 11:21:42,863:INFO:Copying training dataset
2022-11-22 11:21:42,866:INFO:Defining folds
2022-11-22 11:21:42,866:INFO:Declaring metric variables
2022-11-22 11:21:42,870:INFO:Importing untrained model
2022-11-22 11:21:42,875:INFO:Bayesian Ridge Imported successfully
2022-11-22 11:21:42,881:INFO:Starting cross validation
2022-11-22 11:21:42,882:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:42,967:INFO:Calculating mean and std
2022-11-22 11:21:42,968:INFO:Creating metrics dataframe
2022-11-22 11:21:42,971:INFO:Uploading results into container
2022-11-22 11:21:42,971:INFO:Uploading model into container now
2022-11-22 11:21:42,972:INFO:master_model_container: 8
2022-11-22 11:21:42,972:INFO:display_container: 2
2022-11-22 11:21:42,972:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize='deprecated', tol=0.001, verbose=False)
2022-11-22 11:21:42,972:INFO:create_model() successfully completed......................................
2022-11-22 11:21:43,101:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:43,101:INFO:Creating metrics dataframe
2022-11-22 11:21:43,111:INFO:Initializing Passive Aggressive Regressor
2022-11-22 11:21:43,112:INFO:Total runtime is 0.0781335433324178 minutes
2022-11-22 11:21:43,115:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:43,116:INFO:Initializing create_model()
2022-11-22 11:21:43,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:43,116:INFO:Checking exceptions
2022-11-22 11:21:43,118:INFO:Importing libraries
2022-11-22 11:21:43,118:INFO:Copying training dataset
2022-11-22 11:21:43,120:INFO:Defining folds
2022-11-22 11:21:43,120:INFO:Declaring metric variables
2022-11-22 11:21:43,123:INFO:Importing untrained model
2022-11-22 11:21:43,126:INFO:Passive Aggressive Regressor Imported successfully
2022-11-22 11:21:43,134:INFO:Starting cross validation
2022-11-22 11:21:43,135:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:43,236:INFO:Calculating mean and std
2022-11-22 11:21:43,237:INFO:Creating metrics dataframe
2022-11-22 11:21:43,240:INFO:Uploading results into container
2022-11-22 11:21:43,240:INFO:Uploading model into container now
2022-11-22 11:21:43,240:INFO:master_model_container: 9
2022-11-22 11:21:43,240:INFO:display_container: 2
2022-11-22 11:21:43,241:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=6498, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2022-11-22 11:21:43,241:INFO:create_model() successfully completed......................................
2022-11-22 11:21:43,368:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:43,368:INFO:Creating metrics dataframe
2022-11-22 11:21:43,378:INFO:Initializing Huber Regressor
2022-11-22 11:21:43,378:INFO:Total runtime is 0.0825746734937032 minutes
2022-11-22 11:21:43,382:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:43,382:INFO:Initializing create_model()
2022-11-22 11:21:43,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:43,382:INFO:Checking exceptions
2022-11-22 11:21:43,384:INFO:Importing libraries
2022-11-22 11:21:43,384:INFO:Copying training dataset
2022-11-22 11:21:43,387:INFO:Defining folds
2022-11-22 11:21:43,387:INFO:Declaring metric variables
2022-11-22 11:21:43,390:INFO:Importing untrained model
2022-11-22 11:21:43,393:INFO:Huber Regressor Imported successfully
2022-11-22 11:21:43,400:INFO:Starting cross validation
2022-11-22 11:21:43,401:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:43,478:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:21:43,482:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:21:43,484:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:21:43,487:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:21:43,497:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:21:43,507:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:21:43,520:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:21:43,532:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:21:43,542:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:21:43,550:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:21:43,556:INFO:Calculating mean and std
2022-11-22 11:21:43,557:INFO:Creating metrics dataframe
2022-11-22 11:21:43,561:INFO:Uploading results into container
2022-11-22 11:21:43,561:INFO:Uploading model into container now
2022-11-22 11:21:43,562:INFO:master_model_container: 10
2022-11-22 11:21:43,562:INFO:display_container: 2
2022-11-22 11:21:43,562:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2022-11-22 11:21:43,562:INFO:create_model() successfully completed......................................
2022-11-22 11:21:43,686:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:43,686:INFO:Creating metrics dataframe
2022-11-22 11:21:43,696:INFO:Initializing K Neighbors Regressor
2022-11-22 11:21:43,696:INFO:Total runtime is 0.08787843783696492 minutes
2022-11-22 11:21:43,699:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:43,699:INFO:Initializing create_model()
2022-11-22 11:21:43,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:43,699:INFO:Checking exceptions
2022-11-22 11:21:43,701:INFO:Importing libraries
2022-11-22 11:21:43,701:INFO:Copying training dataset
2022-11-22 11:21:43,703:INFO:Defining folds
2022-11-22 11:21:43,704:INFO:Declaring metric variables
2022-11-22 11:21:43,706:INFO:Importing untrained model
2022-11-22 11:21:43,709:INFO:K Neighbors Regressor Imported successfully
2022-11-22 11:21:43,716:INFO:Starting cross validation
2022-11-22 11:21:43,716:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:43,833:INFO:Calculating mean and std
2022-11-22 11:21:43,834:INFO:Creating metrics dataframe
2022-11-22 11:21:43,837:INFO:Uploading results into container
2022-11-22 11:21:43,838:INFO:Uploading model into container now
2022-11-22 11:21:43,838:INFO:master_model_container: 11
2022-11-22 11:21:43,838:INFO:display_container: 2
2022-11-22 11:21:43,838:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2022-11-22 11:21:43,839:INFO:create_model() successfully completed......................................
2022-11-22 11:21:43,961:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:43,961:INFO:Creating metrics dataframe
2022-11-22 11:21:43,971:INFO:Initializing Decision Tree Regressor
2022-11-22 11:21:43,971:INFO:Total runtime is 0.09245783090591429 minutes
2022-11-22 11:21:43,974:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:43,974:INFO:Initializing create_model()
2022-11-22 11:21:43,974:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:43,974:INFO:Checking exceptions
2022-11-22 11:21:43,977:INFO:Importing libraries
2022-11-22 11:21:43,977:INFO:Copying training dataset
2022-11-22 11:21:43,980:INFO:Defining folds
2022-11-22 11:21:43,980:INFO:Declaring metric variables
2022-11-22 11:21:43,983:INFO:Importing untrained model
2022-11-22 11:21:43,986:INFO:Decision Tree Regressor Imported successfully
2022-11-22 11:21:43,992:INFO:Starting cross validation
2022-11-22 11:21:43,993:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:44,106:INFO:Calculating mean and std
2022-11-22 11:21:44,107:INFO:Creating metrics dataframe
2022-11-22 11:21:44,111:INFO:Uploading results into container
2022-11-22 11:21:44,111:INFO:Uploading model into container now
2022-11-22 11:21:44,111:INFO:master_model_container: 12
2022-11-22 11:21:44,112:INFO:display_container: 2
2022-11-22 11:21:44,113:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      random_state=6498, splitter='best')
2022-11-22 11:21:44,113:INFO:create_model() successfully completed......................................
2022-11-22 11:21:44,238:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:44,239:INFO:Creating metrics dataframe
2022-11-22 11:21:44,251:INFO:Initializing Random Forest Regressor
2022-11-22 11:21:44,251:INFO:Total runtime is 0.09711700280507404 minutes
2022-11-22 11:21:44,253:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:44,253:INFO:Initializing create_model()
2022-11-22 11:21:44,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:44,254:INFO:Checking exceptions
2022-11-22 11:21:44,255:INFO:Importing libraries
2022-11-22 11:21:44,255:INFO:Copying training dataset
2022-11-22 11:21:44,257:INFO:Defining folds
2022-11-22 11:21:44,258:INFO:Declaring metric variables
2022-11-22 11:21:44,261:INFO:Importing untrained model
2022-11-22 11:21:44,266:INFO:Random Forest Regressor Imported successfully
2022-11-22 11:21:44,270:INFO:Starting cross validation
2022-11-22 11:21:44,271:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:47,189:INFO:Calculating mean and std
2022-11-22 11:21:47,191:INFO:Creating metrics dataframe
2022-11-22 11:21:47,195:INFO:Uploading results into container
2022-11-22 11:21:47,195:INFO:Uploading model into container now
2022-11-22 11:21:47,195:INFO:master_model_container: 13
2022-11-22 11:21:47,195:INFO:display_container: 2
2022-11-22 11:21:47,196:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                      oob_score=False, random_state=6498, verbose=0,
                      warm_start=False)
2022-11-22 11:21:47,196:INFO:create_model() successfully completed......................................
2022-11-22 11:21:47,321:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:47,322:INFO:Creating metrics dataframe
2022-11-22 11:21:47,333:INFO:Initializing Extra Trees Regressor
2022-11-22 11:21:47,333:INFO:Total runtime is 0.14849340915679932 minutes
2022-11-22 11:21:47,336:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:47,336:INFO:Initializing create_model()
2022-11-22 11:21:47,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:47,336:INFO:Checking exceptions
2022-11-22 11:21:47,338:INFO:Importing libraries
2022-11-22 11:21:47,338:INFO:Copying training dataset
2022-11-22 11:21:47,342:INFO:Defining folds
2022-11-22 11:21:47,343:INFO:Declaring metric variables
2022-11-22 11:21:47,346:INFO:Importing untrained model
2022-11-22 11:21:47,350:INFO:Extra Trees Regressor Imported successfully
2022-11-22 11:21:47,357:INFO:Starting cross validation
2022-11-22 11:21:47,358:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:48,959:INFO:Calculating mean and std
2022-11-22 11:21:48,961:INFO:Creating metrics dataframe
2022-11-22 11:21:48,964:INFO:Uploading results into container
2022-11-22 11:21:48,965:INFO:Uploading model into container now
2022-11-22 11:21:48,965:INFO:master_model_container: 14
2022-11-22 11:21:48,965:INFO:display_container: 2
2022-11-22 11:21:48,966:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=6498, verbose=0,
                    warm_start=False)
2022-11-22 11:21:48,966:INFO:create_model() successfully completed......................................
2022-11-22 11:21:49,102:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:49,102:INFO:Creating metrics dataframe
2022-11-22 11:21:49,114:INFO:Initializing AdaBoost Regressor
2022-11-22 11:21:49,115:INFO:Total runtime is 0.17818154493967692 minutes
2022-11-22 11:21:49,117:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:49,117:INFO:Initializing create_model()
2022-11-22 11:21:49,118:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:49,118:INFO:Checking exceptions
2022-11-22 11:21:49,119:INFO:Importing libraries
2022-11-22 11:21:49,119:INFO:Copying training dataset
2022-11-22 11:21:49,122:INFO:Defining folds
2022-11-22 11:21:49,122:INFO:Declaring metric variables
2022-11-22 11:21:49,125:INFO:Importing untrained model
2022-11-22 11:21:49,129:INFO:AdaBoost Regressor Imported successfully
2022-11-22 11:21:49,134:INFO:Starting cross validation
2022-11-22 11:21:49,135:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:49,764:INFO:Calculating mean and std
2022-11-22 11:21:49,765:INFO:Creating metrics dataframe
2022-11-22 11:21:49,768:INFO:Uploading results into container
2022-11-22 11:21:49,768:INFO:Uploading model into container now
2022-11-22 11:21:49,768:INFO:master_model_container: 15
2022-11-22 11:21:49,768:INFO:display_container: 2
2022-11-22 11:21:49,769:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=6498)
2022-11-22 11:21:49,769:INFO:create_model() successfully completed......................................
2022-11-22 11:21:49,898:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:49,899:INFO:Creating metrics dataframe
2022-11-22 11:21:49,911:INFO:Initializing Gradient Boosting Regressor
2022-11-22 11:21:49,911:INFO:Total runtime is 0.19145468870798746 minutes
2022-11-22 11:21:49,913:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:49,914:INFO:Initializing create_model()
2022-11-22 11:21:49,914:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:49,914:INFO:Checking exceptions
2022-11-22 11:21:49,915:INFO:Importing libraries
2022-11-22 11:21:49,915:INFO:Copying training dataset
2022-11-22 11:21:49,918:INFO:Defining folds
2022-11-22 11:21:49,918:INFO:Declaring metric variables
2022-11-22 11:21:49,921:INFO:Importing untrained model
2022-11-22 11:21:49,925:INFO:Gradient Boosting Regressor Imported successfully
2022-11-22 11:21:49,932:INFO:Starting cross validation
2022-11-22 11:21:49,933:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:51,188:INFO:Calculating mean and std
2022-11-22 11:21:51,190:INFO:Creating metrics dataframe
2022-11-22 11:21:51,193:INFO:Uploading results into container
2022-11-22 11:21:51,194:INFO:Uploading model into container now
2022-11-22 11:21:51,194:INFO:master_model_container: 16
2022-11-22 11:21:51,194:INFO:display_container: 2
2022-11-22 11:21:51,195:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=6498, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-22 11:21:51,195:INFO:create_model() successfully completed......................................
2022-11-22 11:21:51,325:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:51,325:INFO:Creating metrics dataframe
2022-11-22 11:21:51,336:INFO:Initializing Light Gradient Boosting Machine
2022-11-22 11:21:51,337:INFO:Total runtime is 0.21521390676498411 minutes
2022-11-22 11:21:51,340:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:51,340:INFO:Initializing create_model()
2022-11-22 11:21:51,340:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:51,341:INFO:Checking exceptions
2022-11-22 11:21:51,342:INFO:Importing libraries
2022-11-22 11:21:51,342:INFO:Copying training dataset
2022-11-22 11:21:51,345:INFO:Defining folds
2022-11-22 11:21:51,345:INFO:Declaring metric variables
2022-11-22 11:21:51,348:INFO:Importing untrained model
2022-11-22 11:21:51,350:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-22 11:21:51,356:INFO:Starting cross validation
2022-11-22 11:21:51,357:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:51,641:INFO:Calculating mean and std
2022-11-22 11:21:51,642:INFO:Creating metrics dataframe
2022-11-22 11:21:51,645:INFO:Uploading results into container
2022-11-22 11:21:51,646:INFO:Uploading model into container now
2022-11-22 11:21:51,646:INFO:master_model_container: 17
2022-11-22 11:21:51,646:INFO:display_container: 2
2022-11-22 11:21:51,646:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=6498, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-11-22 11:21:51,647:INFO:create_model() successfully completed......................................
2022-11-22 11:21:51,781:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:51,781:INFO:Creating metrics dataframe
2022-11-22 11:21:51,794:INFO:Initializing Dummy Regressor
2022-11-22 11:21:51,794:INFO:Total runtime is 0.2228425860404968 minutes
2022-11-22 11:21:51,797:INFO:SubProcess create_model() called ==================================
2022-11-22 11:21:51,798:INFO:Initializing create_model()
2022-11-22 11:21:51,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5554afb0>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:51,798:INFO:Checking exceptions
2022-11-22 11:21:51,799:INFO:Importing libraries
2022-11-22 11:21:51,799:INFO:Copying training dataset
2022-11-22 11:21:51,802:INFO:Defining folds
2022-11-22 11:21:51,802:INFO:Declaring metric variables
2022-11-22 11:21:51,806:INFO:Importing untrained model
2022-11-22 11:21:51,809:INFO:Dummy Regressor Imported successfully
2022-11-22 11:21:51,815:INFO:Starting cross validation
2022-11-22 11:21:51,816:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:51,891:INFO:Calculating mean and std
2022-11-22 11:21:51,891:INFO:Creating metrics dataframe
2022-11-22 11:21:51,894:INFO:Uploading results into container
2022-11-22 11:21:51,894:INFO:Uploading model into container now
2022-11-22 11:21:51,894:INFO:master_model_container: 18
2022-11-22 11:21:51,894:INFO:display_container: 2
2022-11-22 11:21:51,894:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2022-11-22 11:21:51,894:INFO:create_model() successfully completed......................................
2022-11-22 11:21:52,020:INFO:SubProcess create_model() end ==================================
2022-11-22 11:21:52,020:INFO:Creating metrics dataframe
2022-11-22 11:21:52,042:INFO:Initializing create_model()
2022-11-22 11:21:52,042:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=6498, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:52,042:INFO:Checking exceptions
2022-11-22 11:21:52,045:INFO:Importing libraries
2022-11-22 11:21:52,045:INFO:Copying training dataset
2022-11-22 11:21:52,046:INFO:Defining folds
2022-11-22 11:21:52,047:INFO:Declaring metric variables
2022-11-22 11:21:52,047:INFO:Importing untrained model
2022-11-22 11:21:52,047:INFO:Declaring custom model
2022-11-22 11:21:52,047:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-22 11:21:52,048:INFO:Cross validation set to False
2022-11-22 11:21:52,048:INFO:Fitting Model
2022-11-22 11:21:52,165:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=6498, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-11-22 11:21:52,165:INFO:create_model() successfully completed......................................
2022-11-22 11:21:52,357:INFO:master_model_container: 18
2022-11-22 11:21:52,357:INFO:display_container: 2
2022-11-22 11:21:52,358:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=6498, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-11-22 11:21:52,358:INFO:compare_models() successfully completed......................................
2022-11-22 11:21:54,860:INFO:Initializing create_model()
2022-11-22 11:21:54,861:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=gbr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:21:54,861:INFO:Checking exceptions
2022-11-22 11:21:54,891:INFO:Importing libraries
2022-11-22 11:21:54,891:INFO:Copying training dataset
2022-11-22 11:21:54,894:INFO:Defining folds
2022-11-22 11:21:54,894:INFO:Declaring metric variables
2022-11-22 11:21:54,897:INFO:Importing untrained model
2022-11-22 11:21:54,901:INFO:Gradient Boosting Regressor Imported successfully
2022-11-22 11:21:54,910:INFO:Starting cross validation
2022-11-22 11:21:54,910:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:21:56,171:INFO:Calculating mean and std
2022-11-22 11:21:56,172:INFO:Creating metrics dataframe
2022-11-22 11:21:56,176:INFO:Finalizing model
2022-11-22 11:21:56,661:INFO:Uploading results into container
2022-11-22 11:21:56,662:INFO:Uploading model into container now
2022-11-22 11:21:56,672:INFO:master_model_container: 19
2022-11-22 11:21:56,672:INFO:display_container: 3
2022-11-22 11:21:56,673:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=6498, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-22 11:21:56,673:INFO:create_model() successfully completed......................................
2022-11-22 11:21:56,807:INFO:Initializing tune_model()
2022-11-22 11:21:56,807:INFO:tune_model(estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=6498, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>)
2022-11-22 11:21:56,807:INFO:Checking exceptions
2022-11-22 11:21:56,826:INFO:Copying training dataset
2022-11-22 11:21:56,828:INFO:Checking base model
2022-11-22 11:21:56,828:INFO:Base model : Gradient Boosting Regressor
2022-11-22 11:21:56,832:INFO:Declaring metric variables
2022-11-22 11:21:56,836:INFO:Defining Hyperparameters
2022-11-22 11:21:56,976:INFO:Tuning with n_jobs=-1
2022-11-22 11:21:56,976:INFO:Initializing RandomizedSearchCV
2022-11-22 11:22:05,563:INFO:best_params: {'actual_estimator__subsample': 0.75, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 5, 'actual_estimator__learning_rate': 0.15}
2022-11-22 11:22:05,564:INFO:Hyperparameter search completed
2022-11-22 11:22:05,564:INFO:SubProcess create_model() called ==================================
2022-11-22 11:22:05,565:INFO:Initializing create_model()
2022-11-22 11:22:05,565:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=6498, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad558c27a0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.75, 'n_estimators': 180, 'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.05, 'max_features': 'log2', 'max_depth': 5, 'learning_rate': 0.15})
2022-11-22 11:22:05,565:INFO:Checking exceptions
2022-11-22 11:22:05,572:INFO:Importing libraries
2022-11-22 11:22:05,572:INFO:Copying training dataset
2022-11-22 11:22:05,574:INFO:Defining folds
2022-11-22 11:22:05,574:INFO:Declaring metric variables
2022-11-22 11:22:05,577:INFO:Importing untrained model
2022-11-22 11:22:05,577:INFO:Declaring custom model
2022-11-22 11:22:05,580:INFO:Gradient Boosting Regressor Imported successfully
2022-11-22 11:22:05,585:INFO:Starting cross validation
2022-11-22 11:22:05,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:22:06,591:INFO:Calculating mean and std
2022-11-22 11:22:06,592:INFO:Creating metrics dataframe
2022-11-22 11:22:06,597:INFO:Finalizing model
2022-11-22 11:22:06,997:INFO:Uploading results into container
2022-11-22 11:22:06,997:INFO:Uploading model into container now
2022-11-22 11:22:06,999:INFO:master_model_container: 20
2022-11-22 11:22:06,999:INFO:display_container: 4
2022-11-22 11:22:06,999:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.15, loss='squared_error',
                          max_depth=5, max_features='log2', max_leaf_nodes=None,
                          min_impurity_decrease=0.05, min_samples_leaf=5,
                          min_samples_split=9, min_weight_fraction_leaf=0.0,
                          n_estimators=180, n_iter_no_change=None,
                          random_state=6498, subsample=0.75, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-22 11:22:06,999:INFO:create_model() successfully completed......................................
2022-11-22 11:22:07,129:INFO:SubProcess create_model() end ==================================
2022-11-22 11:22:07,129:INFO:choose_better activated
2022-11-22 11:22:07,132:INFO:SubProcess create_model() called ==================================
2022-11-22 11:22:07,132:INFO:Initializing create_model()
2022-11-22 11:22:07,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=6498, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:22:07,132:INFO:Checking exceptions
2022-11-22 11:22:07,135:INFO:Importing libraries
2022-11-22 11:22:07,135:INFO:Copying training dataset
2022-11-22 11:22:07,137:INFO:Defining folds
2022-11-22 11:22:07,137:INFO:Declaring metric variables
2022-11-22 11:22:07,137:INFO:Importing untrained model
2022-11-22 11:22:07,137:INFO:Declaring custom model
2022-11-22 11:22:07,138:INFO:Gradient Boosting Regressor Imported successfully
2022-11-22 11:22:07,138:INFO:Starting cross validation
2022-11-22 11:22:07,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:22:08,379:INFO:Calculating mean and std
2022-11-22 11:22:08,379:INFO:Creating metrics dataframe
2022-11-22 11:22:08,381:INFO:Finalizing model
2022-11-22 11:22:08,872:INFO:Uploading results into container
2022-11-22 11:22:08,873:INFO:Uploading model into container now
2022-11-22 11:22:08,873:INFO:master_model_container: 21
2022-11-22 11:22:08,873:INFO:display_container: 5
2022-11-22 11:22:08,874:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=6498, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-22 11:22:08,874:INFO:create_model() successfully completed......................................
2022-11-22 11:22:08,998:INFO:SubProcess create_model() end ==================================
2022-11-22 11:22:08,999:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=6498, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) result for R2 is 0.8242
2022-11-22 11:22:08,999:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.15, loss='squared_error',
                          max_depth=5, max_features='log2', max_leaf_nodes=None,
                          min_impurity_decrease=0.05, min_samples_leaf=5,
                          min_samples_split=9, min_weight_fraction_leaf=0.0,
                          n_estimators=180, n_iter_no_change=None,
                          random_state=6498, subsample=0.75, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) result for R2 is 0.8503
2022-11-22 11:22:09,000:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.15, loss='squared_error',
                          max_depth=5, max_features='log2', max_leaf_nodes=None,
                          min_impurity_decrease=0.05, min_samples_leaf=5,
                          min_samples_split=9, min_weight_fraction_leaf=0.0,
                          n_estimators=180, n_iter_no_change=None,
                          random_state=6498, subsample=0.75, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) is best model
2022-11-22 11:22:09,000:INFO:choose_better completed
2022-11-22 11:22:09,010:INFO:master_model_container: 21
2022-11-22 11:22:09,010:INFO:display_container: 4
2022-11-22 11:22:09,010:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.15, loss='squared_error',
                          max_depth=5, max_features='log2', max_leaf_nodes=None,
                          min_impurity_decrease=0.05, min_samples_leaf=5,
                          min_samples_split=9, min_weight_fraction_leaf=0.0,
                          n_estimators=180, n_iter_no_change=None,
                          random_state=6498, subsample=0.75, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-22 11:22:09,010:INFO:tune_model() successfully completed......................................
2022-11-22 11:22:12,926:INFO:Initializing plot_model()
2022-11-22 11:22:12,927:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.15, loss='squared_error',
                          max_depth=5, max_features='log2', max_leaf_nodes=None,
                          min_impurity_decrease=0.05, min_samples_leaf=5,
                          min_samples_split=9, min_weight_fraction_leaf=0.0,
                          n_estimators=180, n_iter_no_change=None,
                          random_state=6498, subsample=0.75, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, system=True)
2022-11-22 11:22:12,927:INFO:Checking exceptions
2022-11-22 11:22:12,933:INFO:Preloading libraries
2022-11-22 11:22:12,942:INFO:Copying training dataset
2022-11-22 11:22:12,942:INFO:Plot type: residuals
2022-11-22 11:22:12,986:INFO:Fitting Model
2022-11-22 11:22:12,987:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2022-11-22 11:22:13,038:INFO:Scoring test/hold-out set
2022-11-22 11:22:13,361:INFO:Visual Rendered Successfully
2022-11-22 11:22:13,501:INFO:plot_model() successfully completed......................................
2022-11-22 11:22:17,541:INFO:Initializing plot_model()
2022-11-22 11:22:17,541:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=6498, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad53bc4880>, system=True)
2022-11-22 11:22:17,541:INFO:Checking exceptions
2022-11-22 11:22:17,545:INFO:Preloading libraries
2022-11-22 11:22:17,551:INFO:Copying training dataset
2022-11-22 11:22:17,551:INFO:Plot type: residuals
2022-11-22 11:22:17,602:INFO:Fitting Model
2022-11-22 11:22:17,602:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2022-11-22 11:22:17,641:INFO:Scoring test/hold-out set
2022-11-22 11:22:17,909:INFO:Visual Rendered Successfully
2022-11-22 11:22:18,055:INFO:plot_model() successfully completed......................................
2022-11-22 11:22:22,038:INFO:Initializing save_model()
2022-11-22 11:22:22,038:INFO:save_model(model=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.15, loss='squared_error',
                          max_depth=5, max_features='log2', max_leaf_nodes=None,
                          min_impurity_decrease=0.05, min_samples_leaf=5,
                          min_samples_split=9, min_weight_fraction_leaf=0.0,
                          n_estimators=180, n_iter_no_change=None,
                          random_state=6498, subsample=0.75, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), model_name=Coches_gbr, prep_pipe_=Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2022-11-22 11:22:22,038:INFO:Adding model into prep_pipe
2022-11-22 11:22:22,060:INFO:Coches_gbr.pkl saved in current working directory
2022-11-22 11:22:22,064:INFO:Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=...
                                           criterion='friedman_mse', init=None,
                                           learning_rate=0.15,
                                           loss='squared_error', max_depth=5,
                                           max_features='log2',
                                           max_leaf_nodes=None,
                                           min_impurity_decrease=0.05,
                                           min_samples_leaf=5,
                                           min_samples_split=9,
                                           min_weight_fraction_leaf=0.0,
                                           n_estimators=180,
                                           n_iter_no_change=None,
                                           random_state=6498, subsample=0.75,
                                           tol=0.0001, validation_fraction=0.1,
                                           verbose=0, warm_start=False))],
         verbose=False)
2022-11-22 11:22:22,064:INFO:save_model() successfully completed......................................
2022-11-22 11:22:41,902:INFO:Initializing load_model()
2022-11-22 11:22:41,902:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:22:41,929:INFO:Initializing predict_model()
2022-11-22 11:22:41,929:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc69ecd7670>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc67e9679a0>)
2022-11-22 11:22:41,930:INFO:Checking exceptions
2022-11-22 11:22:41,930:INFO:Preloading libraries
2022-11-22 11:24:50,724:INFO:Initializing load_model()
2022-11-22 11:24:50,724:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:24:50,747:INFO:Initializing predict_model()
2022-11-22 11:24:50,748:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc67e9f3a00>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc67e967e20>)
2022-11-22 11:24:50,749:INFO:Checking exceptions
2022-11-22 11:24:50,749:INFO:Preloading libraries
2022-11-22 11:29:32,725:INFO:PyCaret RegressionExperiment
2022-11-22 11:29:32,725:INFO:Logging name: reg-default-name
2022-11-22 11:29:32,725:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-22 11:29:32,725:INFO:version 3.0.0.rc4
2022-11-22 11:29:32,725:INFO:Initializing setup()
2022-11-22 11:29:32,725:INFO:self.USI: d781
2022-11-22 11:29:32,725:INFO:self.variable_keys: {'y_test', 'exp_name_log', 'data', 'variable_keys', 'y', 'master_model_container', 'USI', '_all_models_internal', '_ml_usecase', 'memory', '_gpu_n_jobs_param', 'html_param', 'X', 'target_param', '_all_metrics', 'y_train', 'logging_param', 'X_train', 'fold_generator', 'transform_target_param', 'gpu_param', 'X_test', 'idx', 'pipeline', 'seed', '_available_plots', '_all_models', 'exp_id', 'display_container', 'fold_groups_param', 'log_plots_param', 'transform_target_method_param', 'n_jobs_param', 'fold_shuffle_param'}
2022-11-22 11:29:32,725:INFO:Checking environment
2022-11-22 11:29:32,725:INFO:python_version: 3.10.6
2022-11-22 11:29:32,725:INFO:python_build: ('main', 'Nov  2 2022 18:53:38')
2022-11-22 11:29:32,725:INFO:machine: x86_64
2022-11-22 11:29:32,725:INFO:platform: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-22 11:29:32,726:INFO:Memory: svmem(total=7962374144, available=2217644032, percent=72.1, used=4327694336, free=1164791808, active=1953263616, inactive=3968819200, buffers=55476224, cached=2414411776, shared=1079361536, slab=385748992)
2022-11-22 11:29:32,726:INFO:Physical Core: 4
2022-11-22 11:29:32,726:INFO:Logical Core: 8
2022-11-22 11:29:32,726:INFO:Checking libraries
2022-11-22 11:29:32,726:INFO:System:
2022-11-22 11:29:32,726:INFO:    python: 3.10.6 (main, Nov  2 2022, 18:53:38) [GCC 11.3.0]
2022-11-22 11:29:32,726:INFO:executable: /bin/python3
2022-11-22 11:29:32,726:INFO:   machine: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-22 11:29:32,726:INFO:PyCaret required dependencies:
2022-11-22 11:29:32,726:INFO:                 pip: 22.0.2
2022-11-22 11:29:32,726:INFO:          setuptools: 59.6.0
2022-11-22 11:29:32,726:INFO:             pycaret: 3.0.0rc4
2022-11-22 11:29:32,726:INFO:             IPython: 8.6.0
2022-11-22 11:29:32,726:INFO:          ipywidgets: 8.0.2
2022-11-22 11:29:32,726:INFO:                tqdm: 4.64.1
2022-11-22 11:29:32,726:INFO:               numpy: 1.21.4
2022-11-22 11:29:32,726:INFO:              pandas: 1.3.5
2022-11-22 11:29:32,726:INFO:              jinja2: 3.0.3
2022-11-22 11:29:32,726:INFO:               scipy: 1.8.1
2022-11-22 11:29:32,727:INFO:              joblib: 1.2.0
2022-11-22 11:29:32,727:INFO:             sklearn: 1.1.3
2022-11-22 11:29:32,727:INFO:                pyod: 1.0.6
2022-11-22 11:29:32,727:INFO:            imblearn: 0.9.1
2022-11-22 11:29:32,727:INFO:   category_encoders: 2.5.1.post0
2022-11-22 11:29:32,727:INFO:            lightgbm: 3.3.3
2022-11-22 11:29:32,727:INFO:               numba: 0.55.2
2022-11-22 11:29:32,727:INFO:            requests: 2.25.1
2022-11-22 11:29:32,727:INFO:          matplotlib: 3.6.2
2022-11-22 11:29:32,727:INFO:          scikitplot: 0.3.7
2022-11-22 11:29:32,727:INFO:         yellowbrick: 1.5
2022-11-22 11:29:32,727:INFO:              plotly: 5.11.0
2022-11-22 11:29:32,727:INFO:             kaleido: 0.2.1
2022-11-22 11:29:32,727:INFO:         statsmodels: 0.13.5
2022-11-22 11:29:32,727:INFO:              sktime: 0.13.4
2022-11-22 11:29:32,727:INFO:               tbats: 1.1.1
2022-11-22 11:29:32,727:INFO:            pmdarima: 1.8.5
2022-11-22 11:29:32,727:INFO:              psutil: 5.9.0
2022-11-22 11:29:32,727:INFO:PyCaret optional dependencies:
2022-11-22 11:29:32,727:INFO:                shap: Not installed
2022-11-22 11:29:32,727:INFO:           interpret: Not installed
2022-11-22 11:29:32,727:INFO:                umap: Not installed
2022-11-22 11:29:32,727:INFO:    pandas_profiling: Not installed
2022-11-22 11:29:32,727:INFO:  explainerdashboard: Not installed
2022-11-22 11:29:32,727:INFO:             autoviz: Not installed
2022-11-22 11:29:32,727:INFO:           fairlearn: Not installed
2022-11-22 11:29:32,727:INFO:             xgboost: Not installed
2022-11-22 11:29:32,728:INFO:            catboost: Not installed
2022-11-22 11:29:32,728:INFO:              kmodes: Not installed
2022-11-22 11:29:32,728:INFO:             mlxtend: Not installed
2022-11-22 11:29:32,728:INFO:       statsforecast: Not installed
2022-11-22 11:29:32,728:INFO:        tune_sklearn: Not installed
2022-11-22 11:29:32,728:INFO:                 ray: Not installed
2022-11-22 11:29:32,728:INFO:            hyperopt: Not installed
2022-11-22 11:29:32,728:INFO:              optuna: Not installed
2022-11-22 11:29:32,728:INFO:               skopt: Not installed
2022-11-22 11:29:32,728:INFO:              mlflow: Not installed
2022-11-22 11:29:32,728:INFO:              gradio: Not installed
2022-11-22 11:29:32,728:INFO:             fastapi: Not installed
2022-11-22 11:29:32,728:INFO:             uvicorn: Not installed
2022-11-22 11:29:32,728:INFO:              m2cgen: Not installed
2022-11-22 11:29:32,728:INFO:           evidently: Not installed
2022-11-22 11:29:32,728:INFO:                nltk: 3.6.7
2022-11-22 11:29:32,728:INFO:            pyLDAvis: Not installed
2022-11-22 11:29:32,728:INFO:              gensim: Not installed
2022-11-22 11:29:32,728:INFO:               spacy: Not installed
2022-11-22 11:29:32,728:INFO:           wordcloud: Not installed
2022-11-22 11:29:32,728:INFO:            textblob: Not installed
2022-11-22 11:29:32,728:INFO:               fugue: Not installed
2022-11-22 11:29:32,728:INFO:           streamlit: 1.15.0
2022-11-22 11:29:32,728:INFO:             prophet: Not installed
2022-11-22 11:29:32,728:INFO:None
2022-11-22 11:29:32,728:INFO:Set up data.
2022-11-22 11:29:32,734:INFO:Set up train/test split.
2022-11-22 11:29:32,738:INFO:Set up index.
2022-11-22 11:29:32,739:INFO:Set up folding strategy.
2022-11-22 11:29:32,739:INFO:Assigning column types.
2022-11-22 11:29:32,742:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-22 11:29:32,743:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-22 11:29:32,746:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-22 11:29:32,750:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 11:29:32,789:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:29:32,818:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 11:29:32,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:32,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:32,820:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-22 11:29:32,822:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-22 11:29:32,825:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 11:29:32,863:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:29:32,892:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 11:29:32,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:32,893:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:32,893:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-22 11:29:32,897:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-22 11:29:32,900:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 11:29:32,938:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:29:32,971:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 11:29:32,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:32,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:32,975:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-22 11:29:32,979:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 11:29:33,027:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:29:33,064:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 11:29:33,065:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,065:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,065:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-22 11:29:33,071:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 11:29:33,118:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:29:33,148:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 11:29:33,150:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,150:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,156:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-22 11:29:33,200:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:29:33,231:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 11:29:33,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,233:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-22 11:29:33,281:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:29:33,317:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 11:29:33,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,318:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,371:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:29:33,401:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-22 11:29:33,401:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,402:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-22 11:29:33,445:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:29:33,474:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,474:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,518:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-22 11:29:33,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,549:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,549:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-22 11:29:33,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,624:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,697:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,698:INFO:Preparing preprocessing pipeline...
2022-11-22 11:29:33,699:INFO:Set up simple imputation.
2022-11-22 11:29:33,699:INFO:Set up variance threshold.
2022-11-22 11:29:33,726:INFO:Finished creating preprocessing pipeline.
2022-11-22 11:29:33,730:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False)
2022-11-22 11:29:33,730:INFO:Creating final display dataframe.
2022-11-22 11:29:33,888:INFO:Setup display_container:                Description             Value
0               Session id              2908
1                   Target             price
2              Target type        Regression
3               Data shape        (5000, 13)
4         Train data shape        (3499, 13)
5          Test data shape        (1501, 13)
6         Numeric features                12
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              d781
2022-11-22 11:29:33,965:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:33,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:34,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:34,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-22 11:29:34,041:INFO:setup() successfully completed in 1.32s...............
2022-11-22 11:29:34,068:INFO:Initializing compare_models()
2022-11-22 11:29:34,068:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-22 11:29:34,068:INFO:Checking exceptions
2022-11-22 11:29:34,070:INFO:Preparing display monitor
2022-11-22 11:29:34,102:INFO:Initializing Linear Regression
2022-11-22 11:29:34,102:INFO:Total runtime is 2.555052439371745e-06 minutes
2022-11-22 11:29:34,105:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:34,105:INFO:Initializing create_model()
2022-11-22 11:29:34,105:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:34,105:INFO:Checking exceptions
2022-11-22 11:29:34,107:INFO:Importing libraries
2022-11-22 11:29:34,107:INFO:Copying training dataset
2022-11-22 11:29:34,109:INFO:Defining folds
2022-11-22 11:29:34,109:INFO:Declaring metric variables
2022-11-22 11:29:34,113:INFO:Importing untrained model
2022-11-22 11:29:34,118:INFO:Linear Regression Imported successfully
2022-11-22 11:29:34,123:INFO:Starting cross validation
2022-11-22 11:29:34,125:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:36,304:INFO:Calculating mean and std
2022-11-22 11:29:36,307:INFO:Creating metrics dataframe
2022-11-22 11:29:36,312:INFO:Uploading results into container
2022-11-22 11:29:36,313:INFO:Uploading model into container now
2022-11-22 11:29:36,314:INFO:master_model_container: 1
2022-11-22 11:29:36,314:INFO:display_container: 2
2022-11-22 11:29:36,314:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1,
                 normalize='deprecated', positive=False)
2022-11-22 11:29:36,314:INFO:create_model() successfully completed......................................
2022-11-22 11:29:36,481:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:36,481:INFO:Creating metrics dataframe
2022-11-22 11:29:36,490:INFO:Initializing Lasso Regression
2022-11-22 11:29:36,490:INFO:Total runtime is 0.039795025189717614 minutes
2022-11-22 11:29:36,494:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:36,494:INFO:Initializing create_model()
2022-11-22 11:29:36,494:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:36,494:INFO:Checking exceptions
2022-11-22 11:29:36,502:INFO:Importing libraries
2022-11-22 11:29:36,502:INFO:Copying training dataset
2022-11-22 11:29:36,505:INFO:Defining folds
2022-11-22 11:29:36,505:INFO:Declaring metric variables
2022-11-22 11:29:36,508:INFO:Importing untrained model
2022-11-22 11:29:36,512:INFO:Lasso Regression Imported successfully
2022-11-22 11:29:36,517:INFO:Starting cross validation
2022-11-22 11:29:36,518:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:36,601:INFO:Calculating mean and std
2022-11-22 11:29:36,602:INFO:Creating metrics dataframe
2022-11-22 11:29:36,605:INFO:Uploading results into container
2022-11-22 11:29:36,605:INFO:Uploading model into container now
2022-11-22 11:29:36,605:INFO:master_model_container: 2
2022-11-22 11:29:36,605:INFO:display_container: 2
2022-11-22 11:29:36,606:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize='deprecated', positive=False, precompute=False,
      random_state=2908, selection='cyclic', tol=0.0001, warm_start=False)
2022-11-22 11:29:36,606:INFO:create_model() successfully completed......................................
2022-11-22 11:29:36,750:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:36,751:INFO:Creating metrics dataframe
2022-11-22 11:29:36,760:INFO:Initializing Ridge Regression
2022-11-22 11:29:36,760:INFO:Total runtime is 0.044297349452972416 minutes
2022-11-22 11:29:36,764:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:36,764:INFO:Initializing create_model()
2022-11-22 11:29:36,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:36,764:INFO:Checking exceptions
2022-11-22 11:29:36,765:INFO:Importing libraries
2022-11-22 11:29:36,766:INFO:Copying training dataset
2022-11-22 11:29:36,767:INFO:Defining folds
2022-11-22 11:29:36,767:INFO:Declaring metric variables
2022-11-22 11:29:36,770:INFO:Importing untrained model
2022-11-22 11:29:36,772:INFO:Ridge Regression Imported successfully
2022-11-22 11:29:36,781:INFO:Starting cross validation
2022-11-22 11:29:36,782:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:36,862:INFO:Calculating mean and std
2022-11-22 11:29:36,862:INFO:Creating metrics dataframe
2022-11-22 11:29:36,865:INFO:Uploading results into container
2022-11-22 11:29:36,865:INFO:Uploading model into container now
2022-11-22 11:29:36,865:INFO:master_model_container: 3
2022-11-22 11:29:36,865:INFO:display_container: 2
2022-11-22 11:29:36,866:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize='deprecated', positive=False, random_state=2908, solver='auto',
      tol=0.001)
2022-11-22 11:29:36,866:INFO:create_model() successfully completed......................................
2022-11-22 11:29:37,013:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:37,013:INFO:Creating metrics dataframe
2022-11-22 11:29:37,022:INFO:Initializing Elastic Net
2022-11-22 11:29:37,022:INFO:Total runtime is 0.04867130915323894 minutes
2022-11-22 11:29:37,026:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:37,027:INFO:Initializing create_model()
2022-11-22 11:29:37,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:37,027:INFO:Checking exceptions
2022-11-22 11:29:37,029:INFO:Importing libraries
2022-11-22 11:29:37,029:INFO:Copying training dataset
2022-11-22 11:29:37,031:INFO:Defining folds
2022-11-22 11:29:37,032:INFO:Declaring metric variables
2022-11-22 11:29:37,034:INFO:Importing untrained model
2022-11-22 11:29:37,037:INFO:Elastic Net Imported successfully
2022-11-22 11:29:37,044:INFO:Starting cross validation
2022-11-22 11:29:37,045:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:37,139:INFO:Calculating mean and std
2022-11-22 11:29:37,141:INFO:Creating metrics dataframe
2022-11-22 11:29:37,146:INFO:Uploading results into container
2022-11-22 11:29:37,147:INFO:Uploading model into container now
2022-11-22 11:29:37,147:INFO:master_model_container: 4
2022-11-22 11:29:37,147:INFO:display_container: 2
2022-11-22 11:29:37,148:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize='deprecated', positive=False,
           precompute=False, random_state=2908, selection='cyclic', tol=0.0001,
           warm_start=False)
2022-11-22 11:29:37,148:INFO:create_model() successfully completed......................................
2022-11-22 11:29:37,309:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:37,309:INFO:Creating metrics dataframe
2022-11-22 11:29:37,318:INFO:Initializing Least Angle Regression
2022-11-22 11:29:37,318:INFO:Total runtime is 0.053607900937398284 minutes
2022-11-22 11:29:37,321:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:37,321:INFO:Initializing create_model()
2022-11-22 11:29:37,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:37,321:INFO:Checking exceptions
2022-11-22 11:29:37,324:INFO:Importing libraries
2022-11-22 11:29:37,324:INFO:Copying training dataset
2022-11-22 11:29:37,327:INFO:Defining folds
2022-11-22 11:29:37,327:INFO:Declaring metric variables
2022-11-22 11:29:37,331:INFO:Importing untrained model
2022-11-22 11:29:37,334:INFO:Least Angle Regression Imported successfully
2022-11-22 11:29:37,339:INFO:Starting cross validation
2022-11-22 11:29:37,340:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:37,365:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,367:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,374:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,377:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,378:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,385:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,392:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,401:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,402:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,410:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,418:INFO:Calculating mean and std
2022-11-22 11:29:37,419:INFO:Creating metrics dataframe
2022-11-22 11:29:37,421:INFO:Uploading results into container
2022-11-22 11:29:37,421:INFO:Uploading model into container now
2022-11-22 11:29:37,421:INFO:master_model_container: 5
2022-11-22 11:29:37,422:INFO:display_container: 2
2022-11-22 11:29:37,422:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, normalize='deprecated',
     precompute='auto', random_state=2908, verbose=False)
2022-11-22 11:29:37,422:INFO:create_model() successfully completed......................................
2022-11-22 11:29:37,567:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:37,568:INFO:Creating metrics dataframe
2022-11-22 11:29:37,578:INFO:Initializing Lasso Least Angle Regression
2022-11-22 11:29:37,579:INFO:Total runtime is 0.05794344743092856 minutes
2022-11-22 11:29:37,581:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:37,581:INFO:Initializing create_model()
2022-11-22 11:29:37,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:37,581:INFO:Checking exceptions
2022-11-22 11:29:37,583:INFO:Importing libraries
2022-11-22 11:29:37,583:INFO:Copying training dataset
2022-11-22 11:29:37,585:INFO:Defining folds
2022-11-22 11:29:37,585:INFO:Declaring metric variables
2022-11-22 11:29:37,588:INFO:Importing untrained model
2022-11-22 11:29:37,593:INFO:Lasso Least Angle Regression Imported successfully
2022-11-22 11:29:37,599:INFO:Starting cross validation
2022-11-22 11:29:37,600:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:37,621:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:29:37,631:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:29:37,631:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:29:37,638:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:29:37,644:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:29:37,654:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:29:37,661:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:29:37,663:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:29:37,671:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:29:37,680:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-22 11:29:37,688:INFO:Calculating mean and std
2022-11-22 11:29:37,689:INFO:Creating metrics dataframe
2022-11-22 11:29:37,693:INFO:Uploading results into container
2022-11-22 11:29:37,693:INFO:Uploading model into container now
2022-11-22 11:29:37,694:INFO:master_model_container: 6
2022-11-22 11:29:37,694:INFO:display_container: 2
2022-11-22 11:29:37,694:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize='deprecated',
          positive=False, precompute='auto', random_state=2908, verbose=False)
2022-11-22 11:29:37,695:INFO:create_model() successfully completed......................................
2022-11-22 11:29:37,863:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:37,863:INFO:Creating metrics dataframe
2022-11-22 11:29:37,873:INFO:Initializing Orthogonal Matching Pursuit
2022-11-22 11:29:37,874:INFO:Total runtime is 0.0628596584002177 minutes
2022-11-22 11:29:37,879:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:37,880:INFO:Initializing create_model()
2022-11-22 11:29:37,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:37,880:INFO:Checking exceptions
2022-11-22 11:29:37,882:INFO:Importing libraries
2022-11-22 11:29:37,882:INFO:Copying training dataset
2022-11-22 11:29:37,884:INFO:Defining folds
2022-11-22 11:29:37,884:INFO:Declaring metric variables
2022-11-22 11:29:37,887:INFO:Importing untrained model
2022-11-22 11:29:37,891:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-22 11:29:37,898:INFO:Starting cross validation
2022-11-22 11:29:37,898:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:37,924:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,924:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,931:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,936:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,947:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,954:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,957:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,967:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,968:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,974:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-22 11:29:37,982:INFO:Calculating mean and std
2022-11-22 11:29:37,983:INFO:Creating metrics dataframe
2022-11-22 11:29:37,986:INFO:Uploading results into container
2022-11-22 11:29:37,986:INFO:Uploading model into container now
2022-11-22 11:29:37,987:INFO:master_model_container: 7
2022-11-22 11:29:37,987:INFO:display_container: 2
2022-11-22 11:29:37,987:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize='deprecated', precompute='auto', tol=None)
2022-11-22 11:29:37,987:INFO:create_model() successfully completed......................................
2022-11-22 11:29:38,130:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:38,131:INFO:Creating metrics dataframe
2022-11-22 11:29:38,141:INFO:Initializing Bayesian Ridge
2022-11-22 11:29:38,141:INFO:Total runtime is 0.06732421716054282 minutes
2022-11-22 11:29:38,145:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:38,145:INFO:Initializing create_model()
2022-11-22 11:29:38,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:38,145:INFO:Checking exceptions
2022-11-22 11:29:38,146:INFO:Importing libraries
2022-11-22 11:29:38,147:INFO:Copying training dataset
2022-11-22 11:29:38,148:INFO:Defining folds
2022-11-22 11:29:38,148:INFO:Declaring metric variables
2022-11-22 11:29:38,151:INFO:Importing untrained model
2022-11-22 11:29:38,153:INFO:Bayesian Ridge Imported successfully
2022-11-22 11:29:38,162:INFO:Starting cross validation
2022-11-22 11:29:38,163:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:38,242:INFO:Calculating mean and std
2022-11-22 11:29:38,243:INFO:Creating metrics dataframe
2022-11-22 11:29:38,246:INFO:Uploading results into container
2022-11-22 11:29:38,246:INFO:Uploading model into container now
2022-11-22 11:29:38,246:INFO:master_model_container: 8
2022-11-22 11:29:38,246:INFO:display_container: 2
2022-11-22 11:29:38,247:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize='deprecated', tol=0.001, verbose=False)
2022-11-22 11:29:38,247:INFO:create_model() successfully completed......................................
2022-11-22 11:29:38,390:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:38,391:INFO:Creating metrics dataframe
2022-11-22 11:29:38,401:INFO:Initializing Passive Aggressive Regressor
2022-11-22 11:29:38,401:INFO:Total runtime is 0.07164887587229413 minutes
2022-11-22 11:29:38,403:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:38,404:INFO:Initializing create_model()
2022-11-22 11:29:38,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:38,404:INFO:Checking exceptions
2022-11-22 11:29:38,405:INFO:Importing libraries
2022-11-22 11:29:38,406:INFO:Copying training dataset
2022-11-22 11:29:38,409:INFO:Defining folds
2022-11-22 11:29:38,410:INFO:Declaring metric variables
2022-11-22 11:29:38,413:INFO:Importing untrained model
2022-11-22 11:29:38,416:INFO:Passive Aggressive Regressor Imported successfully
2022-11-22 11:29:38,421:INFO:Starting cross validation
2022-11-22 11:29:38,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:38,511:INFO:Calculating mean and std
2022-11-22 11:29:38,512:INFO:Creating metrics dataframe
2022-11-22 11:29:38,515:INFO:Uploading results into container
2022-11-22 11:29:38,515:INFO:Uploading model into container now
2022-11-22 11:29:38,516:INFO:master_model_container: 9
2022-11-22 11:29:38,516:INFO:display_container: 2
2022-11-22 11:29:38,516:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=2908, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2022-11-22 11:29:38,516:INFO:create_model() successfully completed......................................
2022-11-22 11:29:38,658:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:38,658:INFO:Creating metrics dataframe
2022-11-22 11:29:38,668:INFO:Initializing Huber Regressor
2022-11-22 11:29:38,668:INFO:Total runtime is 0.07610523303349814 minutes
2022-11-22 11:29:38,671:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:38,671:INFO:Initializing create_model()
2022-11-22 11:29:38,672:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:38,672:INFO:Checking exceptions
2022-11-22 11:29:38,674:INFO:Importing libraries
2022-11-22 11:29:38,674:INFO:Copying training dataset
2022-11-22 11:29:38,677:INFO:Defining folds
2022-11-22 11:29:38,678:INFO:Declaring metric variables
2022-11-22 11:29:38,681:INFO:Importing untrained model
2022-11-22 11:29:38,684:INFO:Huber Regressor Imported successfully
2022-11-22 11:29:38,690:INFO:Starting cross validation
2022-11-22 11:29:38,691:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:38,753:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:29:38,757:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:29:38,759:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:29:38,782:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:29:38,785:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:29:38,799:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:29:38,800:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:29:38,809:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:29:38,820:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:29:38,827:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-22 11:29:38,834:INFO:Calculating mean and std
2022-11-22 11:29:38,835:INFO:Creating metrics dataframe
2022-11-22 11:29:38,838:INFO:Uploading results into container
2022-11-22 11:29:38,839:INFO:Uploading model into container now
2022-11-22 11:29:38,839:INFO:master_model_container: 10
2022-11-22 11:29:38,839:INFO:display_container: 2
2022-11-22 11:29:38,839:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2022-11-22 11:29:38,840:INFO:create_model() successfully completed......................................
2022-11-22 11:29:38,985:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:38,985:INFO:Creating metrics dataframe
2022-11-22 11:29:38,998:INFO:Initializing K Neighbors Regressor
2022-11-22 11:29:38,998:INFO:Total runtime is 0.08159409364064536 minutes
2022-11-22 11:29:39,000:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:39,000:INFO:Initializing create_model()
2022-11-22 11:29:39,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:39,000:INFO:Checking exceptions
2022-11-22 11:29:39,002:INFO:Importing libraries
2022-11-22 11:29:39,002:INFO:Copying training dataset
2022-11-22 11:29:39,004:INFO:Defining folds
2022-11-22 11:29:39,005:INFO:Declaring metric variables
2022-11-22 11:29:39,009:INFO:Importing untrained model
2022-11-22 11:29:39,013:INFO:K Neighbors Regressor Imported successfully
2022-11-22 11:29:39,018:INFO:Starting cross validation
2022-11-22 11:29:39,019:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:39,118:INFO:Calculating mean and std
2022-11-22 11:29:39,119:INFO:Creating metrics dataframe
2022-11-22 11:29:39,122:INFO:Uploading results into container
2022-11-22 11:29:39,123:INFO:Uploading model into container now
2022-11-22 11:29:39,123:INFO:master_model_container: 11
2022-11-22 11:29:39,124:INFO:display_container: 2
2022-11-22 11:29:39,124:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2022-11-22 11:29:39,124:INFO:create_model() successfully completed......................................
2022-11-22 11:29:39,268:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:39,269:INFO:Creating metrics dataframe
2022-11-22 11:29:39,281:INFO:Initializing Decision Tree Regressor
2022-11-22 11:29:39,281:INFO:Total runtime is 0.08631081978480024 minutes
2022-11-22 11:29:39,283:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:39,283:INFO:Initializing create_model()
2022-11-22 11:29:39,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:39,284:INFO:Checking exceptions
2022-11-22 11:29:39,285:INFO:Importing libraries
2022-11-22 11:29:39,285:INFO:Copying training dataset
2022-11-22 11:29:39,288:INFO:Defining folds
2022-11-22 11:29:39,289:INFO:Declaring metric variables
2022-11-22 11:29:39,293:INFO:Importing untrained model
2022-11-22 11:29:39,296:INFO:Decision Tree Regressor Imported successfully
2022-11-22 11:29:39,302:INFO:Starting cross validation
2022-11-22 11:29:39,302:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:39,410:INFO:Calculating mean and std
2022-11-22 11:29:39,411:INFO:Creating metrics dataframe
2022-11-22 11:29:39,414:INFO:Uploading results into container
2022-11-22 11:29:39,414:INFO:Uploading model into container now
2022-11-22 11:29:39,414:INFO:master_model_container: 12
2022-11-22 11:29:39,414:INFO:display_container: 2
2022-11-22 11:29:39,415:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      random_state=2908, splitter='best')
2022-11-22 11:29:39,415:INFO:create_model() successfully completed......................................
2022-11-22 11:29:39,559:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:39,559:INFO:Creating metrics dataframe
2022-11-22 11:29:39,570:INFO:Initializing Random Forest Regressor
2022-11-22 11:29:39,570:INFO:Total runtime is 0.09113254547119143 minutes
2022-11-22 11:29:39,573:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:39,574:INFO:Initializing create_model()
2022-11-22 11:29:39,574:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:39,574:INFO:Checking exceptions
2022-11-22 11:29:39,576:INFO:Importing libraries
2022-11-22 11:29:39,576:INFO:Copying training dataset
2022-11-22 11:29:39,579:INFO:Defining folds
2022-11-22 11:29:39,579:INFO:Declaring metric variables
2022-11-22 11:29:39,582:INFO:Importing untrained model
2022-11-22 11:29:39,585:INFO:Random Forest Regressor Imported successfully
2022-11-22 11:29:39,592:INFO:Starting cross validation
2022-11-22 11:29:39,593:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:42,141:INFO:Calculating mean and std
2022-11-22 11:29:42,143:INFO:Creating metrics dataframe
2022-11-22 11:29:42,145:INFO:Uploading results into container
2022-11-22 11:29:42,146:INFO:Uploading model into container now
2022-11-22 11:29:42,146:INFO:master_model_container: 13
2022-11-22 11:29:42,146:INFO:display_container: 2
2022-11-22 11:29:42,147:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                      oob_score=False, random_state=2908, verbose=0,
                      warm_start=False)
2022-11-22 11:29:42,147:INFO:create_model() successfully completed......................................
2022-11-22 11:29:42,290:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:42,291:INFO:Creating metrics dataframe
2022-11-22 11:29:42,301:INFO:Initializing Extra Trees Regressor
2022-11-22 11:29:42,301:INFO:Total runtime is 0.13664881388346356 minutes
2022-11-22 11:29:42,305:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:42,305:INFO:Initializing create_model()
2022-11-22 11:29:42,305:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:42,305:INFO:Checking exceptions
2022-11-22 11:29:42,307:INFO:Importing libraries
2022-11-22 11:29:42,307:INFO:Copying training dataset
2022-11-22 11:29:42,310:INFO:Defining folds
2022-11-22 11:29:42,310:INFO:Declaring metric variables
2022-11-22 11:29:42,313:INFO:Importing untrained model
2022-11-22 11:29:42,316:INFO:Extra Trees Regressor Imported successfully
2022-11-22 11:29:42,324:INFO:Starting cross validation
2022-11-22 11:29:42,325:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:43,780:INFO:Calculating mean and std
2022-11-22 11:29:43,782:INFO:Creating metrics dataframe
2022-11-22 11:29:43,786:INFO:Uploading results into container
2022-11-22 11:29:43,786:INFO:Uploading model into container now
2022-11-22 11:29:43,787:INFO:master_model_container: 14
2022-11-22 11:29:43,787:INFO:display_container: 2
2022-11-22 11:29:43,787:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=2908, verbose=0,
                    warm_start=False)
2022-11-22 11:29:43,787:INFO:create_model() successfully completed......................................
2022-11-22 11:29:43,930:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:43,930:INFO:Creating metrics dataframe
2022-11-22 11:29:43,942:INFO:Initializing AdaBoost Regressor
2022-11-22 11:29:43,942:INFO:Total runtime is 0.16400732994079592 minutes
2022-11-22 11:29:43,945:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:43,945:INFO:Initializing create_model()
2022-11-22 11:29:43,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:43,945:INFO:Checking exceptions
2022-11-22 11:29:43,947:INFO:Importing libraries
2022-11-22 11:29:43,947:INFO:Copying training dataset
2022-11-22 11:29:43,949:INFO:Defining folds
2022-11-22 11:29:43,949:INFO:Declaring metric variables
2022-11-22 11:29:43,954:INFO:Importing untrained model
2022-11-22 11:29:43,957:INFO:AdaBoost Regressor Imported successfully
2022-11-22 11:29:43,962:INFO:Starting cross validation
2022-11-22 11:29:43,963:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:44,572:INFO:Calculating mean and std
2022-11-22 11:29:44,573:INFO:Creating metrics dataframe
2022-11-22 11:29:44,575:INFO:Uploading results into container
2022-11-22 11:29:44,576:INFO:Uploading model into container now
2022-11-22 11:29:44,576:INFO:master_model_container: 15
2022-11-22 11:29:44,576:INFO:display_container: 2
2022-11-22 11:29:44,576:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=2908)
2022-11-22 11:29:44,576:INFO:create_model() successfully completed......................................
2022-11-22 11:29:44,713:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:44,713:INFO:Creating metrics dataframe
2022-11-22 11:29:44,725:INFO:Initializing Gradient Boosting Regressor
2022-11-22 11:29:44,725:INFO:Total runtime is 0.17704539299011232 minutes
2022-11-22 11:29:44,727:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:44,727:INFO:Initializing create_model()
2022-11-22 11:29:44,727:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:44,728:INFO:Checking exceptions
2022-11-22 11:29:44,729:INFO:Importing libraries
2022-11-22 11:29:44,729:INFO:Copying training dataset
2022-11-22 11:29:44,732:INFO:Defining folds
2022-11-22 11:29:44,732:INFO:Declaring metric variables
2022-11-22 11:29:44,736:INFO:Importing untrained model
2022-11-22 11:29:44,740:INFO:Gradient Boosting Regressor Imported successfully
2022-11-22 11:29:44,745:INFO:Starting cross validation
2022-11-22 11:29:44,746:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:45,960:INFO:Calculating mean and std
2022-11-22 11:29:45,961:INFO:Creating metrics dataframe
2022-11-22 11:29:45,964:INFO:Uploading results into container
2022-11-22 11:29:45,964:INFO:Uploading model into container now
2022-11-22 11:29:45,964:INFO:master_model_container: 16
2022-11-22 11:29:45,965:INFO:display_container: 2
2022-11-22 11:29:45,965:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=2908, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-22 11:29:45,965:INFO:create_model() successfully completed......................................
2022-11-22 11:29:46,107:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:46,107:INFO:Creating metrics dataframe
2022-11-22 11:29:46,119:INFO:Initializing Light Gradient Boosting Machine
2022-11-22 11:29:46,119:INFO:Total runtime is 0.2002773920694987 minutes
2022-11-22 11:29:46,121:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:46,122:INFO:Initializing create_model()
2022-11-22 11:29:46,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:46,122:INFO:Checking exceptions
2022-11-22 11:29:46,123:INFO:Importing libraries
2022-11-22 11:29:46,123:INFO:Copying training dataset
2022-11-22 11:29:46,125:INFO:Defining folds
2022-11-22 11:29:46,126:INFO:Declaring metric variables
2022-11-22 11:29:46,128:INFO:Importing untrained model
2022-11-22 11:29:46,132:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-22 11:29:46,138:INFO:Starting cross validation
2022-11-22 11:29:46,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:46,412:INFO:Calculating mean and std
2022-11-22 11:29:46,413:INFO:Creating metrics dataframe
2022-11-22 11:29:46,416:INFO:Uploading results into container
2022-11-22 11:29:46,417:INFO:Uploading model into container now
2022-11-22 11:29:46,417:INFO:master_model_container: 17
2022-11-22 11:29:46,417:INFO:display_container: 2
2022-11-22 11:29:46,418:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-11-22 11:29:46,418:INFO:create_model() successfully completed......................................
2022-11-22 11:29:46,553:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:46,553:INFO:Creating metrics dataframe
2022-11-22 11:29:46,564:INFO:Initializing Dummy Regressor
2022-11-22 11:29:46,564:INFO:Total runtime is 0.20770305395126343 minutes
2022-11-22 11:29:46,568:INFO:SubProcess create_model() called ==================================
2022-11-22 11:29:46,569:INFO:Initializing create_model()
2022-11-22 11:29:46,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad5032e440>, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:46,569:INFO:Checking exceptions
2022-11-22 11:29:46,570:INFO:Importing libraries
2022-11-22 11:29:46,570:INFO:Copying training dataset
2022-11-22 11:29:46,573:INFO:Defining folds
2022-11-22 11:29:46,573:INFO:Declaring metric variables
2022-11-22 11:29:46,576:INFO:Importing untrained model
2022-11-22 11:29:46,578:INFO:Dummy Regressor Imported successfully
2022-11-22 11:29:46,584:INFO:Starting cross validation
2022-11-22 11:29:46,585:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:46,652:INFO:Calculating mean and std
2022-11-22 11:29:46,652:INFO:Creating metrics dataframe
2022-11-22 11:29:46,655:INFO:Uploading results into container
2022-11-22 11:29:46,655:INFO:Uploading model into container now
2022-11-22 11:29:46,655:INFO:master_model_container: 18
2022-11-22 11:29:46,655:INFO:display_container: 2
2022-11-22 11:29:46,655:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2022-11-22 11:29:46,655:INFO:create_model() successfully completed......................................
2022-11-22 11:29:46,794:INFO:SubProcess create_model() end ==================================
2022-11-22 11:29:46,794:INFO:Creating metrics dataframe
2022-11-22 11:29:46,813:INFO:Initializing create_model()
2022-11-22 11:29:46,813:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:46,813:INFO:Checking exceptions
2022-11-22 11:29:46,817:INFO:Importing libraries
2022-11-22 11:29:46,817:INFO:Copying training dataset
2022-11-22 11:29:46,818:INFO:Defining folds
2022-11-22 11:29:46,819:INFO:Declaring metric variables
2022-11-22 11:29:46,819:INFO:Importing untrained model
2022-11-22 11:29:46,819:INFO:Declaring custom model
2022-11-22 11:29:46,819:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-22 11:29:46,820:INFO:Cross validation set to False
2022-11-22 11:29:46,820:INFO:Fitting Model
2022-11-22 11:29:46,908:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-11-22 11:29:46,908:INFO:create_model() successfully completed......................................
2022-11-22 11:29:47,088:INFO:master_model_container: 18
2022-11-22 11:29:47,089:INFO:display_container: 2
2022-11-22 11:29:47,089:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-11-22 11:29:47,089:INFO:compare_models() successfully completed......................................
2022-11-22 11:29:47,125:INFO:Initializing create_model()
2022-11-22 11:29:47,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=gbr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:29:47,126:INFO:Checking exceptions
2022-11-22 11:29:47,146:INFO:Importing libraries
2022-11-22 11:29:47,146:INFO:Copying training dataset
2022-11-22 11:29:47,148:INFO:Defining folds
2022-11-22 11:29:47,149:INFO:Declaring metric variables
2022-11-22 11:29:47,152:INFO:Importing untrained model
2022-11-22 11:29:47,156:INFO:Gradient Boosting Regressor Imported successfully
2022-11-22 11:29:47,161:INFO:Starting cross validation
2022-11-22 11:29:47,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:29:48,428:INFO:Calculating mean and std
2022-11-22 11:29:48,429:INFO:Creating metrics dataframe
2022-11-22 11:29:48,436:INFO:Finalizing model
2022-11-22 11:29:48,920:INFO:Uploading results into container
2022-11-22 11:29:48,920:INFO:Uploading model into container now
2022-11-22 11:29:48,929:INFO:master_model_container: 19
2022-11-22 11:29:48,929:INFO:display_container: 3
2022-11-22 11:29:48,930:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=2908, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-22 11:29:48,930:INFO:create_model() successfully completed......................................
2022-11-22 11:29:49,078:INFO:Initializing tune_model()
2022-11-22 11:29:49,078:INFO:tune_model(estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=2908, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>)
2022-11-22 11:29:49,078:INFO:Checking exceptions
2022-11-22 11:29:49,097:INFO:Copying training dataset
2022-11-22 11:29:49,101:INFO:Checking base model
2022-11-22 11:29:49,101:INFO:Base model : Gradient Boosting Regressor
2022-11-22 11:29:49,104:INFO:Declaring metric variables
2022-11-22 11:29:49,107:INFO:Defining Hyperparameters
2022-11-22 11:29:49,258:INFO:Tuning with n_jobs=-1
2022-11-22 11:29:49,258:INFO:Initializing RandomizedSearchCV
2022-11-22 11:30:04,399:INFO:best_params: {'actual_estimator__subsample': 0.9, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 5, 'actual_estimator__learning_rate': 0.2}
2022-11-22 11:30:04,400:INFO:Hyperparameter search completed
2022-11-22 11:30:04,400:INFO:SubProcess create_model() called ==================================
2022-11-22 11:30:04,401:INFO:Initializing create_model()
2022-11-22 11:30:04,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=2908, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad53a95bd0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.9, 'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 5, 'learning_rate': 0.2})
2022-11-22 11:30:04,402:INFO:Checking exceptions
2022-11-22 11:30:04,404:INFO:Importing libraries
2022-11-22 11:30:04,404:INFO:Copying training dataset
2022-11-22 11:30:04,406:INFO:Defining folds
2022-11-22 11:30:04,406:INFO:Declaring metric variables
2022-11-22 11:30:04,408:INFO:Importing untrained model
2022-11-22 11:30:04,408:INFO:Declaring custom model
2022-11-22 11:30:04,411:INFO:Gradient Boosting Regressor Imported successfully
2022-11-22 11:30:04,417:INFO:Starting cross validation
2022-11-22 11:30:04,418:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:30:09,286:INFO:Calculating mean and std
2022-11-22 11:30:09,288:INFO:Creating metrics dataframe
2022-11-22 11:30:09,292:INFO:Finalizing model
2022-11-22 11:30:11,263:INFO:Uploading results into container
2022-11-22 11:30:11,264:INFO:Uploading model into container now
2022-11-22 11:30:11,264:INFO:master_model_container: 20
2022-11-22 11:30:11,264:INFO:display_container: 4
2022-11-22 11:30:11,265:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.2, loss='squared_error',
                          max_depth=5, max_features=1.0, max_leaf_nodes=None,
                          min_impurity_decrease=0.0001, min_samples_leaf=1,
                          min_samples_split=5, min_weight_fraction_leaf=0.0,
                          n_estimators=260, n_iter_no_change=None,
                          random_state=2908, subsample=0.9, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-22 11:30:11,265:INFO:create_model() successfully completed......................................
2022-11-22 11:30:11,407:INFO:SubProcess create_model() end ==================================
2022-11-22 11:30:11,408:INFO:choose_better activated
2022-11-22 11:30:11,412:INFO:SubProcess create_model() called ==================================
2022-11-22 11:30:11,412:INFO:Initializing create_model()
2022-11-22 11:30:11,412:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=2908, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:30:11,413:INFO:Checking exceptions
2022-11-22 11:30:11,415:INFO:Importing libraries
2022-11-22 11:30:11,416:INFO:Copying training dataset
2022-11-22 11:30:11,417:INFO:Defining folds
2022-11-22 11:30:11,417:INFO:Declaring metric variables
2022-11-22 11:30:11,417:INFO:Importing untrained model
2022-11-22 11:30:11,418:INFO:Declaring custom model
2022-11-22 11:30:11,418:INFO:Gradient Boosting Regressor Imported successfully
2022-11-22 11:30:11,418:INFO:Starting cross validation
2022-11-22 11:30:11,419:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:30:12,680:INFO:Calculating mean and std
2022-11-22 11:30:12,681:INFO:Creating metrics dataframe
2022-11-22 11:30:12,682:INFO:Finalizing model
2022-11-22 11:30:13,180:INFO:Uploading results into container
2022-11-22 11:30:13,180:INFO:Uploading model into container now
2022-11-22 11:30:13,181:INFO:master_model_container: 21
2022-11-22 11:30:13,181:INFO:display_container: 5
2022-11-22 11:30:13,181:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=2908, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-22 11:30:13,181:INFO:create_model() successfully completed......................................
2022-11-22 11:30:13,326:INFO:SubProcess create_model() end ==================================
2022-11-22 11:30:13,327:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=2908, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) result for R2 is 0.8206
2022-11-22 11:30:13,327:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.2, loss='squared_error',
                          max_depth=5, max_features=1.0, max_leaf_nodes=None,
                          min_impurity_decrease=0.0001, min_samples_leaf=1,
                          min_samples_split=5, min_weight_fraction_leaf=0.0,
                          n_estimators=260, n_iter_no_change=None,
                          random_state=2908, subsample=0.9, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) result for R2 is 0.8624
2022-11-22 11:30:13,328:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.2, loss='squared_error',
                          max_depth=5, max_features=1.0, max_leaf_nodes=None,
                          min_impurity_decrease=0.0001, min_samples_leaf=1,
                          min_samples_split=5, min_weight_fraction_leaf=0.0,
                          n_estimators=260, n_iter_no_change=None,
                          random_state=2908, subsample=0.9, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) is best model
2022-11-22 11:30:13,328:INFO:choose_better completed
2022-11-22 11:30:13,336:INFO:master_model_container: 21
2022-11-22 11:30:13,336:INFO:display_container: 4
2022-11-22 11:30:13,336:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.2, loss='squared_error',
                          max_depth=5, max_features=1.0, max_leaf_nodes=None,
                          min_impurity_decrease=0.0001, min_samples_leaf=1,
                          min_samples_split=5, min_weight_fraction_leaf=0.0,
                          n_estimators=260, n_iter_no_change=None,
                          random_state=2908, subsample=0.9, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-22 11:30:13,336:INFO:tune_model() successfully completed......................................
2022-11-22 11:30:13,532:INFO:Initializing plot_model()
2022-11-22 11:30:13,532:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.2, loss='squared_error',
                          max_depth=5, max_features=1.0, max_leaf_nodes=None,
                          min_impurity_decrease=0.0001, min_samples_leaf=1,
                          min_samples_split=5, min_weight_fraction_leaf=0.0,
                          n_estimators=260, n_iter_no_change=None,
                          random_state=2908, subsample=0.9, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, system=True)
2022-11-22 11:30:13,533:INFO:Checking exceptions
2022-11-22 11:30:13,537:INFO:Preloading libraries
2022-11-22 11:30:13,551:INFO:Copying training dataset
2022-11-22 11:30:13,551:INFO:Plot type: residuals
2022-11-22 11:30:13,590:INFO:Fitting Model
2022-11-22 11:30:13,590:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning:

X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names


2022-11-22 11:30:13,647:INFO:Scoring test/hold-out set
2022-11-22 11:30:14,080:INFO:Visual Rendered Successfully
2022-11-22 11:30:14,227:INFO:plot_model() successfully completed......................................
2022-11-22 11:30:14,250:INFO:Initializing plot_model()
2022-11-22 11:30:14,250:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=2908, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, system=True)
2022-11-22 11:30:14,250:INFO:Checking exceptions
2022-11-22 11:30:14,254:INFO:Preloading libraries
2022-11-22 11:30:14,261:INFO:Copying training dataset
2022-11-22 11:30:14,261:INFO:Plot type: residuals
2022-11-22 11:30:14,304:INFO:Fitting Model
2022-11-22 11:30:14,304:WARNING:/home/dm/.local/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning:

X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names


2022-11-22 11:30:14,341:INFO:Scoring test/hold-out set
2022-11-22 11:30:14,714:INFO:Visual Rendered Successfully
2022-11-22 11:30:14,866:INFO:plot_model() successfully completed......................................
2022-11-22 11:30:14,886:INFO:Initializing save_model()
2022-11-22 11:30:14,886:INFO:save_model(model=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.2, loss='squared_error',
                          max_depth=5, max_features=1.0, max_leaf_nodes=None,
                          min_impurity_decrease=0.0001, min_samples_leaf=1,
                          min_samples_split=5, min_weight_fraction_leaf=0.0,
                          n_estimators=260, n_iter_no_change=None,
                          random_state=2908, subsample=0.9, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), model_name=Coches_gbr, prep_pipe_=Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2022-11-22 11:30:14,887:INFO:Adding model into prep_pipe
2022-11-22 11:30:14,899:INFO:Coches_gbr.pkl saved in current working directory
2022-11-22 11:30:14,904:INFO:Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=...
                                           criterion='friedman_mse', init=None,
                                           learning_rate=0.2,
                                           loss='squared_error', max_depth=5,
                                           max_features=1.0,
                                           max_leaf_nodes=None,
                                           min_impurity_decrease=0.0001,
                                           min_samples_leaf=1,
                                           min_samples_split=5,
                                           min_weight_fraction_leaf=0.0,
                                           n_estimators=260,
                                           n_iter_no_change=None,
                                           random_state=2908, subsample=0.9,
                                           tol=0.0001, validation_fraction=0.1,
                                           verbose=0, warm_start=False))],
         verbose=False)
2022-11-22 11:30:14,905:INFO:save_model() successfully completed......................................
2022-11-22 11:31:24,470:INFO:Initializing create_model()
2022-11-22 11:31:24,470:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:31:24,470:INFO:Checking exceptions
2022-11-22 11:31:24,492:INFO:Importing libraries
2022-11-22 11:31:24,492:INFO:Copying training dataset
2022-11-22 11:31:24,496:INFO:Defining folds
2022-11-22 11:31:24,496:INFO:Declaring metric variables
2022-11-22 11:31:24,499:INFO:Importing untrained model
2022-11-22 11:31:24,502:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-22 11:31:24,511:INFO:Starting cross validation
2022-11-22 11:31:24,512:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:31:24,777:INFO:Calculating mean and std
2022-11-22 11:31:24,777:INFO:Creating metrics dataframe
2022-11-22 11:31:24,780:INFO:Finalizing model
2022-11-22 11:31:24,867:INFO:Uploading results into container
2022-11-22 11:31:24,868:INFO:Uploading model into container now
2022-11-22 11:31:24,877:INFO:master_model_container: 22
2022-11-22 11:31:24,877:INFO:display_container: 5
2022-11-22 11:31:24,878:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-11-22 11:31:24,878:INFO:create_model() successfully completed......................................
2022-11-22 11:31:50,996:INFO:Initializing create_model()
2022-11-22 11:31:50,996:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:31:50,996:INFO:Checking exceptions
2022-11-22 11:31:51,020:INFO:Importing libraries
2022-11-22 11:31:51,021:INFO:Copying training dataset
2022-11-22 11:31:51,024:INFO:Defining folds
2022-11-22 11:31:51,024:INFO:Declaring metric variables
2022-11-22 11:31:51,028:INFO:Importing untrained model
2022-11-22 11:31:51,032:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-22 11:31:51,040:INFO:Starting cross validation
2022-11-22 11:31:51,041:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:31:51,284:INFO:Calculating mean and std
2022-11-22 11:31:51,284:INFO:Creating metrics dataframe
2022-11-22 11:31:51,288:INFO:Finalizing model
2022-11-22 11:31:51,378:INFO:Uploading results into container
2022-11-22 11:31:51,379:INFO:Uploading model into container now
2022-11-22 11:31:51,390:INFO:master_model_container: 23
2022-11-22 11:31:51,390:INFO:display_container: 6
2022-11-22 11:31:51,391:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-11-22 11:31:51,391:INFO:create_model() successfully completed......................................
2022-11-22 11:31:51,545:INFO:Initializing plot_model()
2022-11-22 11:31:51,545:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, system=True)
2022-11-22 11:31:51,545:INFO:Checking exceptions
2022-11-22 11:31:51,548:INFO:Preloading libraries
2022-11-22 11:31:51,568:INFO:Copying training dataset
2022-11-22 11:31:51,568:INFO:Plot type: feature
2022-11-22 11:31:51,569:WARNING:No coef_ found. Trying feature_importances_
2022-11-22 11:31:51,715:INFO:Visual Rendered Successfully
2022-11-22 11:31:51,869:INFO:plot_model() successfully completed......................................
2022-11-22 11:32:12,562:INFO:Initializing plot_model()
2022-11-22 11:32:12,563:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, system=True)
2022-11-22 11:32:12,563:INFO:Checking exceptions
2022-11-22 11:32:12,568:INFO:Preloading libraries
2022-11-22 11:32:12,590:INFO:Copying training dataset
2022-11-22 11:32:12,590:INFO:Plot type: residuals
2022-11-22 11:32:12,648:INFO:Fitting Model
2022-11-22 11:32:12,711:INFO:Scoring test/hold-out set
2022-11-22 11:32:13,049:INFO:Visual Rendered Successfully
2022-11-22 11:32:13,205:INFO:plot_model() successfully completed......................................
2022-11-22 11:32:25,134:INFO:Initializing save_model()
2022-11-22 11:32:25,134:INFO:save_model(model=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0), model_name=Coches_gbr, prep_pipe_=Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2022-11-22 11:32:25,134:INFO:Adding model into prep_pipe
2022-11-22 11:32:25,143:INFO:Coches_gbr.pkl saved in current working directory
2022-11-22 11:32:25,148:INFO:Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=...
                 LGBMRegressor(boosting_type='gbdt', class_weight=None,
                               colsample_bytree=1.0, importance_type='split',
                               learning_rate=0.1, max_depth=-1,
                               min_child_samples=20, min_child_weight=0.001,
                               min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                               num_leaves=31, objective=None, random_state=2908,
                               reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                               subsample=1.0, subsample_for_bin=200000,
                               subsample_freq=0))],
         verbose=False)
2022-11-22 11:32:25,148:INFO:save_model() successfully completed......................................
2022-11-22 11:33:01,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 11:33:01,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 11:33:01,205:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 11:33:01,205:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-22 11:33:01,946:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-11-22 11:33:02,455:INFO:Initializing load_model()
2022-11-22 11:33:02,455:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:33:02,608:INFO:Initializing predict_model()
2022-11-22 11:33:02,608:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f98f25b9a80>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f99139709d0>)
2022-11-22 11:33:02,608:INFO:Checking exceptions
2022-11-22 11:33:02,608:INFO:Preloading libraries
2022-11-22 11:33:03,163:INFO:Initializing load_model()
2022-11-22 11:33:03,163:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:33:03,224:INFO:Initializing predict_model()
2022-11-22 11:33:03,225:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f98f1bf5900>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f9911eae680>)
2022-11-22 11:33:03,225:INFO:Checking exceptions
2022-11-22 11:33:03,225:INFO:Preloading libraries
2022-11-22 11:34:34,114:INFO:Initializing load_model()
2022-11-22 11:34:34,114:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:34:34,149:INFO:Initializing predict_model()
2022-11-22 11:34:34,149:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f98f1bf5810>, estimator=Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('trained_model', LGBMRegressor(random_state=2908))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f98f1bb1900>)
2022-11-22 11:34:34,150:INFO:Checking exceptions
2022-11-22 11:34:34,150:INFO:Preloading libraries
2022-11-22 11:34:34,150:INFO:Set up data.
2022-11-22 11:34:34,155:INFO:Set up index.
2022-11-22 11:35:31,119:INFO:Initializing load_model()
2022-11-22 11:35:31,119:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:35:31,172:INFO:Initializing predict_model()
2022-11-22 11:35:31,173:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9902c94430>, estimator=Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('trained_model', LGBMRegressor(random_state=2908))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f9900c8c550>)
2022-11-22 11:35:31,173:INFO:Checking exceptions
2022-11-22 11:35:31,173:INFO:Preloading libraries
2022-11-22 11:35:31,173:INFO:Set up data.
2022-11-22 11:35:31,180:INFO:Set up index.
2022-11-22 11:35:51,175:INFO:Initializing load_model()
2022-11-22 11:35:51,175:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:35:51,210:INFO:Initializing predict_model()
2022-11-22 11:35:51,210:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9900c23fa0>, estimator=Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('trained_model', LGBMRegressor(random_state=2908))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f9911d468c0>)
2022-11-22 11:35:51,210:INFO:Checking exceptions
2022-11-22 11:35:51,210:INFO:Preloading libraries
2022-11-22 11:35:51,211:INFO:Set up data.
2022-11-22 11:35:51,215:INFO:Set up index.
2022-11-22 11:35:51,334:INFO:Initializing predict_model()
2022-11-22 11:35:51,335:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f98f26139a0>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f9900c0feb0>)
2022-11-22 11:35:51,335:INFO:Checking exceptions
2022-11-22 11:35:51,335:INFO:Preloading libraries
2022-11-22 11:38:06,554:INFO:Initializing tune_model()
2022-11-22 11:38:06,554:INFO:tune_model(estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>)
2022-11-22 11:38:06,555:INFO:Checking exceptions
2022-11-22 11:38:06,578:INFO:Copying training dataset
2022-11-22 11:38:06,582:INFO:Checking base model
2022-11-22 11:38:06,583:INFO:Base model : Light Gradient Boosting Machine
2022-11-22 11:38:06,587:INFO:Declaring metric variables
2022-11-22 11:38:06,590:INFO:Defining Hyperparameters
2022-11-22 11:38:06,777:INFO:Tuning with n_jobs=-1
2022-11-22 11:38:06,777:INFO:Initializing RandomizedSearchCV
2022-11-22 11:38:12,380:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 0.2, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 120, 'actual_estimator__min_split_gain': 0.8, 'actual_estimator__min_child_samples': 16, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2022-11-22 11:38:12,382:INFO:Hyperparameter search completed
2022-11-22 11:38:12,382:INFO:SubProcess create_model() called ==================================
2022-11-22 11:38:12,383:INFO:Initializing create_model()
2022-11-22 11:38:12,383:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fad54a574c0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.4, 'reg_alpha': 0.2, 'num_leaves': 30, 'n_estimators': 120, 'min_split_gain': 0.8, 'min_child_samples': 16, 'learning_rate': 0.2, 'feature_fraction': 1.0, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2022-11-22 11:38:12,383:INFO:Checking exceptions
2022-11-22 11:38:12,385:INFO:Importing libraries
2022-11-22 11:38:12,385:INFO:Copying training dataset
2022-11-22 11:38:12,387:INFO:Defining folds
2022-11-22 11:38:12,387:INFO:Declaring metric variables
2022-11-22 11:38:12,390:INFO:Importing untrained model
2022-11-22 11:38:12,390:INFO:Declaring custom model
2022-11-22 11:38:12,395:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-22 11:38:12,401:INFO:Starting cross validation
2022-11-22 11:38:12,402:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:38:12,790:INFO:Calculating mean and std
2022-11-22 11:38:12,791:INFO:Creating metrics dataframe
2022-11-22 11:38:12,798:INFO:Finalizing model
2022-11-22 11:38:12,817:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2022-11-22 11:38:12,817:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2022-11-22 11:38:12,817:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2022-11-22 11:38:12,935:INFO:Uploading results into container
2022-11-22 11:38:12,936:INFO:Uploading model into container now
2022-11-22 11:38:12,937:INFO:master_model_container: 24
2022-11-22 11:38:12,937:INFO:display_container: 7
2022-11-22 11:38:12,938:INFO:LGBMRegressor(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
              importance_type='split', learning_rate=0.2, max_depth=-1,
              min_child_samples=16, min_child_weight=0.001, min_split_gain=0.8,
              n_estimators=120, n_jobs=-1, num_leaves=30, objective=None,
              random_state=2908, reg_alpha=0.2, reg_lambda=0.4, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-11-22 11:38:12,938:INFO:create_model() successfully completed......................................
2022-11-22 11:38:13,105:INFO:SubProcess create_model() end ==================================
2022-11-22 11:38:13,105:INFO:choose_better activated
2022-11-22 11:38:13,108:INFO:SubProcess create_model() called ==================================
2022-11-22 11:38:13,109:INFO:Initializing create_model()
2022-11-22 11:38:13,109:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-22 11:38:13,109:INFO:Checking exceptions
2022-11-22 11:38:13,114:INFO:Importing libraries
2022-11-22 11:38:13,114:INFO:Copying training dataset
2022-11-22 11:38:13,116:INFO:Defining folds
2022-11-22 11:38:13,116:INFO:Declaring metric variables
2022-11-22 11:38:13,116:INFO:Importing untrained model
2022-11-22 11:38:13,116:INFO:Declaring custom model
2022-11-22 11:38:13,117:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-22 11:38:13,117:INFO:Starting cross validation
2022-11-22 11:38:13,118:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-22 11:38:13,379:INFO:Calculating mean and std
2022-11-22 11:38:13,380:INFO:Creating metrics dataframe
2022-11-22 11:38:13,381:INFO:Finalizing model
2022-11-22 11:38:13,464:INFO:Uploading results into container
2022-11-22 11:38:13,465:INFO:Uploading model into container now
2022-11-22 11:38:13,465:INFO:master_model_container: 25
2022-11-22 11:38:13,465:INFO:display_container: 8
2022-11-22 11:38:13,466:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-11-22 11:38:13,466:INFO:create_model() successfully completed......................................
2022-11-22 11:38:13,613:INFO:SubProcess create_model() end ==================================
2022-11-22 11:38:13,613:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for R2 is 0.8583
2022-11-22 11:38:13,614:INFO:LGBMRegressor(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
              importance_type='split', learning_rate=0.2, max_depth=-1,
              min_child_samples=16, min_child_weight=0.001, min_split_gain=0.8,
              n_estimators=120, n_jobs=-1, num_leaves=30, objective=None,
              random_state=2908, reg_alpha=0.2, reg_lambda=0.4, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for R2 is 0.838
2022-11-22 11:38:13,614:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2022-11-22 11:38:13,614:INFO:choose_better completed
2022-11-22 11:38:13,614:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2022-11-22 11:38:13,623:INFO:master_model_container: 25
2022-11-22 11:38:13,623:INFO:display_container: 7
2022-11-22 11:38:13,624:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-11-22 11:38:13,624:INFO:tune_model() successfully completed......................................
2022-11-22 11:38:27,178:INFO:Initializing plot_model()
2022-11-22 11:38:27,178:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fad50394e50>, system=True)
2022-11-22 11:38:27,178:INFO:Checking exceptions
2022-11-22 11:38:27,184:INFO:Preloading libraries
2022-11-22 11:38:27,202:INFO:Copying training dataset
2022-11-22 11:38:27,202:INFO:Plot type: residuals
2022-11-22 11:38:27,257:INFO:Fitting Model
2022-11-22 11:38:27,293:INFO:Scoring test/hold-out set
2022-11-22 11:38:27,641:INFO:Visual Rendered Successfully
2022-11-22 11:38:27,793:INFO:plot_model() successfully completed......................................
2022-11-22 11:38:30,956:INFO:Initializing save_model()
2022-11-22 11:38:30,956:INFO:save_model(model=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2908, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0), model_name=Coches_gbr, prep_pipe_=Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2022-11-22 11:38:30,956:INFO:Adding model into prep_pipe
2022-11-22 11:38:30,975:INFO:Coches_gbr.pkl saved in current working directory
2022-11-22 11:38:30,980:INFO:Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=...
                 LGBMRegressor(boosting_type='gbdt', class_weight=None,
                               colsample_bytree=1.0, importance_type='split',
                               learning_rate=0.1, max_depth=-1,
                               min_child_samples=20, min_child_weight=0.001,
                               min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                               num_leaves=31, objective=None, random_state=2908,
                               reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                               subsample=1.0, subsample_for_bin=200000,
                               subsample_freq=0))],
         verbose=False)
2022-11-22 11:38:30,980:INFO:save_model() successfully completed......................................
2022-11-22 11:38:39,442:INFO:Initializing load_model()
2022-11-22 11:38:39,442:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:38:39,470:INFO:Initializing predict_model()
2022-11-22 11:38:39,471:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9910be3910>, estimator=Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('trained_model', LGBMRegressor(random_state=2908))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f9911eaf9a0>)
2022-11-22 11:38:39,471:INFO:Checking exceptions
2022-11-22 11:38:39,471:INFO:Preloading libraries
2022-11-22 11:38:39,471:INFO:Set up data.
2022-11-22 11:38:39,477:INFO:Set up index.
2022-11-22 11:38:39,615:INFO:Initializing predict_model()
2022-11-22 11:38:39,615:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f98f1bfcd30>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f9911eafac0>)
2022-11-22 11:38:39,615:INFO:Checking exceptions
2022-11-22 11:38:39,615:INFO:Preloading libraries
2022-11-22 11:40:54,267:INFO:Initializing load_model()
2022-11-22 11:40:54,267:INFO:load_model(model_name=Coches_gbr, platform=None, authentication=None, verbose=True)
2022-11-22 11:40:54,300:INFO:Initializing predict_model()
2022-11-22 11:40:54,301:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9911f6bcd0>, estimator=Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['make', 'model', 'version', 'fuel',
                                             'year', 'kms', 'shift',
                                             'is_professional', 'dealer',
                                             'province', 'publish_date',
                                             'insert_date'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('trained_model', LGBMRegressor(random_state=2908))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f9900c0feb0>)
2022-11-22 11:40:54,302:INFO:Checking exceptions
2022-11-22 11:40:54,302:INFO:Preloading libraries
2022-11-22 11:40:54,302:INFO:Set up data.
2022-11-22 11:40:54,308:INFO:Set up index.
2022-11-22 11:40:54,435:INFO:Initializing predict_model()
2022-11-22 11:40:54,435:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9911f6b4f0>, estimator=alfa_romeo, probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f98f1f8cdc0>)
2022-11-22 11:40:54,435:INFO:Checking exceptions
2022-11-22 11:40:54,436:INFO:Preloading libraries
